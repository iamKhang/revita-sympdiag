{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e20adc9",
   "metadata": {},
   "source": [
    "# Notebook 01 ‚Äî Dataset Construction from MIMIC-IV / MIMIC-IV-Note\n",
    "\n",
    "M·ª•c ti√™u: x√¢y d·ª±ng m·ªôt t·∫≠p d·ªØ li·ªáu g·ªçn ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh vƒÉn b·∫£n ‚Üí ƒëa nh√£n (ICD-block v√† nh√≥m x√©t nghi·ªám giai ƒëo·∫°n s·ªõm), v·ªõi kh·∫£ nƒÉng gi·ªõi h·∫°n s·ªë d√≤ng ƒë·ªçc ·ªü m·ªçi b∆∞·ªõc nh·∫±m ph·ª•c v·ª• demo nhanh v√† ti·∫øt ki·ªám t√†i nguy√™n.\n",
    "\n",
    "Quy ∆∞·ªõc tr√¨nh b√†y cho m·ªói b∆∞·ªõc:\n",
    "1) M·ª•c ƒë√≠ch c·ªßa b∆∞·ªõc v√† l√Ω do c·∫ßn thi·∫øt.\n",
    "2) Tr∆∞·ªùng d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† √Ω nghƒ©a c·ªßa t·ª´ng tr∆∞·ªùng; n·∫øu n·ªëi gi·ªØa c√°c b·∫£ng, ch·ªâ r√µ kh√≥a n·ªëi v√† √Ω nghƒ©a c·ªßa kh√≥a.\n",
    "3) Th·ª±c hi·ªán x·ª≠ l√Ω d·ªØ li·ªáu.\n",
    "4) Di·ªÖn gi·∫£i √Ω nghƒ©a c√°c tr∆∞·ªùng trong k·∫øt qu·∫£ hi·ªÉn th·ªã."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2d7fb",
   "metadata": {},
   "source": [
    "## 0) C·∫•u h√¨nh & nguy√™n t·∫Øc ƒë·ªçc d·ªØ li·ªáu (kh√¥ng d√πng `nrows`)\n",
    "\n",
    "**Quan tr·ªçng:** Kh√¥ng t·ª± ƒë·ªông gi·ªõi h·∫°n s·ªë d√≤ng b·∫±ng `nrows`. Thay v√†o ƒë√≥:\n",
    "- Ch·ªçn **COHORT** ngay ·ªü b∆∞·ªõc setup b·∫±ng bi·∫øn `N_HADM` (s·ªë l·∫ßn nh·∫≠p vi·ªán mu·ªën l·∫•y).\n",
    "- ·ªû c√°c b∆∞·ªõc sau, **ƒë·ªçc theo `chunksize`** v√† **l·ªçc theo `COHORT_HADM`** ƒë·ªÉ ƒë·∫£m b·∫£o kh√≥a nh·∫•t qu√°n gi·ªØa admissions/ICD/Lab/Notes.\n",
    "\n",
    "**Tham s·ªë ch√≠nh trong b∆∞·ªõc n√†y:**\n",
    "- `N_HADM` *(int | None)*: s·ªë l·∫ßn nh·∫≠p vi·ªán trong cohort (ƒë·∫∑t `None` ƒë·ªÉ d√πng to√†n b·ªô).\n",
    "- `SEED` *(int)*: h·∫°t gi·ªëng ng·∫´u nhi√™n khi c·∫ßn ch·ªçn ng·∫´u nhi√™n.\n",
    "- `BALANCE_BY_SUBJECT` *(bool)*: g·ª£i √Ω c√¢n b·∫±ng theo `subject_id` khi ch·ªçn cohort.\n",
    "- `CHUNKSIZE_DEFAULT` *(int)*: k√≠ch th∆∞·ªõc chunk chu·∫©n khi ƒë·ªçc c√°c b·∫£ng l·ªõn.\n",
    "- `TOP_LABS` *(int)*: s·ªë lab ph·ªï bi·∫øn (0‚Äì6h) d√πng l√†m vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8191b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data\n",
      "HOSP_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimiciv/3.1/hosp\n",
      "NOTE_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimic-iv-note/2.2/note\n",
      "PROC_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/proc\n",
      "{'N_HADM': 10000, 'SEED': 42, 'BALANCE_BY_SUBJECT': True, 'CHUNKSIZE_DEFAULT': 500000, 'TOP_LABS': 50, 'TOP_ICD': 50, 'TOP_PROCS': 50}\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 1 ‚Äî C·∫§U H√åNH D·ªÆ LI·ªÜU V√Ä THAM S·ªê TI·ªÄN X·ª¨ L√ù\n",
    "# ======================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ====== Tham s·ªë cohort & ƒë·ªçc file ======\n",
    "N_HADM = 10000              # vd: 300_000 ho·∫∑c None ƒë·ªÉ d√πng to√†n b·ªô admissions\n",
    "SEED = 42                  # reproducibility\n",
    "BALANCE_BY_SUBJECT = True\n",
    "CHUNKSIZE_DEFAULT = 500_000  # ƒë·ªçc file l·ªõn theo chunk\n",
    "\n",
    "# ====== Gi·ªõi h·∫°n vocab / feature ======\n",
    "TOP_LABS = 50              # s·ªë l∆∞·ª£ng lab ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "TOP_ICD = 50               # s·ªë l∆∞·ª£ng ICD-block ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "TOP_PROCS = 50             # s·ªë l∆∞·ª£ng th·ªß thu·∫≠t ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "\n",
    "# ====== D√≤ ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu ======\n",
    "CANDIDATES = [Path(\"data\"), Path(\"../data\"), Path(\"../../data\")]\n",
    "DATA_ROOT = None\n",
    "for cand in CANDIDATES:\n",
    "    if (cand / \"mimiciv\").exists() and (cand / \"mimic-iv-note\").exists():\n",
    "        DATA_ROOT = cand\n",
    "        break\n",
    "if DATA_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'data' ch·ª©a 'mimiciv' v√† 'mimic-iv-note'. \"\n",
    "        \"H√£y ƒëi·ªÅu ch·ªânh CANDIDATES ho·∫∑c thi·∫øt l·∫≠p DATA_ROOT th·ªß c√¥ng.\"\n",
    "    )\n",
    "\n",
    "# ====== Khai b√°o ƒë∆∞·ªùng d·∫´n ======\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "ICU_DIR  = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"icu\"\n",
    "NOTE_DIR = DATA_ROOT / \"mimic-iv-note\" / \"2.2\" / \"note\"\n",
    "PROC_DIR = DATA_ROOT / \"proc\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====== In th√¥ng tin c·∫•u h√¨nh ======\n",
    "print(\"DATA_ROOT:\", DATA_ROOT.resolve())\n",
    "print(\"HOSP_DIR:\", HOSP_DIR.resolve())\n",
    "print(\"NOTE_DIR:\", NOTE_DIR.resolve())\n",
    "print(\"PROC_DIR:\", PROC_DIR.resolve())\n",
    "print({\n",
    "    \"N_HADM\": N_HADM,\n",
    "    \"SEED\": SEED,\n",
    "    \"BALANCE_BY_SUBJECT\": BALANCE_BY_SUBJECT,\n",
    "    \"CHUNKSIZE_DEFAULT\": CHUNKSIZE_DEFAULT,\n",
    "    \"TOP_LABS\": TOP_LABS,\n",
    "    \"TOP_ICD\": TOP_ICD,\n",
    "    \"TOP_PROCS\": TOP_PROCS,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb40fe2",
   "metadata": {},
   "source": [
    "### Ti·ªán √≠ch ƒë·ªçc d·ªØ li·ªáu & x·ª≠ l√Ω c∆° b·∫£n\n",
    "- `read_csv_chunks(path, usecols=None, chunksize=CHUNKSIZE_DEFAULT)`: **generator** ƒë·ªçc theo chunk, KH√îNG d√πng `nrows`.\n",
    "- `normalize_text(s)`: chu·∫©n h√≥a kho·∫£ng tr·∫Øng, c·∫Øt 4,000 k√Ω t·ª±.\n",
    "- `icd_to_block(icd_code)`: r√∫t g·ªçn m√£ ICD v·ªÅ block 3 k√Ω t·ª± (b·ªè d·∫•u ch·∫•m).\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i:**\n",
    "- In x√°c nh·∫≠n ƒë√£ n·∫°p ti·ªán √≠ch.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng tr·∫£ v·ªÅ:**\n",
    "- `read_csv_chunks(...) ‚Üí Iterator[DataFrame]`: d√πng trong v√≤ng l·∫∑p ƒë·ªÉ l·ªçc theo `COHORT_HADM`.\n",
    "- `normalize_text(s) ‚Üí str`: vƒÉn b·∫£n s·∫°ch, ·ªïn ƒë·ªãnh tokenize.\n",
    "- `icd_to_block(code) ‚Üí str|nan`: nh√£n ICD r√∫t g·ªçn, gi·∫£m chi·ªÅu kh√¥ng gian nh√£n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288f2afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ n·∫°p ti·ªán √≠ch: read_csv_chunks, normalize_text, icd_to_block, proc_to_block\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Iterator, Optional, List\n",
    "\n",
    "# ======================================================\n",
    "# B∆Ø·ªöC 2 ‚Äî H√ÄM TI·ªÜN √çCH CHUNG CHO TI·ªÄN X·ª¨ L√ù\n",
    "# ======================================================\n",
    "\n",
    "def read_csv_chunks(path, usecols: Optional[List[str]] = None, chunksize: int = CHUNKSIZE_DEFAULT) -> Iterator[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ƒê·ªçc file .csv.gz theo t·ª´ng kh·ªëi (chunk) ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "    KH√îNG d√πng nrows.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        usecols=usecols,\n",
    "        chunksize=chunksize,\n",
    "        compression=\"gzip\"\n",
    "    )\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Chu·∫©n h√≥a text: lo·∫°i kho·∫£ng tr·∫Øng d∆∞, c·∫Øt t·ªëi ƒëa 4000 k√Ω t·ª±.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    return \" \".join(str(s).split())[:4000]\n",
    "\n",
    "def icd_to_block(icd_code: str) -> str:\n",
    "    \"\"\"Chuy·ªÉn m√£ ICD th√†nh block 3 k√Ω t·ª± (VD: 'E119' ‚Üí 'E11').\"\"\"\n",
    "    if pd.isna(icd_code):\n",
    "        return np.nan\n",
    "    s = str(icd_code).replace('.', '').strip()\n",
    "    return s[:3] if len(s) >= 3 else s\n",
    "\n",
    "def proc_to_block(proc_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a m√£ th·ªß thu·∫≠t (procedure) ICD:\n",
    "    - Lo·∫°i b·ªè d·∫•u ch·∫•m.\n",
    "    - V·ªõi ICD-9: c·∫Øt 3 k√Ω t·ª± ƒë·∫ßu (v√≠ d·ª• '88.72' ‚Üí '887').\n",
    "    - V·ªõi ICD-10: l·∫•y 4 k√Ω t·ª± ƒë·∫ßu (v√≠ d·ª• '0UT9FZZ' ‚Üí '0UT9').\n",
    "    \"\"\"\n",
    "    if pd.isna(proc_code):\n",
    "        return np.nan\n",
    "    s = str(proc_code).replace('.', '').strip().upper()\n",
    "    return s[:3] if s[0].isdigit() else s[:4]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 180)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ n·∫°p ti·ªán √≠ch: read_csv_chunks, normalize_text, icd_to_block, proc_to_block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae1d63",
   "metadata": {},
   "source": [
    "## 1) Admissions ‚Äî m·ªëc th·ªùi gian nh·∫≠p vi·ªán & kh·ªüi t·∫°o COHORT\n",
    "\n",
    "**M·ª•c ƒë√≠ch**\n",
    "1) L·∫•y m·ªëc `admittime` cho t·ª´ng `hadm_id` ƒë·ªÉ t√≠nh c√°c c·ª≠a s·ªï s·ªõm: x√©t nghi·ªám **0‚Äì6h**, ghi ch√∫ **0‚Äì12h**.\n",
    "2) **T·∫°o COHORT_HADM** theo c·∫•u h√¨nh ·ªü b∆∞·ªõc setup (`N_HADM`, `BALANCE_BY_SUBJECT`, `SEED`). C√°c b·∫£ng sau (ICD/Lab/Note) s·∫Ω **l·ªçc theo cohort** khi ƒë·ªçc theo `chunksize`.\n",
    "\n",
    "**Tham s·ªë ·∫£nh h∆∞·ªüng** (ƒë√£ khai b√°o ·ªü b∆∞·ªõc setup):\n",
    "- `N_HADM` *(int | None)*: s·ªë l·∫ßn nh·∫≠p vi·ªán c·∫ßn l·∫•y v√†o cohort. `None` = d√πng to√†n b·ªô `admissions`.\n",
    "- `BALANCE_BY_SUBJECT` *(bool)*: n·∫øu `True`, duy·ªát theo `subject_id` ƒë·ªÉ h·∫°n ch·∫ø thi√™n l·ªách (nhi·ªÅu HADM t·ª´ c√πng m·ªôt b·ªánh nh√¢n).\n",
    "- `SEED` *(int)*: h·∫°t gi·ªëng ng·∫´u nhi√™n khi c·∫ßn l·∫•y m·∫´u.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**\n",
    "- `COHORT_HADM` *(set[int])*: t·∫≠p `hadm_id` c·ªë ƒë·ªãnh d√πng xuy√™n su·ªët pipeline.\n",
    "- `admissions_idx` *(Series indexed by `hadm_id`)*: tra c·ª©u nhanh `admittime` ph·ª•c v·ª• join th·ªùi gian cho Lab/Note.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng d·ªØ li·ªáu trong k·∫øt qu·∫£**\n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán ‚Äî kh√≥a n·ªëi gi·ªØa c√°c b·∫£ng.\n",
    "- `admittime`: m·ªëc th·ªùi gian nh·∫≠p vi·ªán ‚Äî cƒÉn c·ª© c·∫Øt c·ª≠a s·ªï 0‚Äì6h (Lab) v√† 0‚Äì12h (Note).\n",
    "- `subject_id`: m√£ b·ªánh nh√¢n (ch·ªâ d√πng khi c√¢n b·∫±ng cohort theo b·ªánh nh√¢n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28d516bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìò T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ban ƒë·∫ßu: 546,028\n",
      "üîç ƒêang ƒë·ªçc ghi ch√∫ xu·∫•t vi·ªán...\n",
      "‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ghi ch√∫ xu·∫•t vi·ªán: 10,000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admittime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000815</th>\n",
       "      <td>2162-03-08 19:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004116</th>\n",
       "      <td>2202-06-21 14:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004829</th>\n",
       "      <td>2172-05-25 16:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20004866</th>\n",
       "      <td>2126-09-22 16:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006409</th>\n",
       "      <td>2126-10-28 00:28:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   admittime\n",
       "hadm_id                     \n",
       "20000815 2162-03-08 19:52:00\n",
       "20004116 2202-06-21 14:15:00\n",
       "20004829 2172-05-25 16:52:00\n",
       "20004866 2126-09-22 16:12:00\n",
       "20006409 2126-10-28 00:28:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- hadm_id (index): m√£ l·∫ßn nh·∫≠p vi·ªán trong cohort (c√≥ ghi ch√∫ xu·∫•t vi·ªán).\n",
      "- admittime: th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán ƒë·ªÉ tham chi·∫øu c√°c b·∫£ng kh√°c (ICD, th·ªß thu·∫≠t, x√©t nghi·ªám, v.v.).\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 1 ‚Äî ƒê·ªåC ADMISSIONS & T·∫†O COHORT_HADM (CH·ªà NH·ªÆNG CA C√ì GHI CH√ö XU·∫§T VI·ªÜN)\n",
    "# ======================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "adm_path = HOSP_DIR / \"admissions.csv.gz\"\n",
    "discharge_path = NOTE_DIR / \"discharge.csv.gz\"\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# ƒê·ªçc danh s√°ch admissions (to√†n b·ªô)\n",
    "# ------------------------------------------------------\n",
    "usecols = [\"hadm_id\", \"subject_id\", \"admittime\"]\n",
    "admissions = pd.read_csv(adm_path, usecols=usecols, parse_dates=[\"admittime\"], compression=\"gzip\")\n",
    "\n",
    "# L√†m s·∫°ch d·ªØ li·ªáu c∆° b·∫£n\n",
    "admissions = (\n",
    "    admissions\n",
    "    .dropna(subset=[\"hadm_id\", \"admittime\"])\n",
    "    .drop_duplicates(subset=[\"hadm_id\"])\n",
    ")\n",
    "print(f\"üìò T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ban ƒë·∫ßu: {len(admissions):,}\")\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# ƒê·ªçc ghi ch√∫ xu·∫•t vi·ªán ƒë·ªÉ x√°c ƒë·ªãnh c√°c HADM c√≥ text\n",
    "# ------------------------------------------------------\n",
    "usecols = [\"hadm_id\", \"charttime\", \"text\"]\n",
    "print(\"üîç ƒêang ƒë·ªçc ghi ch√∫ xu·∫•t vi·ªán...\")\n",
    "dis_rows = []\n",
    "\n",
    "for chunk in read_csv_chunks(discharge_path, usecols=usecols):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"text\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk[\"text\"] = chunk[\"text\"].map(normalize_text)\n",
    "    dis_rows.append(chunk[[\"hadm_id\", \"charttime\", \"text\"]])\n",
    "\n",
    "if dis_rows:\n",
    "    discharge_df = pd.concat(dis_rows, ignore_index=True)\n",
    "    # Ch·ªçn note s·ªõm nh·∫•t (tr√°nh tr√πng ghi ch√∫ discharge)\n",
    "    discharge_df = (\n",
    "        discharge_df.sort_values([\"hadm_id\", \"charttime\"], ascending=[True, True])\n",
    "        .drop_duplicates(subset=[\"hadm_id\"], keep=\"first\")\n",
    "    )\n",
    "else:\n",
    "    discharge_df = pd.DataFrame(columns=[\"hadm_id\", \"text\"])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Gi·ªØ l·∫°i cohort admissions c√≥ ghi ch√∫ xu·∫•t vi·ªán\n",
    "# ------------------------------------------------------\n",
    "HADM_WITH_NOTE = set(discharge_df[\"hadm_id\"].astype(int))\n",
    "admissions = admissions[admissions[\"hadm_id\"].isin(HADM_WITH_NOTE)]\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# T·∫°o COHORT_HADM (l·∫•y to√†n b·ªô ho·∫∑c l·∫•y m·∫´u n·∫øu gi·ªõi h·∫°n N_HADM)\n",
    "# ------------------------------------------------------\n",
    "if (N_HADM is None) or (N_HADM >= len(admissions)):\n",
    "    COHORT_HADM = set(admissions[\"hadm_id\"].astype(int))\n",
    "else:\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    if BALANCE_BY_SUBJECT:\n",
    "        subjects = admissions[\"subject_id\"].dropna().astype(int).unique()\n",
    "        rng.shuffle(subjects)\n",
    "        picked = []\n",
    "        for sid in subjects:\n",
    "            rows = admissions.loc[admissions[\"subject_id\"] == sid, \"hadm_id\"].astype(int).tolist()\n",
    "            picked.extend(rows)\n",
    "            if len(picked) >= N_HADM:\n",
    "                break\n",
    "        COHORT_HADM = set(picked[:N_HADM])\n",
    "    else:\n",
    "        hadms = admissions[\"hadm_id\"].astype(int).values\n",
    "        sel = rng.choice(hadms, size=N_HADM, replace=False)\n",
    "        COHORT_HADM = set(int(x) for x in sel)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# T·∫°o index th·ªùi gian nh·∫≠p vi·ªán (ƒë·ªÉ join v·ªõi c√°c b·∫£ng kh√°c)\n",
    "# ------------------------------------------------------\n",
    "admissions_cohort = admissions[admissions[\"hadm_id\"].isin(COHORT_HADM)].copy()\n",
    "admissions_idx = admissions_cohort.set_index(\"hadm_id\")[\"admittime\"].sort_index()\n",
    "\n",
    "print(f\"‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ghi ch√∫ xu·∫•t vi·ªán: {len(COHORT_HADM):,}\")\n",
    "display(admissions_idx.to_frame().head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- hadm_id (index): m√£ l·∫ßn nh·∫≠p vi·ªán trong cohort (c√≥ ghi ch√∫ xu·∫•t vi·ªán).\")\n",
    "print(\"- admittime: th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán ƒë·ªÉ tham chi·∫øu c√°c b·∫£ng kh√°c (ICD, th·ªß thu·∫≠t, x√©t nghi·ªám, v.v.).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597b385",
   "metadata": {},
   "source": [
    "## 2) ICD-block cho t·ª´ng l·∫ßn nh·∫≠p vi·ªán (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- R√∫t g·ªçn c√°c m√£ ICD chi ti·∫øt th√†nh **ICD-block** (3 k√Ω t·ª± ƒë·∫ßu) ƒë·ªÉ gi·∫£m s·ªë nh√£n, v·∫´n gi·ªØ th√¥ng tin nh√≥m b·ªánh ch√≠nh.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**  \n",
    "- D·ª±a tr√™n **COHORT_HADM** ƒë√£ ch·ªçn ·ªü B∆∞·ªõc 1.\n",
    "- ƒê·ªçc `diagnoses_icd.csv.gz` theo **chunksize** v√† **l·ªçc theo `hadm_id ‚àà COHORT_HADM`** ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n kh√≥a.\n",
    "\n",
    "**Tr∆∞·ªùng d√πng**  \n",
    "- `subject_id`: m√£ b·ªánh nh√¢n  \n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh)  \n",
    "- `icd_code`: m√£ ICD g·ªëc ‚Üí chuy·ªÉn v·ªÅ **ICD-block**\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- B·∫£ng `icd_df` g·ªìm: `subject_id`, `hadm_id`, `icd_blocks` (danh s√°ch ICD-block **duy nh·∫•t** c·ªßa ca ƒë√≥).\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**  \n",
    "- `icd_blocks`: danh s√°ch c√°c ICD-block (3 k√Ω t·ª±) ƒë·∫°i di·ªán nh√≥m b·ªánh ch√≠nh cho m·ªói l·∫ßn nh·∫≠p vi·ªán.\n",
    "\n",
    "**L∆∞u √Ω**  \n",
    "- Kh√¥ng c√≤n d√πng `nrows`; thay v√†o ƒë√≥ **ƒë·ªçc full theo `chunksize`** v√† l·ªçc theo **COHORT** ngay trong v√≤ng l·∫∑p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe3b9af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD ‚Äî s·ªë hadm c√≥ nh√£n: 9996 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000935</td>\n",
       "      <td>21738619</td>\n",
       "      <td>[266, 272, 276, 288, 311, 427, 715, 721, 780, 786, 787, 793, V15, V45, V58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000935</td>\n",
       "      <td>25849114</td>\n",
       "      <td>[153, 197, 266, 272, 276, 285, 286, 288, 300, 311, 348, 427, 578, 715, 721, 729, 788, V15, V16, V45, V49, V88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000935</td>\n",
       "      <td>26381316</td>\n",
       "      <td>[197, 199, 266, 272, 276, 288, 311, 338, 564, 715, 721, 724, 780, 782, 783, 786, 787, 789, V10, V15, V45, V85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000935</td>\n",
       "      <td>29541074</td>\n",
       "      <td>[266, 272, 278, 311, 560, 788, 998, E87, V10, V88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002430</td>\n",
       "      <td>24513842</td>\n",
       "      <td>[E78, E87, I10, I25, I27, I28, I48, I50, J44, K21, N40, Z79, Z87, Z90, Z98]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id                                                                                                      icd_blocks\n",
       "0    10000935  21738619                                     [266, 272, 276, 288, 311, 427, 715, 721, 780, 786, 787, 793, V15, V45, V58]\n",
       "1    10000935  25849114  [153, 197, 266, 272, 276, 285, 286, 288, 300, 311, 348, 427, 578, 715, 721, 729, 788, V15, V16, V45, V49, V88]\n",
       "2    10000935  26381316  [197, 199, 266, 272, 276, 288, 311, 338, 564, 715, 721, 724, 780, 782, 783, 786, 787, 789, V10, V15, V45, V85]\n",
       "3    10000935  29541074                                                              [266, 272, 278, 311, 560, 788, 998, E87, V10, V88]\n",
       "4    10002430  24513842                                     [E78, E87, I10, I25, I27, I28, I48, I50, J44, K21, N40, Z79, Z87, Z90, Z98]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- subject_id: m√£ b·ªánh nh√¢n.\n",
      "- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh v·ªõi Lab/Note).\n",
      "- icd_blocks: danh s√°ch ICD-block (3 k√Ω t·ª±) ‚Äî nh√≥m b·ªánh ch√≠nh.\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 2: ƒê·ªçc ICD theo chunksize & l·ªçc theo COHORT_HADM, t·∫°o icd_df ---\n",
    "import pandas as pd\n",
    "\n",
    "diag_path = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "\n",
    "icd_rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    diag_path,\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"icd_code\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # l√†m s·∫°ch c∆° b·∫£n v√† l·ªçc theo cohort\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    # chuy·ªÉn icd_code -> block\n",
    "    chunk[\"block\"] = chunk[\"icd_code\"].map(icd_to_block)\n",
    "    icd_rows.append(chunk[[\"subject_id\", \"hadm_id\", \"block\"]])\n",
    "\n",
    "if icd_rows:\n",
    "    diag_df = pd.concat(icd_rows, ignore_index=True)\n",
    "else:\n",
    "    diag_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"block\"])  # r·ªóng an to√†n\n",
    "\n",
    "icd_df = (\n",
    "    diag_df\n",
    "    .groupby([\"subject_id\", \"hadm_id\"]) [\"block\"]\n",
    "    .apply(lambda x: sorted({b for b in x if pd.notna(b)}))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"block\": \"icd_blocks\"})\n",
    ")\n",
    "\n",
    "# sanity checks\n",
    "hadm_icd_n = icd_df[\"hadm_id\"].nunique()\n",
    "print(\"ICD ‚Äî s·ªë hadm c√≥ nh√£n:\", hadm_icd_n, \"/\", len(COHORT_HADM))\n",
    "display(icd_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- subject_id: m√£ b·ªánh nh√¢n.\")\n",
    "print(\"- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh v·ªõi Lab/Note).\")\n",
    "print(\"- icd_blocks: danh s√°ch ICD-block (3 k√Ω t·ª±) ‚Äî nh√≥m b·ªánh ch√≠nh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad30690",
   "metadata": {},
   "source": [
    "### 2.5) Demographics: gi·ªõi t√≠nh & tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- T√≠nh **tu·ªïi t·∫°i nh·∫≠p vi·ªán** v√† l·∫•y **gi·ªõi t√≠nh** ƒë·ªÉ d√πng l√†m ƒë·∫∑c tr∆∞ng tabular (B∆∞·ªõc train).\n",
    "\n",
    "**C√¥ng th·ª©c**  \n",
    "- `age_at_admit = anchor_age + (admit_year - anchor_year)`  \n",
    "- Sau ƒë√≥ **clip** v·ªÅ `[0, 120]`, **round** v√† l∆∞u ki·ªÉu s·ªë nguy√™n `Int64` (nullable).\n",
    "\n",
    "**D·ªØ li·ªáu & r√†ng bu·ªôc**  \n",
    "- L·∫•y `subject_id` ‚Üî `hadm_id` t·ª´ `icd_df` (ƒë√£ l·ªçc theo cohort).\n",
    "- NƒÉm nh·∫≠p vi·ªán `admit_year` l·∫•y t·ª´ `admissions_idx` (B∆∞·ªõc 1).  \n",
    "- ƒê·ªçc `patients.csv.gz` ƒë·∫ßy ƒë·ªß (file v·ª´a ph·∫£i) ƒë·ªÉ t√≠nh tu·ªïi & l·∫•y gi·ªõi t√≠nh.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- B·∫£ng `demo_df` g·ªìm: `hadm_id`, `subject_id`, `gender` (M/F/U), `age_at_admit` (0‚Äì120, Int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a96cb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo ‚Äî s·ªë hadm c√≥ demographics: 10000 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21738619</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25849114</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26381316</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29541074</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24513842</td>\n",
       "      <td>10002430</td>\n",
       "      <td>M</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id gender  age_at_admit\n",
       "0  21738619    10000935      F            57\n",
       "1  25849114    10000935      F            57\n",
       "2  26381316    10000935      F            57\n",
       "3  29541074    10000935      F            53\n",
       "4  24513842    10002430      M            86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- Ch·ªâ t√≠nh cho c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán.\n",
      "- gender: M/F/U.\n",
      "- age_at_admit: tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán (0‚Äì120, ki·ªÉu Int64).\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 2.5: T√≠nh demographics (gender, age_at_admit) ---\n",
    "pat_path = HOSP_DIR / \"patients.csv.gz\"\n",
    "\n",
    "# ƒê·ªçc demographics t·ª´ b·∫£ng patients\n",
    "patients = pd.read_csv(\n",
    "    pat_path,\n",
    "    usecols=[\"subject_id\", \"gender\", \"anchor_age\", \"anchor_year\"],\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "patients[\"gender\"] = patients[\"gender\"].astype(str).str.upper().str[0]  # 'M'/'F'/'U'\n",
    "\n",
    "# L·∫•y subject_id t·ª´ c√°c hadm c√≥ note xu·∫•t vi·ªán (COHORT_HADM)\n",
    "# ·ªû b∆∞·ªõc 1 b·∫°n ƒë√£ c√≥ admissions_cohort ch·ª©a hadm_id, subject_id\n",
    "hadm_subject = admissions_cohort[[\"hadm_id\", \"subject_id\"]].drop_duplicates()\n",
    "\n",
    "# L·∫•y nƒÉm nh·∫≠p vi·ªán t·ª´ admissions_idx (Series indexed by hadm_id)\n",
    "adm_year = admissions_idx.to_frame(name=\"admittime\").reset_index()\n",
    "adm_year[\"admit_year\"] = adm_year[\"admittime\"].dt.year\n",
    "\n",
    "# Gh√©p ƒë·ªÉ t√≠nh tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán\n",
    "age_df = (\n",
    "    hadm_subject\n",
    "    .merge(patients, on=\"subject_id\", how=\"left\")\n",
    "    .merge(adm_year[[\"hadm_id\", \"admit_year\"]], on=\"hadm_id\", how=\"left\")\n",
    ")\n",
    "age_df[\"age_at_admit\"] = age_df[\"anchor_age\"] + (age_df[\"admit_year\"] - age_df[\"anchor_year\"])\n",
    "age_df[\"age_at_admit\"] = (\n",
    "    age_df[\"age_at_admit\"].clip(lower=0, upper=120).round().astype(\"Int64\")\n",
    ")\n",
    "\n",
    "demo_df = age_df[[\"hadm_id\", \"subject_id\", \"gender\", \"age_at_admit\"]].copy()\n",
    "\n",
    "# ƒê·∫£m b·∫£o ch·ªâ gi·ªØ ƒë√∫ng c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "demo_df = demo_df[demo_df[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "\n",
    "# sanity checks\n",
    "print(\"Demo ‚Äî s·ªë hadm c√≥ demographics:\", demo_df[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(demo_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- Ch·ªâ t√≠nh cho c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán.\")\n",
    "print(\"- gender: M/F/U.\")\n",
    "print(\"- age_at_admit: tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán (0‚Äì120, ki·ªÉu Int64).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ea9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCEDURE ‚Äî s·ªë hadm c√≥ th·ªß thu·∫≠t: 6019 / 10000\n",
      "‚úÖ ƒê√£ l∆∞u danh s√°ch Top 100 th·ªß thu·∫≠t: ../data/proc/top_procedures.csv\n",
      "‚úÖ ƒê√£ l∆∞u c·∫•u tr√∫c ph√¢n c·∫•p th·ªß thu·∫≠t: ../data/proc/top_procedure_hierarchy.csv\n",
      "T·ªïng s·ªë th·ªß thu·∫≠t (record-level): 18026\n",
      "T·ªïng s·ªë m√£ th·ªß thu·∫≠t kh√°c nhau: 2913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proc_block</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>389</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02H</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3E0</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5A1</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0W9</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>885</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>967</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>884</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>372</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  proc_block  count\n",
       "0        389   1013\n",
       "1        02H    487\n",
       "2        3E0    483\n",
       "3        5A1    465\n",
       "4        004    371\n",
       "5        0W9    339\n",
       "6        885    328\n",
       "7        967    315\n",
       "8        884    295\n",
       "9        372    280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>n_hadm</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>0014</td>\n",
       "      <td>16</td>\n",
       "      <td>Injection or infusion of oxazolidinone class of antibiotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>0015</td>\n",
       "      <td>11</td>\n",
       "      <td>High-dose infusion interleukin-2 [IL-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>00163J6</td>\n",
       "      <td>3</td>\n",
       "      <td>Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>0017</td>\n",
       "      <td>3</td>\n",
       "      <td>Infusion of vasopressor agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>0011</td>\n",
       "      <td>1</td>\n",
       "      <td>Infusion of drotrecogin alfa (activated)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001</td>\n",
       "      <td>0012</td>\n",
       "      <td>1</td>\n",
       "      <td>Administration of inhaled nitric oxide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001</td>\n",
       "      <td>00163J4</td>\n",
       "      <td>1</td>\n",
       "      <td>Bypass Cerebral Ventricle to Pleural Cavity with Synthetic Substitute, Percutaneous Approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002</td>\n",
       "      <td>0024</td>\n",
       "      <td>3</td>\n",
       "      <td>Intravascular imaging of coronary vessels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002</td>\n",
       "      <td>0023</td>\n",
       "      <td>1</td>\n",
       "      <td>Intravascular imaging of peripheral vessels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>003</td>\n",
       "      <td>0039</td>\n",
       "      <td>2</td>\n",
       "      <td>Other computer assisted surgery</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block icd_code  n_hadm                                                                                       long_title\n",
       "0   001     0014      16                                      Injection or infusion of oxazolidinone class of antibiotics\n",
       "1   001     0015      11                                                          High-dose infusion interleukin-2 [IL-2]\n",
       "2   001  00163J6       3  Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Approach\n",
       "3   001     0017       3                                                                    Infusion of vasopressor agent\n",
       "4   001     0011       1                                                         Infusion of drotrecogin alfa (activated)\n",
       "5   001     0012       1                                                           Administration of inhaled nitric oxide\n",
       "6   001  00163J4       1     Bypass Cerebral Ventricle to Pleural Cavity with Synthetic Substitute, Percutaneous Approach\n",
       "7   002     0024       3                                                        Intravascular imaging of coronary vessels\n",
       "8   002     0023       1                                                      Intravascular imaging of peripheral vessels\n",
       "9   003     0039       2                                                                  Other computer assisted surgery"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>proc_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000935</td>\n",
       "      <td>25849114</td>\n",
       "      <td>[501]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000935</td>\n",
       "      <td>29541074</td>\n",
       "      <td>[456, 545]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002430</td>\n",
       "      <td>27218502</td>\n",
       "      <td>[0YU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003199</td>\n",
       "      <td>21858062</td>\n",
       "      <td>[793]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003203</td>\n",
       "      <td>25146997</td>\n",
       "      <td>[048, 793, 836]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id      proc_blocks\n",
       "0    10000935  25849114            [501]\n",
       "1    10000935  29541074       [456, 545]\n",
       "2    10002430  27218502            [0YU]\n",
       "3    10003199  21858062            [793]\n",
       "4    10003203  25146997  [048, 793, 836]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch:\n",
      "- proc_df: d√πng cho merge ·ªü b∆∞·ªõc 5.\n",
      "- top_procedures.csv: th·ªëng k√™ t·∫ßn su·∫•t 3 k√Ω t·ª± ƒë·∫ßu (block).\n",
      "- top_procedure_hierarchy.csv: chi ti·∫øt t·ª´ng m√£ th·ªß thu·∫≠t con trong t·ª´ng block.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 3 ‚Äî ƒê·ªåC TH·ª¶ THU·∫¨T (PROCEDURES ICD) & T·∫†O proc_df + C√ÅC FILE TH·ªêNG K√ä\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "proc_path = HOSP_DIR / \"procedures_icd.csv.gz\"\n",
    "\n",
    "proc_rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    proc_path,\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"icd_code\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # L√†m s·∫°ch c∆° b·∫£n v√† l·ªçc theo cohort\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # Chu·∫©n h√≥a v√† t√°ch block\n",
    "    chunk[\"icd_code\"] = chunk[\"icd_code\"].astype(str).str.replace(\".\", \"\", regex=False)\n",
    "    chunk[\"block\"] = chunk[\"icd_code\"].str[:3]\n",
    "    proc_rows.append(chunk[[\"subject_id\", \"hadm_id\", \"block\", \"icd_code\"]])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# H·ª¢P NH·∫§T C√ÅC CHUNK\n",
    "# ------------------------------------------------------\n",
    "if proc_rows:\n",
    "    proc_df_raw = pd.concat(proc_rows, ignore_index=True)\n",
    "else:\n",
    "    proc_df_raw = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"block\", \"icd_code\"])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.1 ‚Äî GOM NH√ìM CHO M·ªñI L·∫¶N NH·∫¨P VI·ªÜN\n",
    "# ------------------------------------------------------\n",
    "proc_df = (\n",
    "    proc_df_raw\n",
    "    .groupby([\"subject_id\", \"hadm_id\"])[\"block\"]\n",
    "    .apply(lambda x: sorted({b for b in x if pd.notna(b)}))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"block\": \"proc_blocks\"})\n",
    ")\n",
    "\n",
    "hadm_proc_n = proc_df[\"hadm_id\"].nunique()\n",
    "print(\"PROCEDURE ‚Äî s·ªë hadm c√≥ th·ªß thu·∫≠t:\", hadm_proc_n, \"/\", len(COHORT_HADM))\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.2 ‚Äî XU·∫§T TOP C√ÅC TH·ª¶ THU·∫¨T (BLOCK)\n",
    "# ------------------------------------------------------\n",
    "cnt_proc = Counter(proc_df_raw[\"block\"].dropna().astype(str))\n",
    "top_proc_df = (\n",
    "    pd.DataFrame(cnt_proc.items(), columns=[\"proc_block\", \"count\"])\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "TOP_PROCS = 100\n",
    "out_top_proc = PROC_DIR / \"top_procedures.csv\"\n",
    "top_proc_df.head(TOP_PROCS).to_csv(out_top_proc, index=False)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u danh s√°ch Top {TOP_PROCS} th·ªß thu·∫≠t:\", out_top_proc)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.3 ‚Äî T·∫†O FILE PH√ÇN C·∫§P (BLOCK ‚Üí M√É CHI TI·∫æT)\n",
    "# ------------------------------------------------------\n",
    "freq_detail = (\n",
    "    proc_df_raw\n",
    "    .groupby([\"block\", \"icd_code\"])[\"hadm_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"n_hadm\")\n",
    "    .sort_values([\"block\", \"n_hadm\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# G·∫Øn m√¥ t·∫£ n·∫øu c√≥ dictionary\n",
    "proc_dict_path = HOSP_DIR / \"d_icd_procedures.csv.gz\"\n",
    "if proc_dict_path.exists():\n",
    "    d_proc = pd.read_csv(proc_dict_path, usecols=[\"icd_code\", \"long_title\"], compression=\"gzip\")\n",
    "    d_proc[\"icd_code\"] = d_proc[\"icd_code\"].astype(str).str.replace(\".\", \"\", regex=False)\n",
    "    freq_detail = freq_detail.merge(d_proc, on=\"icd_code\", how=\"left\")\n",
    "\n",
    "out_hierarchy = PROC_DIR / \"top_procedure_hierarchy.csv\"\n",
    "freq_detail.to_csv(out_hierarchy, index=False)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u c·∫•u tr√∫c ph√¢n c·∫•p th·ªß thu·∫≠t:\", out_hierarchy)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.4 ‚Äî KI·ªÇM TRA NHANH\n",
    "# ------------------------------------------------------\n",
    "print(\"T·ªïng s·ªë th·ªß thu·∫≠t (record-level):\", len(proc_df_raw))\n",
    "print(\"T·ªïng s·ªë m√£ th·ªß thu·∫≠t kh√°c nhau:\", proc_df_raw[\"icd_code\"].nunique())\n",
    "display(top_proc_df.head(10))\n",
    "display(freq_detail.head(10))\n",
    "display(proc_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch:\")\n",
    "print(\"- proc_df: d√πng cho merge ·ªü b∆∞·ªõc 5.\")\n",
    "print(\"- top_procedures.csv: th·ªëng k√™ t·∫ßn su·∫•t 3 k√Ω t·ª± ƒë·∫ßu (block).\")\n",
    "print(\"- top_procedure_hierarchy.csv: chi ti·∫øt t·ª´ng m√£ th·ªß thu·∫≠t con trong t·ª´ng block.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac404739",
   "metadata": {},
   "source": [
    "## 3) Nh√≥m x√©t nghi·ªám trong 6 gi·ªù ƒë·∫ßu (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**\n",
    "- X√¢y d·ª±ng nh√£n v·ªÅ **c√°c x√©t nghi·ªám ƒë∆∞·ª£c th·ª±c hi·ªán s·ªõm** (0‚Äì6 gi·ªù ƒë·∫ßu k·ªÉ t·ª´ `admittime`) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh g·ª£i √Ω c·∫≠n l√¢m s√†ng.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**\n",
    "- `labevents.csv.gz`: `hadm_id`, `itemid`, `charttime`  \n",
    "- `d_labitems.csv.gz`: `itemid` ‚Üí `label`  \n",
    "- `admissions_idx` (B∆∞·ªõc 1): tra c·ª©u `admittime` theo `hadm_id`  \n",
    "- **Ch·ªâ l·∫•y b·∫£n ghi c√≥ `hadm_id ‚àà COHORT_HADM`**. ƒê·ªçc theo `chunksize` ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "\n",
    "**X·ª≠ l√Ω (2 pass)**\n",
    "1) **ƒê·∫øm t·∫ßn su·∫•t** `itemid` trong 0‚Äì6h ƒë·ªÉ ch·ªçn `TOP_LABS` (vocab x√©t nghi·ªám s·ªõm ph·ªï bi·∫øn).  \n",
    "2) **G√°n nh√£n cho t·ª´ng ca**: v·ªõi m·ªói `hadm_id`, l·∫•y t·∫≠p h·ª£p `itemid` (thu·ªôc vocab) di·ªÖn ra trong 0‚Äì6h.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**\n",
    "- `lab_vocab_df`: b·∫£ng vocab x√©t nghi·ªám s·ªõm g·ªìm `itemid`, `label`, `count` (t·∫ßn su·∫•t).  \n",
    "- `lab_items_by_hadm`: cho *m·ªói* `hadm_id`, danh s√°ch duy nh·∫•t c√°c `itemid` (thu·ªôc vocab) xu·∫•t hi·ªán trong 0‚Äì6h.  \n",
    "- (Ti·ªán √≠ch) `itemid_to_label`: √°nh x·∫° `itemid ‚Üí label` ƒë·ªÉ hi·ªÉn th·ªã d·ªÖ ƒë·ªçc.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**\n",
    "- `itemid`: m√£ x√©t nghi·ªám.  \n",
    "- `label`: t√™n x√©t nghi·ªám.  \n",
    "- `count`: s·ªë l·∫ßn xu·∫•t hi·ªán trong c·ª≠a s·ªï 0‚Äì6h (tr√™n to√†n cohort).  \n",
    "- `lab_items` (·ªü `lab_items_by_hadm`): danh s√°ch *duy nh·∫•t* c√°c `itemid` thu·ªôc vocab c·ªßa t·ª´ng ca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405b2d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë ph·∫ßn t·ª≠ vocab x√©t nghi·ªám (TOP_N): 50\n",
      "S·ªë ca c√≥ √≠t nh·∫•t m·ªôt x√©t nghi·ªám trong TOP_N: 9395 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50971</td>\n",
       "      <td>Potassium</td>\n",
       "      <td>57874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50983</td>\n",
       "      <td>Sodium</td>\n",
       "      <td>57319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50902</td>\n",
       "      <td>Chloride</td>\n",
       "      <td>56839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51221</td>\n",
       "      <td>Hematocrit</td>\n",
       "      <td>56608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50912</td>\n",
       "      <td>Creatinine</td>\n",
       "      <td>56355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51006</td>\n",
       "      <td>Urea Nitrogen</td>\n",
       "      <td>55954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50882</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>55406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50868</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>55279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50931</td>\n",
       "      <td>Glucose</td>\n",
       "      <td>54769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51265</td>\n",
       "      <td>Platelet Count</td>\n",
       "      <td>53634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid           label  count\n",
       "0   50971       Potassium  57874\n",
       "1   50983          Sodium  57319\n",
       "2   50902        Chloride  56839\n",
       "3   51221      Hematocrit  56608\n",
       "4   50912      Creatinine  56355\n",
       "5   51006   Urea Nitrogen  55954\n",
       "6   50882     Bicarbonate  55406\n",
       "7   50868       Anion Gap  55279\n",
       "8   50931         Glucose  54769\n",
       "9   51265  Platelet Count  53634"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>lab_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000815</td>\n",
       "      <td>[50861, 50863, 50868, 50878, 50882, 50885, 50902, 50912, 50931, 50954, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20004829</td>\n",
       "      <td>[50861, 50862, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51237, 51244, 51248, 51249, 51250, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20004866</td>\n",
       "      <td>[50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20006409</td>\n",
       "      <td>[50802, 50804, 50813, 50818, 50820, 50821, 50868, 50882, 50893, 50902, 50912, 50920, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20007388</td>\n",
       "      <td>[50868, 50882, 50902, 50912, 50920, 50931, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20008094</td>\n",
       "      <td>[50813, 50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20008386</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51275, 51277, 51279, 51301, 51678, 52172]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20010230</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20010239</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20010951</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  \\\n",
       "0  20000815   \n",
       "1  20004829   \n",
       "2  20004866   \n",
       "3  20006409   \n",
       "4  20007388   \n",
       "5  20008094   \n",
       "6  20008386   \n",
       "7  20010230   \n",
       "8  20010239   \n",
       "9  20010951   \n",
       "\n",
       "                                                                                                                                                                             lab_items  \n",
       "0                           [50861, 50863, 50868, 50878, 50882, 50885, 50902, 50912, 50931, 50954, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "1  [50861, 50862, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51237, 51244, 51248, 51249, 51250, ...  \n",
       "2             [50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "3  [50802, 50804, 50813, 50818, 50820, 50821, 50868, 50882, 50893, 50902, 50912, 50920, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, ...  \n",
       "4                    [50868, 50882, 50902, 50912, 50920, 50931, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, 51301]  \n",
       "5  [50813, 50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, ...  \n",
       "6      [50868, 50882, 50893, 50902, 50912, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51275, 51277, 51279, 51301, 51678, 52172]  \n",
       "7                    [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, 51277, 51279, 51301]  \n",
       "8  [50868, 50882, 50893, 50902, 50912, 50931, 50934, 50947, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, ...  \n",
       "9  [50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u danh s√°ch Top Labs: ../data/proc/top_lab_items.csv\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 4: L·∫•y x√©t nghi·ªám Top-N theo t·∫ßn su·∫•t (to√†n b·ªô th·ªùi gian nh·∫≠p vi·ªán) ---\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "labs_path = HOSP_DIR / \"labevents.csv.gz\"\n",
    "dlab_path = HOSP_DIR / \"d_labitems.csv.gz\"\n",
    "\n",
    "# 4.1 ƒê·ªçc dictionary lab: itemid -> label\n",
    "dlab = pd.read_csv(dlab_path, usecols=[\"itemid\", \"label\"], compression=\"gzip\")\n",
    "dlab[\"itemid\"] = dlab[\"itemid\"].astype(int)\n",
    "dlab[\"label\"] = dlab[\"label\"].astype(str)\n",
    "\n",
    "# 4.2 Pass 1 ‚Äî ƒê·∫øm t·∫ßn su·∫•t itemid trong to√†n b·ªô cohort\n",
    "cnt = Counter()\n",
    "\n",
    "for chunk in read_csv_chunks(\n",
    "    labs_path,\n",
    "    usecols=[\"hadm_id\", \"itemid\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk[\"itemid\"]  = chunk[\"itemid\"].astype(int)\n",
    "    # Ch·ªâ l·∫•y c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    cnt.update(chunk[\"itemid\"].value_counts().to_dict())\n",
    "\n",
    "# T√≠nh t·∫ßn su·∫•t\n",
    "counts_df = (\n",
    "    pd.DataFrame(list(cnt.items()), columns=[\"itemid\", \"count\"])\n",
    "    if cnt else pd.DataFrame(columns=[\"itemid\", \"count\"])\n",
    ")\n",
    "counts_df = counts_df.sort_values([\"count\", \"itemid\"], ascending=[False, True])\n",
    "top_items = counts_df.head(TOP_LABS)[\"itemid\"].astype(int).tolist()\n",
    "\n",
    "lab_vocab_df = (\n",
    "    counts_df[counts_df[\"itemid\"].isin(top_items)]\n",
    "    .merge(dlab, on=\"itemid\", how=\"left\")\n",
    "    [[\"itemid\", \"label\", \"count\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 4.3 Pass 2 ‚Äî G√°n danh s√°ch x√©t nghi·ªám theo hadm_id (kh√¥ng gi·ªõi h·∫°n th·ªùi gian)\n",
    "lab_rows = []\n",
    "\n",
    "if len(top_items) > 0:\n",
    "    for chunk in read_csv_chunks(\n",
    "        labs_path,\n",
    "        usecols=[\"hadm_id\", \"itemid\"],\n",
    "        chunksize=CHUNKSIZE_DEFAULT,\n",
    "    ):\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"]).copy()\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "        chunk[\"itemid\"]  = chunk[\"itemid\"].astype(int)\n",
    "        chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        early_top = chunk[chunk[\"itemid\"].isin(top_items)]\n",
    "        if not early_top.empty:\n",
    "            lab_rows.append(early_top[[\"hadm_id\", \"itemid\"]])\n",
    "\n",
    "if lab_rows:\n",
    "    labs_concat = pd.concat(lab_rows, ignore_index=True)\n",
    "    lab_items_by_hadm = (\n",
    "        labs_concat\n",
    "        .groupby(\"hadm_id\")[\"itemid\"]\n",
    "        .apply(lambda s: sorted(set(s.tolist())))\n",
    "        .reset_index()\n",
    "        .rename(columns={\"itemid\": \"lab_items\"})\n",
    "    )\n",
    "else:\n",
    "    lab_items_by_hadm = pd.DataFrame(columns=[\"hadm_id\", \"lab_items\"])\n",
    "\n",
    "# √Ånh x·∫° itemid -> label (ƒë·ªÉ hi·ªÉn th·ªã d·ªÖ hi·ªÉu h∆°n)\n",
    "itemid_to_label = dict(zip(lab_vocab_df[\"itemid\"], lab_vocab_df[\"label\"]))\n",
    "\n",
    "# B√°o c√°o nhanh\n",
    "print(\"S·ªë ph·∫ßn t·ª≠ vocab x√©t nghi·ªám (TOP_N):\", len(lab_vocab_df))\n",
    "print(\"S·ªë ca c√≥ √≠t nh·∫•t m·ªôt x√©t nghi·ªám trong TOP_N:\", lab_items_by_hadm[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(lab_vocab_df.head(10))\n",
    "display(lab_items_by_hadm.head(10))\n",
    "\n",
    "# 4.4 L∆∞u danh s√°ch Top Labs\n",
    "out_top_labs = PROC_DIR / \"top_lab_items.csv\"\n",
    "lab_vocab_df.to_csv(out_top_labs, index=False)\n",
    "print(\"ƒê√£ l∆∞u danh s√°ch Top Labs:\", out_top_labs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb92b8b",
   "metadata": {},
   "source": [
    "## 4) Ghi ch√∫ Radiology trong 12 gi·ªù ƒë·∫ßu (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- L·∫•y **ghi ch√∫ radiology s·ªõm nh·∫•t** trong **0‚Äì12 gi·ªù** k·ªÉ t·ª´ `admittime` cho m·ªói `hadm_id` trong **COHORT_HADM**, l√†m ƒë·∫ßu v√†o m√¥ h√¨nh text‚Üílabel.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**  \n",
    "- `radiology.csv.gz`: `hadm_id`, `charttime`, `text`  \n",
    "- `admissions_idx` (B∆∞·ªõc 1): tra c·ª©u `admittime` theo `hadm_id`  \n",
    "- **Ch·ªâ l·∫•y b·∫£n ghi c√≥ `hadm_id ‚àà COHORT_HADM`**. ƒê·ªçc theo `chunksize` ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "\n",
    "**X·ª≠ l√Ω**  \n",
    "1) ƒê·ªçc radiology theo `chunksize`, l·ªçc theo `COHORT_HADM`.  \n",
    "2) Join `admittime` t·ª´ `admissions_idx`, t√≠nh \\(\\Delta t\\) (gi·ªù).  \n",
    "3) Gi·ªØ c√°c ghi ch√∫ c√≥ \\(0 \\le \\Delta t \\le 12\\).  \n",
    "4) `normalize_text` n·ªôi dung v√† **ch·ªçn ghi ch√∫ s·ªõm nh·∫•t** (nh·ªè nh·∫•t `charttime`) cho m·ªói `hadm_id`.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- `text_df`: DataFrame g·ªìm `hadm_id`, `text` (radiology note s·ªõm nh·∫•t trong 12h, ƒë√£ chu·∫©n ho√°).\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**  \n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a ch√≠nh ƒë·ªÉ join).  \n",
    "- `text`: vƒÉn b·∫£n ghi ch√∫ radiology ƒë·∫ßu ti√™n trong 12h ƒë·∫ßu, ƒë√£ l√†m s·∫°ch ƒë·ªÉ s·∫µn s√†ng tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00d5081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discharge ‚Äî s·ªë hadm c√≥ ghi ch√∫ xu·∫•t vi·ªán: 10000 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000815</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: walnuts Attending: ___. Chief Complaint: vomiting Major Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20004116</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: PLASTIC Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20004829</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Allopurinol Attending: ___ ___ Complaint: dysphagia Major ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004866</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Codeine / Ceftin / Penicillins / Quinine / Demerol / Bactr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20006409</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Dilantin / Sulfa (Sulfonamide Antibiotics) / morphine / ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  \\\n",
       "0  20000815   \n",
       "1  20004116   \n",
       "2  20004829   \n",
       "3  20004866   \n",
       "4  20006409   \n",
       "\n",
       "                                                                                                                                                                                  text  \n",
       "0  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: walnuts Attending: ___. Chief Complaint: vomiting Major Su...  \n",
       "1  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: PLASTIC Allergies: No Known Allergies / Adverse Drug Reactions Attending: ___....  \n",
       "2  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Allopurinol Attending: ___ ___ Complaint: dysphagia Major ...  \n",
       "3  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Codeine / Ceftin / Penicillins / Quinine / Demerol / Bactr...  \n",
       "4  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Dilantin / Sulfa (Sulfonamide Antibiotics) / morphine / ab...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (tr√πng kh√≥a chu·∫©n).\n",
      "- text: n·ªôi dung ghi ch√∫ xu·∫•t vi·ªán m·ªõi nh·∫•t c·ªßa m·ªói ca nh·∫≠p vi·ªán, ƒë√£ chu·∫©n h√≥a.\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 5: L·∫•y ghi ch√∫ xu·∫•t vi·ªán (Discharge Summary) ---\n",
    "import pandas as pd\n",
    "\n",
    "dis_path = NOTE_DIR / \"discharge.csv.gz\"\n",
    "\n",
    "rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    dis_path,\n",
    "    usecols=[\"hadm_id\", \"charttime\", \"text\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # Gi·ªØ l·∫°i b·∫£n ghi h·ª£p l·ªá\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"charttime\", \"text\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "\n",
    "    # Ch·ªâ gi·ªØ nh·ªØng ca c√≥ trong cohort (c√≥ note xu·∫•t vi·ªán)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # Chu·∫©n h√≥a vƒÉn b·∫£n\n",
    "    chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"], errors=\"coerce\")\n",
    "    chunk[\"text\"] = chunk[\"text\"].map(normalize_text)\n",
    "\n",
    "    rows.append(chunk[[\"hadm_id\", \"charttime\", \"text\"]])\n",
    "\n",
    "# G·ªôp to√†n b·ªô\n",
    "if rows:\n",
    "    dis_all = pd.concat(rows, ignore_index=True)\n",
    "    # Ch·ªçn b·∫£n ghi discharge m·ªõi nh·∫•t cho m·ªói hadm_id\n",
    "    dis_all = dis_all.sort_values([\"hadm_id\", \"charttime\"], ascending=[True, False])\n",
    "    text_df = (\n",
    "        dis_all.groupby(\"hadm_id\", as_index=False)[\"text\"]\n",
    "        .first()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "else:\n",
    "    text_df = pd.DataFrame(columns=[\"hadm_id\", \"text\"])\n",
    "\n",
    "# B√°o c√°o k·∫øt qu·∫£\n",
    "print(\"Discharge ‚Äî s·ªë hadm c√≥ ghi ch√∫ xu·∫•t vi·ªán:\", text_df[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(text_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (tr√πng kh√≥a chu·∫©n).\")\n",
    "print(\"- text: n·ªôi dung ghi ch√∫ xu·∫•t vi·ªán m·ªõi nh·∫•t c·ªßa m·ªói ca nh·∫≠p vi·ªán, ƒë√£ chu·∫©n h√≥a.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328929e",
   "metadata": {},
   "source": [
    "## 5) Gh√©p d·ªØ li·ªáu & sinh nh√£n ƒëa nh√£n (multi-hot) ‚Äî **theo COHORT**\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- Gom c√°c ph·∫ßn: **ICD-block** (B∆∞·ªõc 2), **lab s·ªõm 0‚Äì6h** (B∆∞·ªõc 3), **radiology 0‚Äì12h** (B∆∞·ªõc 4), **demographics** (B∆∞·ªõc 2.5) th√†nh **m·ªôt b·∫£ng m·∫´u/nh√£n** d√πng cho hu·∫•n luy·ªán.\n",
    "\n",
    "**Kh√≥a n·ªëi & ƒë·∫ßu v√†o**  \n",
    "- N·ªëi theo `hadm_id` gi·ªØa `icd_df`, `lab_items_by_hadm`, `text_df`.  \n",
    "- Th√™m demographics t·ª´ `demo_df` theo c·∫∑p kh√≥a `[hadm_id, subject_id]`.\n",
    "\n",
    "**X·ª≠ l√Ω**  \n",
    "1) Chu·∫©n h√≥a c√°c c·ªôt list/text/demographics.  \n",
    "2) T·∫°o **vocabulary**:  \n",
    "   ‚Ä¢ `icd_vocab`: danh s√°ch ICD-block ph·ªï bi·∫øn (gi·ªõi h·∫°n b·ªüi `ICD_MAX`).  \n",
    "   ‚Ä¢ `lab_vocab_items`: ch√≠nh l√† Top-N ·ªü B∆∞·ªõc 3 (gi·ªØ nguy√™n th·ª© t·ª±).  \n",
    "3) Sinh vector **multi-hot** cho m·ªói h√†ng: `y_icd`, `y_lab`.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- DataFrame `df_out` g·ªìm: `hadm_id`, `subject_id`, `gender`, `age_at_admit`, `text`, `icd_blocks`, `lab_items`, `y_icd`, `y_lab`.  \n",
    "- Ghi file:  \n",
    "  ‚Ä¢ `examples.parquet`  \n",
    "  ‚Ä¢ `vocab_meta.json` (l∆∞u vocab & mapping `itemid‚Üílabel`).\n",
    "\n",
    "**√ù nghƒ©a c√°c tr∆∞·ªùng ch√≠nh**  \n",
    "- `icd_blocks`: danh s√°ch ICD-block (3 k√Ω t·ª±).  \n",
    "- `lab_items`: danh s√°ch *duy nh·∫•t* c√°c `itemid` thu·ªôc vocab xu·∫•t hi·ªán trong 0‚Äì6h.  \n",
    "- `y_icd`/`y_lab`: vector multi-hot t∆∞∆°ng ·ª©ng v·ªõi `icd_vocab`/`lab_vocab_items`.  \n",
    "- `gender` (`M/F/U`), `age_at_admit` (0‚Äì120, `Int64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89e1d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K√≠ch th∆∞·ªõc vocab ICD: 50\n",
      "K√≠ch th∆∞·ªõc vocab Proc: 50\n",
      "K√≠ch th∆∞·ªõc vocab Lab (Top-N): 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id_x</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_blocks</th>\n",
       "      <th>subject_id_y</th>\n",
       "      <th>proc_blocks</th>\n",
       "      <th>lab_items</th>\n",
       "      <th>text</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "      <th>y_icd</th>\n",
       "      <th>y_lab</th>\n",
       "      <th>y_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000935</td>\n",
       "      <td>21738619</td>\n",
       "      <td>[266, 272, 276, 288, 311, 427, 715, 721, 780, 786, 787, 793, V15, V45, V58]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[50813, 50861, 50868, 50878, 50882, 50885, 50902, 50912, 50931, 50960, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, 51277, 51279, 51301]</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>[0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000935</td>\n",
       "      <td>25849114</td>\n",
       "      <td>[153, 197, 266, 272, 276, 285, 286, 288, 300, 311, 348, 427, 578, 715, 721, 729, 788, V15, V16, V45, V49, V88]</td>\n",
       "      <td>10000935.0</td>\n",
       "      <td>[501]</td>\n",
       "      <td>[50802, 50804, 50813, 50818, 50820, 50821, 50861, 50862, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50920, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51146, ...</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000935</td>\n",
       "      <td>26381316</td>\n",
       "      <td>[197, 199, 266, 272, 276, 288, 311, 338, 564, 715, 721, 724, 780, 782, 783, 786, 787, 789, V10, V15, V45, V85]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>57</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000935</td>\n",
       "      <td>29541074</td>\n",
       "      <td>[266, 272, 278, 311, 560, 788, 998, E87, V10, V88]</td>\n",
       "      <td>10000935.0</td>\n",
       "      <td>[456, 545]</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, ...</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: SURGERY Allergies: Sulfonamides / Codeine / Bactrim Attending: ___. Chief Comp...</td>\n",
       "      <td>10000935</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10002430</td>\n",
       "      <td>24513842</td>\n",
       "      <td>[E78, E87, I10, I25, I27, I28, I48, I50, J44, K21, N40, Z79, Z87, Z90, Z98]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, ...</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Corgard / Vasotec Attending: ___ Chief Complaint: leg edem...</td>\n",
       "      <td>10002430</td>\n",
       "      <td>M</td>\n",
       "      <td>86</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id_x   hadm_id                                                                                                      icd_blocks  \\\n",
       "0      10000935  21738619                                     [266, 272, 276, 288, 311, 427, 715, 721, 780, 786, 787, 793, V15, V45, V58]   \n",
       "1      10000935  25849114  [153, 197, 266, 272, 276, 285, 286, 288, 300, 311, 348, 427, 578, 715, 721, 729, 788, V15, V16, V45, V49, V88]   \n",
       "2      10000935  26381316  [197, 199, 266, 272, 276, 288, 311, 338, 564, 715, 721, 724, 780, 782, 783, 786, 787, 789, V10, V15, V45, V85]   \n",
       "3      10000935  29541074                                                              [266, 272, 278, 311, 560, 788, 998, E87, V10, V88]   \n",
       "4      10002430  24513842                                     [E78, E87, I10, I25, I27, I28, I48, I50, J44, K21, N40, Z79, Z87, Z90, Z98]   \n",
       "\n",
       "   subject_id_y proc_blocks  \\\n",
       "0           NaN          []   \n",
       "1    10000935.0       [501]   \n",
       "2           NaN          []   \n",
       "3    10000935.0  [456, 545]   \n",
       "4           NaN          []   \n",
       "\n",
       "                                                                                                                                                                             lab_items  \\\n",
       "0      [50813, 50861, 50868, 50878, 50882, 50885, 50902, 50912, 50931, 50960, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, 51277, 51279, 51301]   \n",
       "1  [50802, 50804, 50813, 50818, 50820, 50821, 50861, 50862, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50920, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51146, ...   \n",
       "2      [50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]   \n",
       "3  [50868, 50882, 50893, 50902, 50912, 50920, 50931, 50960, 50970, 50971, 50983, 51006, 51146, 51200, 51221, 51222, 51244, 51248, 51249, 51250, 51254, 51256, 51265, 51277, 51279, ...   \n",
       "4  [50861, 50863, 50868, 50878, 50882, 50885, 50893, 50902, 50912, 50931, 50954, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51237, 51248, 51249, 51250, 51265, 51274, 51275, ...   \n",
       "\n",
       "                                                                                                                                                                                  text  \\\n",
       "0  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...   \n",
       "1  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...   \n",
       "2  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: MEDICINE Allergies: Sulfa (Sulfonamide Antibiotics) / Codeine / Bactrim Attend...   \n",
       "3  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: SURGERY Allergies: Sulfonamides / Codeine / Bactrim Attending: ___. Chief Comp...   \n",
       "4  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Corgard / Vasotec Attending: ___ Chief Complaint: leg edem...   \n",
       "\n",
       "   subject_id gender  age_at_admit  \\\n",
       "0    10000935      F            57   \n",
       "1    10000935      F            57   \n",
       "2    10000935      F            57   \n",
       "3    10000935      F            53   \n",
       "4    10002430      M            86   \n",
       "\n",
       "                                                                                                                                                    y_icd  \\\n",
       "0  [0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]   \n",
       "1  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "2  [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]   \n",
       "3  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]   \n",
       "4  [0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                                                                                                                    y_lab  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1]   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                                                                                                                   y_proc  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u (ch·ªâ c√°c HADM c√≥ note):\n",
      "- ../data/proc/examples.parquet\n",
      "- ../data/proc/vocab_meta.json\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 5: Merge & sinh nh√£n multi-hot (g·ªìm ICD + Lab + Procedure) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# 5.1 Gh√©p theo hadm_id\n",
    "df = (\n",
    "    icd_df\n",
    "    .merge(proc_df,             on=\"hadm_id\", how=\"left\")   # ‚¨ÖÔ∏è th√™m th·ªß thu·∫≠t\n",
    "    .merge(lab_items_by_hadm,  on=\"hadm_id\", how=\"left\")\n",
    "    .merge(text_df,             on=\"hadm_id\", how=\"left\")\n",
    "    .merge(demo_df,             on=\"hadm_id\", how=\"left\")   # ‚¨ÖÔ∏è s·ª≠a ·ªü ƒë√¢y\n",
    ")\n",
    "\n",
    "# 5.2 Chu·∫©n ho√° c√°c c·ªôt\n",
    "df[\"icd_blocks\"] = df[\"icd_blocks\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"proc_blocks\"] = df[\"proc_blocks\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"lab_items\"]  = df[\"lab_items\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"text\"]       = df[\"text\"].fillna(\"\")\n",
    "df[\"gender\"]     = df[\"gender\"].fillna(\"U\").astype(str).str.upper().str[0]\n",
    "df[\"age_at_admit\"] = df[\"age_at_admit\"].astype(\"Int64\")\n",
    "\n",
    "# Ch·ªâ gi·ªØ l·∫ßn nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "df = df[df[\"text\"].str.len() > 0].copy()\n",
    "\n",
    "# 5.3 Vocabulary\n",
    "cnt_icd = Counter(b for blocks in df[\"icd_blocks\"] for b in blocks)\n",
    "icd_vocab = [b for b, _ in cnt_icd.most_common(TOP_ICD)]\n",
    "icd_index = {b: i for i, b in enumerate(icd_vocab)}\n",
    "\n",
    "cnt_proc = Counter(p for ps in df[\"proc_blocks\"] for p in ps if pd.notna(p))\n",
    "proc_vocab = [p for p, _ in cnt_proc.most_common(TOP_ICD)]\n",
    "proc_index = {p: i for i, p in enumerate(proc_vocab)}\n",
    "\n",
    "lab_vocab_items = lab_vocab_df[\"itemid\"].astype(int).tolist()\n",
    "lab_index = {it: i for i, it in enumerate(lab_vocab_items)}\n",
    "\n",
    "# 5.4 Multi-hot\n",
    "def to_multihot_generic(labels, index_map, length):\n",
    "    arr = np.zeros(length, dtype=np.int8)\n",
    "    for t in labels:\n",
    "        if t in index_map:\n",
    "            arr[index_map[t]] = 1\n",
    "    return arr\n",
    "\n",
    "df[\"y_icd\"]  = df[\"icd_blocks\"].apply(lambda xs: to_multihot_generic(xs, icd_index, len(icd_vocab)))\n",
    "df[\"y_lab\"]  = df[\"lab_items\"].apply(lambda xs: to_multihot_generic(xs, lab_index, len(lab_vocab_items)))\n",
    "df[\"y_proc\"] = df[\"proc_blocks\"].apply(lambda xs: to_multihot_generic(xs, proc_index, len(proc_vocab)))\n",
    "\n",
    "# 5.5 √Ånh x·∫° itemid -> label (lab)\n",
    "itemid_to_label = dict(zip(lab_vocab_df[\"itemid\"].astype(int), lab_vocab_df[\"label\"].astype(str)))\n",
    "\n",
    "print(\"K√≠ch th∆∞·ªõc vocab ICD:\", len(icd_vocab))\n",
    "print(\"K√≠ch th∆∞·ªõc vocab Proc:\", len(proc_vocab))\n",
    "print(\"K√≠ch th∆∞·ªõc vocab Lab (Top-N):\", len(lab_vocab_items))\n",
    "display(df.head())\n",
    "\n",
    "# 5.6 L∆∞u ra ƒëƒ©a\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_examples = PROC_DIR / \"examples.parquet\"\n",
    "df_out = df[[\n",
    "    \"hadm_id\", \"subject_id\", \"gender\", \"age_at_admit\",\n",
    "    \"text\", \"icd_blocks\", \"proc_blocks\", \"lab_items\",\n",
    "    \"y_icd\", \"y_proc\", \"y_lab\"\n",
    "]].copy()\n",
    "df_out.to_parquet(out_examples, index=False)\n",
    "\n",
    "out_vocab = PROC_DIR / \"vocab_meta.json\"\n",
    "with open(out_vocab, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"icd_vocab\": icd_vocab,\n",
    "        \"n_icd\": len(icd_vocab),\n",
    "        \"proc_vocab\": proc_vocab,\n",
    "        \"n_proc\": len(proc_vocab),\n",
    "        \"lab_vocab_items\": lab_vocab_items,\n",
    "        \"n_lab\": len(lab_vocab_items),\n",
    "        \"itemid_to_label\": {int(k): str(v) for k, v in itemid_to_label.items()}\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"ƒê√£ l∆∞u (ch·ªâ c√°c HADM c√≥ note):\")\n",
    "print(\"-\", out_examples)\n",
    "print(\"-\", out_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra 5 m·∫´u c√≥ lab_items KH√îNG r·ªóng (v√† y_lab c√≥ √≠t nh·∫•t 1 nh√£n)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def has_lab_items(x):\n",
    "    return isinstance(x, (list, tuple)) and len(x) > 0\n",
    "\n",
    "def has_y_lab(x):\n",
    "    try:\n",
    "        return np.asarray(x).sum() > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# N·∫øu b·∫°n ƒë√£ l∆∞u ra df_out (·ªü B∆∞·ªõc 5), th√¨ ƒë·ªçc l·∫°i; c√≤n n·∫øu ƒëang c√≥ bi·∫øn df th√¨ d√πng df\n",
    "try:\n",
    "    _ = df\n",
    "    frame = df\n",
    "except NameError:\n",
    "    frame = pd.read_parquet(PROC_DIR / \"examples.parquet\")\n",
    "\n",
    "mask_items = frame[\"lab_items\"].apply(has_lab_items)\n",
    "mask_y     = frame[\"y_lab\"].apply(has_y_lab)\n",
    "\n",
    "nonempty_lab = frame[mask_items].copy()\n",
    "print(f\"S·ªë ca c√≥ lab_items kh√¥ng r·ªóng: {len(nonempty_lab)} / {len(frame)} \"\n",
    "      f\"({len(nonempty_lab)/len(frame):.1%})\")\n",
    "\n",
    "nonempty_both = frame[mask_items & mask_y].copy()\n",
    "print(f\"S·ªë ca c√≥ lab_items‚â†‚àÖ v√† y_lab>0: {len(nonempty_both)}\")\n",
    "\n",
    "# L·∫•y ng·∫´u nhi√™n 5 m·∫´u ƒë·ªÉ xem chi ti·∫øt\n",
    "sample_n = min(5, len(nonempty_lab))\n",
    "sample_rows = nonempty_lab.sample(sample_n, random_state=42) if sample_n > 0 else nonempty_lab.head(0)\n",
    "\n",
    "cols_show = [\"subject_id\", \"hadm_id\", \"gender\", \"age_at_admit\", \"icd_blocks\", \"lab_items\", \"text\"]\n",
    "display(sample_rows[cols_show])\n",
    "\n",
    "# (Tu·ª≥ ch·ªçn) In k√®m t·ªïng s·ªë nh√£n lab ƒë∆∞·ª£c b·∫≠t ƒë·ªÉ x√°c nh·∫≠n kh·ªõp y_lab\n",
    "if sample_n > 0:\n",
    "    tmp = sample_rows.copy()\n",
    "    tmp[\"y_lab_sum\"] = tmp[\"y_lab\"].apply(lambda a: int(np.asarray(a).sum()) if isinstance(a, (list,np.ndarray)) else 0)\n",
    "    display(tmp[[\"hadm_id\", \"lab_items\", \"y_lab_sum\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
