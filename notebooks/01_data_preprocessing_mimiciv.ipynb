{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e20adc9",
   "metadata": {},
   "source": [
    "# Notebook 01 ‚Äî Dataset Construction from MIMIC-IV / MIMIC-IV-Note\n",
    "\n",
    "M·ª•c ti√™u: x√¢y d·ª±ng m·ªôt t·∫≠p d·ªØ li·ªáu g·ªçn ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh vƒÉn b·∫£n ‚Üí ƒëa nh√£n (ICD-block v√† nh√≥m x√©t nghi·ªám giai ƒëo·∫°n s·ªõm), v·ªõi kh·∫£ nƒÉng gi·ªõi h·∫°n s·ªë d√≤ng ƒë·ªçc ·ªü m·ªçi b∆∞·ªõc nh·∫±m ph·ª•c v·ª• demo nhanh v√† ti·∫øt ki·ªám t√†i nguy√™n.\n",
    "\n",
    "Quy ∆∞·ªõc tr√¨nh b√†y cho m·ªói b∆∞·ªõc:\n",
    "1) M·ª•c ƒë√≠ch c·ªßa b∆∞·ªõc v√† l√Ω do c·∫ßn thi·∫øt.\n",
    "2) Tr∆∞·ªùng d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng v√† √Ω nghƒ©a c·ªßa t·ª´ng tr∆∞·ªùng; n·∫øu n·ªëi gi·ªØa c√°c b·∫£ng, ch·ªâ r√µ kh√≥a n·ªëi v√† √Ω nghƒ©a c·ªßa kh√≥a.\n",
    "3) Th·ª±c hi·ªán x·ª≠ l√Ω d·ªØ li·ªáu.\n",
    "4) Di·ªÖn gi·∫£i √Ω nghƒ©a c√°c tr∆∞·ªùng trong k·∫øt qu·∫£ hi·ªÉn th·ªã."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2d7fb",
   "metadata": {},
   "source": [
    "## 0) C·∫•u h√¨nh & nguy√™n t·∫Øc ƒë·ªçc d·ªØ li·ªáu (kh√¥ng d√πng `nrows`)\n",
    "\n",
    "**Quan tr·ªçng:** Kh√¥ng t·ª± ƒë·ªông gi·ªõi h·∫°n s·ªë d√≤ng b·∫±ng `nrows`. Thay v√†o ƒë√≥:\n",
    "- Ch·ªçn **COHORT** ngay ·ªü b∆∞·ªõc setup b·∫±ng bi·∫øn `N_HADM` (s·ªë l·∫ßn nh·∫≠p vi·ªán mu·ªën l·∫•y).\n",
    "- ·ªû c√°c b∆∞·ªõc sau, **ƒë·ªçc theo `chunksize`** v√† **l·ªçc theo `COHORT_HADM`** ƒë·ªÉ ƒë·∫£m b·∫£o kh√≥a nh·∫•t qu√°n gi·ªØa admissions/ICD/Lab/Notes.\n",
    "\n",
    "**Tham s·ªë ch√≠nh trong b∆∞·ªõc n√†y:**\n",
    "- `N_HADM` *(int | None)*: s·ªë l·∫ßn nh·∫≠p vi·ªán trong cohort (ƒë·∫∑t `None` ƒë·ªÉ d√πng to√†n b·ªô).\n",
    "- `SEED` *(int)*: h·∫°t gi·ªëng ng·∫´u nhi√™n khi c·∫ßn ch·ªçn ng·∫´u nhi√™n.\n",
    "- `BALANCE_BY_SUBJECT` *(bool)*: g·ª£i √Ω c√¢n b·∫±ng theo `subject_id` khi ch·ªçn cohort.\n",
    "- `CHUNKSIZE_DEFAULT` *(int)*: k√≠ch th∆∞·ªõc chunk chu·∫©n khi ƒë·ªçc c√°c b·∫£ng l·ªõn.\n",
    "- `TOP_LABS` *(int)*: s·ªë lab ph·ªï bi·∫øn (0‚Äì6h) d√πng l√†m vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8191b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data\n",
      "HOSP_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimiciv/3.1/hosp\n",
      "NOTE_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimic-iv-note/2.2/note\n",
      "PROC_DIR: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/proc\n",
      "{'N_HADM': 10000, 'SEED': 42, 'BALANCE_BY_SUBJECT': True, 'CHUNKSIZE_DEFAULT': 500000, 'TOP_LABS': 20, 'TOP_ICD': 20, 'TOP_PROCS': 20}\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 1 ‚Äî C·∫§U H√åNH D·ªÆ LI·ªÜU V√Ä THAM S·ªê TI·ªÄN X·ª¨ L√ù\n",
    "# ======================================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# ====== Tham s·ªë cohort & ƒë·ªçc file ======\n",
    "N_HADM = 10000              # vd: 300_000 ho·∫∑c None ƒë·ªÉ d√πng to√†n b·ªô admissions\n",
    "SEED = 42                  # reproducibility\n",
    "BALANCE_BY_SUBJECT = True\n",
    "CHUNKSIZE_DEFAULT = 500_000  # ƒë·ªçc file l·ªõn theo chunk\n",
    "\n",
    "# ====== Gi·ªõi h·∫°n vocab / feature ======\n",
    "TOP_LABS = 20              # s·ªë l∆∞·ª£ng lab ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "TOP_ICD = 20               # s·ªë l∆∞·ª£ng ICD-block ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "TOP_PROCS = 20             # s·ªë l∆∞·ª£ng th·ªß thu·∫≠t ph·ªï bi·∫øn (to√†n k·ª≥)\n",
    "COHORT_MODE = \"full\"   # \"note\" ho·∫∑c \"full\"\n",
    "\n",
    "# ====== D√≤ ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu ======\n",
    "CANDIDATES = [Path(\"data\"), Path(\"../data\"), Path(\"../../data\")]\n",
    "DATA_ROOT = None\n",
    "for cand in CANDIDATES:\n",
    "    if (cand / \"mimiciv\").exists() and (cand / \"mimic-iv-note\").exists():\n",
    "        DATA_ROOT = cand\n",
    "        break\n",
    "if DATA_ROOT is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c 'data' ch·ª©a 'mimiciv' v√† 'mimic-iv-note'. \"\n",
    "        \"H√£y ƒëi·ªÅu ch·ªânh CANDIDATES ho·∫∑c thi·∫øt l·∫≠p DATA_ROOT th·ªß c√¥ng.\"\n",
    "    )\n",
    "\n",
    "# ====== Khai b√°o ƒë∆∞·ªùng d·∫´n ======\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "ICU_DIR  = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"icu\"\n",
    "NOTE_DIR = DATA_ROOT / \"mimic-iv-note\" / \"2.2\" / \"note\"\n",
    "PROC_DIR = DATA_ROOT / \"proc\"\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ====== In th√¥ng tin c·∫•u h√¨nh ======\n",
    "print(\"DATA_ROOT:\", DATA_ROOT.resolve())\n",
    "print(\"HOSP_DIR:\", HOSP_DIR.resolve())\n",
    "print(\"NOTE_DIR:\", NOTE_DIR.resolve())\n",
    "print(\"PROC_DIR:\", PROC_DIR.resolve())\n",
    "print({\n",
    "    \"N_HADM\": N_HADM,\n",
    "    \"SEED\": SEED,\n",
    "    \"BALANCE_BY_SUBJECT\": BALANCE_BY_SUBJECT,\n",
    "    \"CHUNKSIZE_DEFAULT\": CHUNKSIZE_DEFAULT,\n",
    "    \"TOP_LABS\": TOP_LABS,\n",
    "    \"TOP_ICD\": TOP_ICD,\n",
    "    \"TOP_PROCS\": TOP_PROCS,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb40fe2",
   "metadata": {},
   "source": [
    "### Ti·ªán √≠ch ƒë·ªçc d·ªØ li·ªáu & x·ª≠ l√Ω c∆° b·∫£n\n",
    "- `read_csv_chunks(path, usecols=None, chunksize=CHUNKSIZE_DEFAULT)`: **generator** ƒë·ªçc theo chunk, KH√îNG d√πng `nrows`.\n",
    "- `normalize_text(s)`: chu·∫©n h√≥a kho·∫£ng tr·∫Øng, c·∫Øt 4,000 k√Ω t·ª±.\n",
    "- `icd_to_block(icd_code)`: r√∫t g·ªçn m√£ ICD v·ªÅ block 3 k√Ω t·ª± (b·ªè d·∫•u ch·∫•m).\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i:**\n",
    "- In x√°c nh·∫≠n ƒë√£ n·∫°p ti·ªán √≠ch.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng tr·∫£ v·ªÅ:**\n",
    "- `read_csv_chunks(...) ‚Üí Iterator[DataFrame]`: d√πng trong v√≤ng l·∫∑p ƒë·ªÉ l·ªçc theo `COHORT_HADM`.\n",
    "- `normalize_text(s) ‚Üí str`: vƒÉn b·∫£n s·∫°ch, ·ªïn ƒë·ªãnh tokenize.\n",
    "- `icd_to_block(code) ‚Üí str|nan`: nh√£n ICD r√∫t g·ªçn, gi·∫£m chi·ªÅu kh√¥ng gian nh√£n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288f2afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ n·∫°p ti·ªán √≠ch: read_csv_chunks, normalize_text, icd_to_block, proc_to_block\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Iterator, Optional, List\n",
    "\n",
    "# ======================================================\n",
    "# B∆Ø·ªöC 2 ‚Äî H√ÄM TI·ªÜN √çCH CHUNG CHO TI·ªÄN X·ª¨ L√ù\n",
    "# ======================================================\n",
    "\n",
    "def read_csv_chunks(path, usecols: Optional[List[str]] = None, chunksize: int = CHUNKSIZE_DEFAULT) -> Iterator[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ƒê·ªçc file .csv.gz theo t·ª´ng kh·ªëi (chunk) ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "    KH√îNG d√πng nrows.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        usecols=usecols,\n",
    "        chunksize=chunksize,\n",
    "        compression=\"gzip\"\n",
    "    )\n",
    "\n",
    "def normalize_text(s):\n",
    "    \"\"\"Chu·∫©n h√≥a text: lo·∫°i kho·∫£ng tr·∫Øng d∆∞, c·∫Øt t·ªëi ƒëa 4000 k√Ω t·ª±.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    return \" \".join(str(s).split())[:4000]\n",
    "\n",
    "def icd_to_block(icd_code: str) -> str:\n",
    "    \"\"\"Chuy·ªÉn m√£ ICD th√†nh block 3 k√Ω t·ª± (VD: 'E119' ‚Üí 'E11').\"\"\"\n",
    "    if pd.isna(icd_code):\n",
    "        return np.nan\n",
    "    s = str(icd_code).replace('.', '').strip()\n",
    "    return s[:3] if len(s) >= 3 else s\n",
    "\n",
    "def proc_to_block(proc_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Chu·∫©n h√≥a m√£ th·ªß thu·∫≠t (procedure) ICD:\n",
    "    - Lo·∫°i b·ªè d·∫•u ch·∫•m.\n",
    "    - V·ªõi ICD-9: c·∫Øt 3 k√Ω t·ª± ƒë·∫ßu (v√≠ d·ª• '88.72' ‚Üí '887').\n",
    "    - V·ªõi ICD-10: l·∫•y 4 k√Ω t·ª± ƒë·∫ßu (v√≠ d·ª• '0UT9FZZ' ‚Üí '0UT9').\n",
    "    \"\"\"\n",
    "    if pd.isna(proc_code):\n",
    "        return np.nan\n",
    "    s = str(proc_code).replace('.', '').strip().upper()\n",
    "    return s[:3] if s[0].isdigit() else s[:4]\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 180)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ n·∫°p ti·ªán √≠ch: read_csv_chunks, normalize_text, icd_to_block, proc_to_block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae1d63",
   "metadata": {},
   "source": [
    "## 1) Admissions ‚Äî m·ªëc th·ªùi gian nh·∫≠p vi·ªán & kh·ªüi t·∫°o COHORT\n",
    "\n",
    "**M·ª•c ƒë√≠ch**\n",
    "1) L·∫•y m·ªëc `admittime` cho t·ª´ng `hadm_id` ƒë·ªÉ t√≠nh c√°c c·ª≠a s·ªï s·ªõm: x√©t nghi·ªám **0‚Äì6h**, ghi ch√∫ **0‚Äì12h**.\n",
    "2) **T·∫°o COHORT_HADM** theo c·∫•u h√¨nh ·ªü b∆∞·ªõc setup (`N_HADM`, `BALANCE_BY_SUBJECT`, `SEED`). C√°c b·∫£ng sau (ICD/Lab/Note) s·∫Ω **l·ªçc theo cohort** khi ƒë·ªçc theo `chunksize`.\n",
    "\n",
    "**Tham s·ªë ·∫£nh h∆∞·ªüng** (ƒë√£ khai b√°o ·ªü b∆∞·ªõc setup):\n",
    "- `N_HADM` *(int | None)*: s·ªë l·∫ßn nh·∫≠p vi·ªán c·∫ßn l·∫•y v√†o cohort. `None` = d√πng to√†n b·ªô `admissions`.\n",
    "- `BALANCE_BY_SUBJECT` *(bool)*: n·∫øu `True`, duy·ªát theo `subject_id` ƒë·ªÉ h·∫°n ch·∫ø thi√™n l·ªách (nhi·ªÅu HADM t·ª´ c√πng m·ªôt b·ªánh nh√¢n).\n",
    "- `SEED` *(int)*: h·∫°t gi·ªëng ng·∫´u nhi√™n khi c·∫ßn l·∫•y m·∫´u.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**\n",
    "- `COHORT_HADM` *(set[int])*: t·∫≠p `hadm_id` c·ªë ƒë·ªãnh d√πng xuy√™n su·ªët pipeline.\n",
    "- `admissions_idx` *(Series indexed by `hadm_id`)*: tra c·ª©u nhanh `admittime` ph·ª•c v·ª• join th·ªùi gian cho Lab/Note.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng d·ªØ li·ªáu trong k·∫øt qu·∫£**\n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán ‚Äî kh√≥a n·ªëi gi·ªØa c√°c b·∫£ng.\n",
    "- `admittime`: m·ªëc th·ªùi gian nh·∫≠p vi·ªán ‚Äî cƒÉn c·ª© c·∫Øt c·ª≠a s·ªï 0‚Äì6h (Lab) v√† 0‚Äì12h (Note).\n",
    "- `subject_id`: m√£ b·ªánh nh√¢n (ch·ªâ d√πng khi c√¢n b·∫±ng cohort theo b·ªánh nh√¢n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d516bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è  Cohort mode: FULL\n",
      "üìò T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ban ƒë·∫ßu: 546,028\n",
      "üîç ƒêang ƒë·ªçc ghi ch√∫ xu·∫•t vi·ªán...\n",
      "‚úÖ L·ªçc theo mode FULL: c√≤n 186,014 l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ƒë·ªß 4 y·∫øu t·ªë\n",
      "‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán trong cohort: 10,000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admittime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20005070</th>\n",
       "      <td>2130-08-17 15:13:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005426</th>\n",
       "      <td>2153-10-02 16:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20005473</th>\n",
       "      <td>2156-02-18 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006377</th>\n",
       "      <td>2157-10-16 21:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20006679</th>\n",
       "      <td>2120-10-18 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   admittime\n",
       "hadm_id                     \n",
       "20005070 2130-08-17 15:13:00\n",
       "20005426 2153-10-02 16:38:00\n",
       "20005473 2156-02-18 08:00:00\n",
       "20006377 2157-10-16 21:09:00\n",
       "20006679 2120-10-18 00:00:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch:\n",
      "- Cohort mode = 'full': ƒë·ªß c·∫£ 4 y·∫øu t·ªë\n",
      "- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán trong cohort.\n",
      "- admittime: th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán ƒë·ªÉ tham chi·∫øu c√°c b·∫£ng kh√°c (ICD, Proc, Lab...).\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 1 ‚Äî T·∫†O COHORT_HADM (THEO KI·ªÇU NOTE HO·∫∂C ƒê·ª¶ D·ªÆ LI·ªÜU)\n",
    "# ======================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "adm_path = HOSP_DIR / \"admissions.csv.gz\"\n",
    "discharge_path = NOTE_DIR / \"discharge.csv.gz\"\n",
    "diag_path = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "proc_path = HOSP_DIR / \"procedures_icd.csv.gz\"\n",
    "lab_path  = HOSP_DIR / \"labevents.csv.gz\"\n",
    "\n",
    "# ------------------------------\n",
    "# C·∫•u h√¨nh ch·∫ø ƒë·ªô cohort\n",
    "# ------------------------------\n",
    "print(f\"üè∑Ô∏è  Cohort mode: {COHORT_MODE.upper()}\")\n",
    "\n",
    "# ------------------------------\n",
    "# ƒê·ªçc danh s√°ch admissions\n",
    "# ------------------------------\n",
    "usecols = [\"hadm_id\", \"subject_id\", \"admittime\"]\n",
    "admissions = pd.read_csv(adm_path, usecols=usecols, parse_dates=[\"admittime\"], compression=\"gzip\")\n",
    "admissions = (\n",
    "    admissions.dropna(subset=[\"hadm_id\", \"admittime\"])\n",
    "              .drop_duplicates(subset=[\"hadm_id\"])\n",
    ")\n",
    "print(f\"üìò T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ban ƒë·∫ßu: {len(admissions):,}\")\n",
    "\n",
    "# ------------------------------\n",
    "# ƒê·ªçc ghi ch√∫ xu·∫•t vi·ªán\n",
    "# ------------------------------\n",
    "usecols = [\"hadm_id\", \"charttime\", \"text\"]\n",
    "print(\"üîç ƒêang ƒë·ªçc ghi ch√∫ xu·∫•t vi·ªán...\")\n",
    "dis_rows = []\n",
    "\n",
    "for chunk in read_csv_chunks(discharge_path, usecols=usecols):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"text\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk[\"text\"] = chunk[\"text\"].map(normalize_text)\n",
    "    dis_rows.append(chunk[[\"hadm_id\", \"charttime\", \"text\"]])\n",
    "\n",
    "if dis_rows:\n",
    "    discharge_df = pd.concat(dis_rows, ignore_index=True)\n",
    "    discharge_df = (\n",
    "        discharge_df.sort_values([\"hadm_id\", \"charttime\"], ascending=[True, True])\n",
    "                    .drop_duplicates(subset=[\"hadm_id\"], keep=\"first\")\n",
    "    )\n",
    "else:\n",
    "    discharge_df = pd.DataFrame(columns=[\"hadm_id\", \"text\"])\n",
    "\n",
    "HADM_WITH_NOTE = set(discharge_df[\"hadm_id\"].astype(int))\n",
    "\n",
    "# ------------------------------\n",
    "# N·∫øu ch·ªçn mode \"full\" ‚Üí y√™u c·∫ßu ƒë·ªß c·∫£ 4 th√†nh ph·∫ßn\n",
    "# ------------------------------\n",
    "if COHORT_MODE == \"full\":\n",
    "    hadm_icd = set(pd.read_csv(diag_path, usecols=[\"hadm_id\"], compression=\"gzip\")[\"hadm_id\"].dropna().astype(int))\n",
    "    hadm_proc = set(pd.read_csv(proc_path, usecols=[\"hadm_id\"], compression=\"gzip\")[\"hadm_id\"].dropna().astype(int))\n",
    "    hadm_lab  = set(pd.read_csv(lab_path,  usecols=[\"hadm_id\"], compression=\"gzip\")[\"hadm_id\"].dropna().astype(int))\n",
    "    HADM_WITH_FULL = HADM_WITH_NOTE & hadm_icd & hadm_proc & hadm_lab\n",
    "    admissions = admissions[admissions[\"hadm_id\"].isin(HADM_WITH_FULL)]\n",
    "    print(f\"‚úÖ L·ªçc theo mode FULL: c√≤n {len(admissions):,} l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ƒë·ªß 4 y·∫øu t·ªë\")\n",
    "else:\n",
    "    admissions = admissions[admissions[\"hadm_id\"].isin(HADM_WITH_NOTE)]\n",
    "    print(f\"‚úÖ L·ªçc theo mode NOTE: c√≤n {len(admissions):,} l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ghi ch√∫ xu·∫•t vi·ªán\")\n",
    "\n",
    "# ------------------------------\n",
    "# T·∫°o COHORT_HADM (c√≥ th·ªÉ gi·ªõi h·∫°n N_HADM)\n",
    "# ------------------------------\n",
    "if (N_HADM is None) or (N_HADM >= len(admissions)):\n",
    "    COHORT_HADM = set(admissions[\"hadm_id\"].astype(int))\n",
    "else:\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    if BALANCE_BY_SUBJECT:\n",
    "        subjects = admissions[\"subject_id\"].dropna().astype(int).unique()\n",
    "        rng.shuffle(subjects)\n",
    "        picked = []\n",
    "        for sid in subjects:\n",
    "            rows = admissions.loc[admissions[\"subject_id\"] == sid, \"hadm_id\"].astype(int).tolist()\n",
    "            picked.extend(rows)\n",
    "            if len(picked) >= N_HADM:\n",
    "                break\n",
    "        COHORT_HADM = set(picked[:N_HADM])\n",
    "    else:\n",
    "        hadms = admissions[\"hadm_id\"].astype(int).values\n",
    "        sel = rng.choice(hadms, size=N_HADM, replace=False)\n",
    "        COHORT_HADM = set(int(x) for x in sel)\n",
    "\n",
    "# ------------------------------\n",
    "# Index th·ªùi gian nh·∫≠p vi·ªán\n",
    "# ------------------------------\n",
    "admissions_cohort = admissions[admissions[\"hadm_id\"].isin(COHORT_HADM)].copy()\n",
    "admissions_idx = admissions_cohort.set_index(\"hadm_id\")[\"admittime\"].sort_index()\n",
    "\n",
    "print(f\"‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán trong cohort: {len(COHORT_HADM):,}\")\n",
    "display(admissions_idx.to_frame().head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch:\")\n",
    "print(f\"- Cohort mode = '{COHORT_MODE}': {'ƒë·ªß c·∫£ 4 y·∫øu t·ªë' if COHORT_MODE=='full' else 'ch·ªâ c√≥ note xu·∫•t vi·ªán'}\")\n",
    "print(\"- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán trong cohort.\")\n",
    "print(\"- admittime: th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán ƒë·ªÉ tham chi·∫øu c√°c b·∫£ng kh√°c (ICD, Proc, Lab...).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597b385",
   "metadata": {},
   "source": [
    "## 2) ICD-block cho t·ª´ng l·∫ßn nh·∫≠p vi·ªán (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- R√∫t g·ªçn c√°c m√£ ICD chi ti·∫øt th√†nh **ICD-block** (3 k√Ω t·ª± ƒë·∫ßu) ƒë·ªÉ gi·∫£m s·ªë nh√£n, v·∫´n gi·ªØ th√¥ng tin nh√≥m b·ªánh ch√≠nh.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**  \n",
    "- D·ª±a tr√™n **COHORT_HADM** ƒë√£ ch·ªçn ·ªü B∆∞·ªõc 1.\n",
    "- ƒê·ªçc `diagnoses_icd.csv.gz` theo **chunksize** v√† **l·ªçc theo `hadm_id ‚àà COHORT_HADM`** ƒë·ªÉ ƒë·∫£m b·∫£o nh·∫•t qu√°n kh√≥a.\n",
    "\n",
    "**Tr∆∞·ªùng d√πng**  \n",
    "- `subject_id`: m√£ b·ªánh nh√¢n  \n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh)  \n",
    "- `icd_code`: m√£ ICD g·ªëc ‚Üí chuy·ªÉn v·ªÅ **ICD-block**\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- B·∫£ng `icd_df` g·ªìm: `subject_id`, `hadm_id`, `icd_blocks` (danh s√°ch ICD-block **duy nh·∫•t** c·ªßa ca ƒë√≥).\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**  \n",
    "- `icd_blocks`: danh s√°ch c√°c ICD-block (3 k√Ω t·ª±) ƒë·∫°i di·ªán nh√≥m b·ªánh ch√≠nh cho m·ªói l·∫ßn nh·∫≠p vi·ªán.\n",
    "\n",
    "**L∆∞u √Ω**  \n",
    "- Kh√¥ng c√≤n d√πng `nrows`; thay v√†o ƒë√≥ **ƒë·ªçc full theo `chunksize`** v√† l·ªçc theo **COHORT** ngay trong v√≤ng l·∫∑p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3b9af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICD ‚Äî s·ªë hadm c√≥ nh√£n: 10000 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001725</td>\n",
       "      <td>25563031</td>\n",
       "      <td>[300, 311, 314, 333, 457, 493, 530, 564, 618, 729, 780, 788, 995, E93, V10, V15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002167</td>\n",
       "      <td>29383904</td>\n",
       "      <td>[268, 272, 278, 280, 327, 477, 553, 564, 571, V85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002557</td>\n",
       "      <td>20731670</td>\n",
       "      <td>[241, 346, 401, 530, 574, V10, V45, V58]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002804</td>\n",
       "      <td>20769698</td>\n",
       "      <td>[365, 813, E88]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003731</td>\n",
       "      <td>23646008</td>\n",
       "      <td>[278, 311, 403, 427, 459, 530, 585, 682, 780, 924, E84, E92, V85]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id                                                                        icd_blocks\n",
       "0    10001725  25563031  [300, 311, 314, 333, 457, 493, 530, 564, 618, 729, 780, 788, 995, E93, V10, V15]\n",
       "1    10002167  29383904                                [268, 272, 278, 280, 327, 477, 553, 564, 571, V85]\n",
       "2    10002557  20731670                                          [241, 346, 401, 530, 574, V10, V45, V58]\n",
       "3    10002804  20769698                                                                   [365, 813, E88]\n",
       "4    10003731  23646008                 [278, 311, 403, 427, 459, 530, 585, 682, 780, 924, E84, E92, V85]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- subject_id: m√£ b·ªánh nh√¢n.\n",
      "- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh v·ªõi Lab/Note).\n",
      "- icd_blocks: danh s√°ch ICD-block (3 k√Ω t·ª±) ‚Äî nh√≥m b·ªánh ch√≠nh.\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 2: ƒê·ªçc ICD theo chunksize & l·ªçc theo COHORT_HADM, t·∫°o icd_df ---\n",
    "import pandas as pd\n",
    "\n",
    "diag_path = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "\n",
    "icd_rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    diag_path,\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"icd_code\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # l√†m s·∫°ch c∆° b·∫£n v√† l·ªçc theo cohort\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    # chuy·ªÉn icd_code -> block\n",
    "    chunk[\"block\"] = chunk[\"icd_code\"].map(icd_to_block)\n",
    "    icd_rows.append(chunk[[\"subject_id\", \"hadm_id\", \"block\"]])\n",
    "\n",
    "if icd_rows:\n",
    "    diag_df = pd.concat(icd_rows, ignore_index=True)\n",
    "else:\n",
    "    diag_df = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"block\"])  # r·ªóng an to√†n\n",
    "\n",
    "icd_df = (\n",
    "    diag_df\n",
    "    .groupby([\"subject_id\", \"hadm_id\"]) [\"block\"]\n",
    "    .apply(lambda x: sorted({b for b in x if pd.notna(b)}))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"block\": \"icd_blocks\"})\n",
    ")\n",
    "\n",
    "# sanity checks\n",
    "hadm_icd_n = icd_df[\"hadm_id\"].nunique()\n",
    "print(\"ICD ‚Äî s·ªë hadm c√≥ nh√£n:\", hadm_icd_n, \"/\", len(COHORT_HADM))\n",
    "display(icd_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- subject_id: m√£ b·ªánh nh√¢n.\")\n",
    "print(\"- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a n·ªëi ch√≠nh v·ªõi Lab/Note).\")\n",
    "print(\"- icd_blocks: danh s√°ch ICD-block (3 k√Ω t·ª±) ‚Äî nh√≥m b·ªánh ch√≠nh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad30690",
   "metadata": {},
   "source": [
    "### 2.5) Demographics: gi·ªõi t√≠nh & tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- T√≠nh **tu·ªïi t·∫°i nh·∫≠p vi·ªán** v√† l·∫•y **gi·ªõi t√≠nh** ƒë·ªÉ d√πng l√†m ƒë·∫∑c tr∆∞ng tabular (B∆∞·ªõc train).\n",
    "\n",
    "**C√¥ng th·ª©c**  \n",
    "- `age_at_admit = anchor_age + (admit_year - anchor_year)`  \n",
    "- Sau ƒë√≥ **clip** v·ªÅ `[0, 120]`, **round** v√† l∆∞u ki·ªÉu s·ªë nguy√™n `Int64` (nullable).\n",
    "\n",
    "**D·ªØ li·ªáu & r√†ng bu·ªôc**  \n",
    "- L·∫•y `subject_id` ‚Üî `hadm_id` t·ª´ `icd_df` (ƒë√£ l·ªçc theo cohort).\n",
    "- NƒÉm nh·∫≠p vi·ªán `admit_year` l·∫•y t·ª´ `admissions_idx` (B∆∞·ªõc 1).  \n",
    "- ƒê·ªçc `patients.csv.gz` ƒë·∫ßy ƒë·ªß (file v·ª´a ph·∫£i) ƒë·ªÉ t√≠nh tu·ªïi & l·∫•y gi·ªõi t√≠nh.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- B·∫£ng `demo_df` g·ªìm: `hadm_id`, `subject_id`, `gender` (M/F/U), `age_at_admit` (0‚Äì120, Int64)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a96cb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo ‚Äî s·ªë hadm c√≥ demographics: 10000 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25563031</td>\n",
       "      <td>10001725</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29383904</td>\n",
       "      <td>10002167</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20731670</td>\n",
       "      <td>10002557</td>\n",
       "      <td>F</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20769698</td>\n",
       "      <td>10002804</td>\n",
       "      <td>M</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23646008</td>\n",
       "      <td>10003731</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  subject_id gender  age_at_admit\n",
       "0  25563031    10001725      F            46\n",
       "1  29383904    10002167      F            34\n",
       "2  20731670    10002557      F            82\n",
       "3  20769698    10002804      M            66\n",
       "4  23646008    10003731      F            61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- Ch·ªâ t√≠nh cho c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán.\n",
      "- gender: M/F/U.\n",
      "- age_at_admit: tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán (0‚Äì120, ki·ªÉu Int64).\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 2.5: T√≠nh demographics (gender, age_at_admit) ---\n",
    "pat_path = HOSP_DIR / \"patients.csv.gz\"\n",
    "\n",
    "# ƒê·ªçc demographics t·ª´ b·∫£ng patients\n",
    "patients = pd.read_csv(\n",
    "    pat_path,\n",
    "    usecols=[\"subject_id\", \"gender\", \"anchor_age\", \"anchor_year\"],\n",
    "    compression=\"gzip\",\n",
    ")\n",
    "patients[\"gender\"] = patients[\"gender\"].astype(str).str.upper().str[0]  # 'M'/'F'/'U'\n",
    "\n",
    "# L·∫•y subject_id t·ª´ c√°c hadm c√≥ note xu·∫•t vi·ªán (COHORT_HADM)\n",
    "# ·ªû b∆∞·ªõc 1 b·∫°n ƒë√£ c√≥ admissions_cohort ch·ª©a hadm_id, subject_id\n",
    "hadm_subject = admissions_cohort[[\"hadm_id\", \"subject_id\"]].drop_duplicates()\n",
    "\n",
    "# L·∫•y nƒÉm nh·∫≠p vi·ªán t·ª´ admissions_idx (Series indexed by hadm_id)\n",
    "adm_year = admissions_idx.to_frame(name=\"admittime\").reset_index()\n",
    "adm_year[\"admit_year\"] = adm_year[\"admittime\"].dt.year\n",
    "\n",
    "# Gh√©p ƒë·ªÉ t√≠nh tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán\n",
    "age_df = (\n",
    "    hadm_subject\n",
    "    .merge(patients, on=\"subject_id\", how=\"left\")\n",
    "    .merge(adm_year[[\"hadm_id\", \"admit_year\"]], on=\"hadm_id\", how=\"left\")\n",
    ")\n",
    "age_df[\"age_at_admit\"] = age_df[\"anchor_age\"] + (age_df[\"admit_year\"] - age_df[\"anchor_year\"])\n",
    "age_df[\"age_at_admit\"] = (\n",
    "    age_df[\"age_at_admit\"].clip(lower=0, upper=120).round().astype(\"Int64\")\n",
    ")\n",
    "\n",
    "demo_df = age_df[[\"hadm_id\", \"subject_id\", \"gender\", \"age_at_admit\"]].copy()\n",
    "\n",
    "# ƒê·∫£m b·∫£o ch·ªâ gi·ªØ ƒë√∫ng c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "demo_df = demo_df[demo_df[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "\n",
    "# sanity checks\n",
    "print(\"Demo ‚Äî s·ªë hadm c√≥ demographics:\", demo_df[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(demo_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- Ch·ªâ t√≠nh cho c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán.\")\n",
    "print(\"- gender: M/F/U.\")\n",
    "print(\"- age_at_admit: tu·ªïi t·∫°i th·ªùi ƒëi·ªÉm nh·∫≠p vi·ªán (0‚Äì120, ki·ªÉu Int64).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96ea9683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCEDURE ‚Äî s·ªë hadm c√≥ th·ªß thu·∫≠t: 10000 / 10000\n",
      "‚úÖ ƒê√£ l∆∞u danh s√°ch Top 100 th·ªß thu·∫≠t: ../data/proc/top_procedures.csv\n",
      "‚úÖ ƒê√£ l∆∞u c·∫•u tr√∫c ph√¢n c·∫•p th·ªß thu·∫≠t: ../data/proc/top_procedure_hierarchy.csv\n",
      "T·ªïng s·ªë th·ªß thu·∫≠t (record-level): 30032\n",
      "T·ªïng s·ªë m√£ th·ªß thu·∫≠t kh√°c nhau: 3758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proc_block</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>389</td>\n",
       "      <td>1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5A1</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02H</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3E0</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>967</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>885</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0W9</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>372</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>451</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  proc_block  count\n",
       "0        389   1660\n",
       "1        5A1    819\n",
       "2        02H    795\n",
       "3        3E0    766\n",
       "4        004    615\n",
       "5        967    583\n",
       "6        885    571\n",
       "7        0W9    533\n",
       "8        372    505\n",
       "9        451    437"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>n_hadm</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001</td>\n",
       "      <td>0014</td>\n",
       "      <td>26</td>\n",
       "      <td>Injection or infusion of oxazolidinone class of antibiotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001</td>\n",
       "      <td>0015</td>\n",
       "      <td>25</td>\n",
       "      <td>High-dose infusion interleukin-2 [IL-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001</td>\n",
       "      <td>00163J6</td>\n",
       "      <td>6</td>\n",
       "      <td>Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001</td>\n",
       "      <td>0017</td>\n",
       "      <td>4</td>\n",
       "      <td>Infusion of vasopressor agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001</td>\n",
       "      <td>00160J6</td>\n",
       "      <td>2</td>\n",
       "      <td>Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Open Approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001</td>\n",
       "      <td>00164J6</td>\n",
       "      <td>2</td>\n",
       "      <td>Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Endoscopic Approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>001</td>\n",
       "      <td>0018</td>\n",
       "      <td>2</td>\n",
       "      <td>Infusion of immunosuppressive antibody therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>001</td>\n",
       "      <td>0012</td>\n",
       "      <td>1</td>\n",
       "      <td>Administration of inhaled nitric oxide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>002</td>\n",
       "      <td>0023</td>\n",
       "      <td>2</td>\n",
       "      <td>Intravascular imaging of peripheral vessels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>002</td>\n",
       "      <td>0024</td>\n",
       "      <td>1</td>\n",
       "      <td>Intravascular imaging of coronary vessels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  block icd_code  n_hadm                                                                                                  long_title\n",
       "0   001     0014      26                                                 Injection or infusion of oxazolidinone class of antibiotics\n",
       "1   001     0015      25                                                                     High-dose infusion interleukin-2 [IL-2]\n",
       "2   001  00163J6       6             Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Approach\n",
       "3   001     0017       4                                                                               Infusion of vasopressor agent\n",
       "4   001  00160J6       2                     Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Open Approach\n",
       "5   001  00164J6       2  Bypass Cerebral Ventricle to Peritoneal Cavity with Synthetic Substitute, Percutaneous Endoscopic Approach\n",
       "6   001     0018       2                                                              Infusion of immunosuppressive antibody therapy\n",
       "7   001     0012       1                                                                      Administration of inhaled nitric oxide\n",
       "8   002     0023       2                                                                 Intravascular imaging of peripheral vessels\n",
       "9   002     0024       1                                                                   Intravascular imaging of coronary vessels"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>proc_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001725</td>\n",
       "      <td>25563031</td>\n",
       "      <td>[705, 709, 869]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002167</td>\n",
       "      <td>29383904</td>\n",
       "      <td>[449, 537]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002557</td>\n",
       "      <td>20731670</td>\n",
       "      <td>[512, 875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002804</td>\n",
       "      <td>20769698</td>\n",
       "      <td>[790]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003731</td>\n",
       "      <td>23646008</td>\n",
       "      <td>[860]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id      proc_blocks\n",
       "0    10001725  25563031  [705, 709, 869]\n",
       "1    10002167  29383904       [449, 537]\n",
       "2    10002557  20731670       [512, 875]\n",
       "3    10002804  20769698            [790]\n",
       "4    10003731  23646008            [860]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch:\n",
      "- proc_df: d√πng cho merge ·ªü b∆∞·ªõc 5.\n",
      "- top_procedures.csv: th·ªëng k√™ t·∫ßn su·∫•t 3 k√Ω t·ª± ƒë·∫ßu (block).\n",
      "- top_procedure_hierarchy.csv: chi ti·∫øt t·ª´ng m√£ th·ªß thu·∫≠t con trong t·ª´ng block.\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# B∆Ø·ªöC 3 ‚Äî ƒê·ªåC TH·ª¶ THU·∫¨T (PROCEDURES ICD) & T·∫†O proc_df + C√ÅC FILE TH·ªêNG K√ä\n",
    "# ======================================================\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "proc_path = HOSP_DIR / \"procedures_icd.csv.gz\"\n",
    "\n",
    "proc_rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    proc_path,\n",
    "    usecols=[\"subject_id\", \"hadm_id\", \"icd_code\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # L√†m s·∫°ch c∆° b·∫£n v√† l·ªçc theo cohort\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # Chu·∫©n h√≥a v√† t√°ch block\n",
    "    chunk[\"icd_code\"] = chunk[\"icd_code\"].astype(str).str.replace(\".\", \"\", regex=False)\n",
    "    chunk[\"block\"] = chunk[\"icd_code\"].str[:3]\n",
    "    proc_rows.append(chunk[[\"subject_id\", \"hadm_id\", \"block\", \"icd_code\"]])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# H·ª¢P NH·∫§T C√ÅC CHUNK\n",
    "# ------------------------------------------------------\n",
    "if proc_rows:\n",
    "    proc_df_raw = pd.concat(proc_rows, ignore_index=True)\n",
    "else:\n",
    "    proc_df_raw = pd.DataFrame(columns=[\"subject_id\", \"hadm_id\", \"block\", \"icd_code\"])\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.1 ‚Äî GOM NH√ìM CHO M·ªñI L·∫¶N NH·∫¨P VI·ªÜN\n",
    "# ------------------------------------------------------\n",
    "proc_df = (\n",
    "    proc_df_raw\n",
    "    .groupby([\"subject_id\", \"hadm_id\"])[\"block\"]\n",
    "    .apply(lambda x: sorted({b for b in x if pd.notna(b)}))\n",
    "    .reset_index()\n",
    "    .rename(columns={\"block\": \"proc_blocks\"})\n",
    ")\n",
    "\n",
    "hadm_proc_n = proc_df[\"hadm_id\"].nunique()\n",
    "print(\"PROCEDURE ‚Äî s·ªë hadm c√≥ th·ªß thu·∫≠t:\", hadm_proc_n, \"/\", len(COHORT_HADM))\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.2 ‚Äî XU·∫§T TOP C√ÅC TH·ª¶ THU·∫¨T (BLOCK)\n",
    "# ------------------------------------------------------\n",
    "cnt_proc = Counter(proc_df_raw[\"block\"].dropna().astype(str))\n",
    "top_proc_df = (\n",
    "    pd.DataFrame(cnt_proc.items(), columns=[\"proc_block\", \"count\"])\n",
    "    .sort_values(\"count\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "TOP_PROCS = 100\n",
    "out_top_proc = PROC_DIR / \"top_procedures.csv\"\n",
    "top_proc_df.head(TOP_PROCS).to_csv(out_top_proc, index=False)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u danh s√°ch Top {TOP_PROCS} th·ªß thu·∫≠t:\", out_top_proc)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.3 ‚Äî T·∫†O FILE PH√ÇN C·∫§P (BLOCK ‚Üí M√É CHI TI·∫æT)\n",
    "# ------------------------------------------------------\n",
    "freq_detail = (\n",
    "    proc_df_raw\n",
    "    .groupby([\"block\", \"icd_code\"])[\"hadm_id\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"n_hadm\")\n",
    "    .sort_values([\"block\", \"n_hadm\"], ascending=[True, False])\n",
    ")\n",
    "\n",
    "# G·∫Øn m√¥ t·∫£ n·∫øu c√≥ dictionary\n",
    "proc_dict_path = HOSP_DIR / \"d_icd_procedures.csv.gz\"\n",
    "if proc_dict_path.exists():\n",
    "    d_proc = pd.read_csv(proc_dict_path, usecols=[\"icd_code\", \"long_title\"], compression=\"gzip\")\n",
    "    d_proc[\"icd_code\"] = d_proc[\"icd_code\"].astype(str).str.replace(\".\", \"\", regex=False)\n",
    "    freq_detail = freq_detail.merge(d_proc, on=\"icd_code\", how=\"left\")\n",
    "\n",
    "out_hierarchy = PROC_DIR / \"top_procedure_hierarchy.csv\"\n",
    "freq_detail.to_csv(out_hierarchy, index=False)\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u c·∫•u tr√∫c ph√¢n c·∫•p th·ªß thu·∫≠t:\", out_hierarchy)\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 3.4 ‚Äî KI·ªÇM TRA NHANH\n",
    "# ------------------------------------------------------\n",
    "print(\"T·ªïng s·ªë th·ªß thu·∫≠t (record-level):\", len(proc_df_raw))\n",
    "print(\"T·ªïng s·ªë m√£ th·ªß thu·∫≠t kh√°c nhau:\", proc_df_raw[\"icd_code\"].nunique())\n",
    "display(top_proc_df.head(10))\n",
    "display(freq_detail.head(10))\n",
    "display(proc_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch:\")\n",
    "print(\"- proc_df: d√πng cho merge ·ªü b∆∞·ªõc 5.\")\n",
    "print(\"- top_procedures.csv: th·ªëng k√™ t·∫ßn su·∫•t 3 k√Ω t·ª± ƒë·∫ßu (block).\")\n",
    "print(\"- top_procedure_hierarchy.csv: chi ti·∫øt t·ª´ng m√£ th·ªß thu·∫≠t con trong t·ª´ng block.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac404739",
   "metadata": {},
   "source": [
    "## 3) Nh√≥m x√©t nghi·ªám trong 6 gi·ªù ƒë·∫ßu (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**\n",
    "- X√¢y d·ª±ng nh√£n v·ªÅ **c√°c x√©t nghi·ªám ƒë∆∞·ª£c th·ª±c hi·ªán s·ªõm** (0‚Äì6 gi·ªù ƒë·∫ßu k·ªÉ t·ª´ `admittime`) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh g·ª£i √Ω c·∫≠n l√¢m s√†ng.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**\n",
    "- `labevents.csv.gz`: `hadm_id`, `itemid`, `charttime`  \n",
    "- `d_labitems.csv.gz`: `itemid` ‚Üí `label`  \n",
    "- `admissions_idx` (B∆∞·ªõc 1): tra c·ª©u `admittime` theo `hadm_id`  \n",
    "- **Ch·ªâ l·∫•y b·∫£n ghi c√≥ `hadm_id ‚àà COHORT_HADM`**. ƒê·ªçc theo `chunksize` ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "\n",
    "**X·ª≠ l√Ω (2 pass)**\n",
    "1) **ƒê·∫øm t·∫ßn su·∫•t** `itemid` trong 0‚Äì6h ƒë·ªÉ ch·ªçn `TOP_LABS` (vocab x√©t nghi·ªám s·ªõm ph·ªï bi·∫øn).  \n",
    "2) **G√°n nh√£n cho t·ª´ng ca**: v·ªõi m·ªói `hadm_id`, l·∫•y t·∫≠p h·ª£p `itemid` (thu·ªôc vocab) di·ªÖn ra trong 0‚Äì6h.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**\n",
    "- `lab_vocab_df`: b·∫£ng vocab x√©t nghi·ªám s·ªõm g·ªìm `itemid`, `label`, `count` (t·∫ßn su·∫•t).  \n",
    "- `lab_items_by_hadm`: cho *m·ªói* `hadm_id`, danh s√°ch duy nh·∫•t c√°c `itemid` (thu·ªôc vocab) xu·∫•t hi·ªán trong 0‚Äì6h.  \n",
    "- (Ti·ªán √≠ch) `itemid_to_label`: √°nh x·∫° `itemid ‚Üí label` ƒë·ªÉ hi·ªÉn th·ªã d·ªÖ ƒë·ªçc.\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**\n",
    "- `itemid`: m√£ x√©t nghi·ªám.  \n",
    "- `label`: t√™n x√©t nghi·ªám.  \n",
    "- `count`: s·ªë l·∫ßn xu·∫•t hi·ªán trong c·ª≠a s·ªï 0‚Äì6h (tr√™n to√†n cohort).  \n",
    "- `lab_items` (·ªü `lab_items_by_hadm`): danh s√°ch *duy nh·∫•t* c√°c `itemid` thu·ªôc vocab c·ªßa t·ª´ng ca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405b2d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë ph·∫ßn t·ª≠ vocab x√©t nghi·ªám (TOP_N): 20\n",
      "S·ªë ca c√≥ √≠t nh·∫•t m·ªôt x√©t nghi·ªám trong TOP_N: 9903 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50971</td>\n",
       "      <td>Potassium</td>\n",
       "      <td>80786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51221</td>\n",
       "      <td>Hematocrit</td>\n",
       "      <td>80010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50983</td>\n",
       "      <td>Sodium</td>\n",
       "      <td>79951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50902</td>\n",
       "      <td>Chloride</td>\n",
       "      <td>79311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50912</td>\n",
       "      <td>Creatinine</td>\n",
       "      <td>78161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51006</td>\n",
       "      <td>Urea Nitrogen</td>\n",
       "      <td>77558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50882</td>\n",
       "      <td>Bicarbonate</td>\n",
       "      <td>76837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50868</td>\n",
       "      <td>Anion Gap</td>\n",
       "      <td>76624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50931</td>\n",
       "      <td>Glucose</td>\n",
       "      <td>75701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>51265</td>\n",
       "      <td>Platelet Count</td>\n",
       "      <td>75390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid           label  count\n",
       "0   50971       Potassium  80786\n",
       "1   51221      Hematocrit  80010\n",
       "2   50983          Sodium  79951\n",
       "3   50902        Chloride  79311\n",
       "4   50912      Creatinine  78161\n",
       "5   51006   Urea Nitrogen  77558\n",
       "6   50882     Bicarbonate  76837\n",
       "7   50868       Anion Gap  76624\n",
       "8   50931         Glucose  75701\n",
       "9   51265  Platelet Count  75390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>lab_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20005070</td>\n",
       "      <td>[51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20005426</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20005473</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20006377</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20006679</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20007022</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20008580</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20015287</td>\n",
       "      <td>[50912, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20015766</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20015927</td>\n",
       "      <td>[50868, 50882, 50902, 50912, 50931, 50960, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  \\\n",
       "0  20005070   \n",
       "1  20005426   \n",
       "2  20005473   \n",
       "3  20006377   \n",
       "4  20006679   \n",
       "5  20007022   \n",
       "6  20008580   \n",
       "7  20015287   \n",
       "8  20015766   \n",
       "9  20015927   \n",
       "\n",
       "                                                                                                                                      lab_items  \n",
       "0                                                                               [51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "1  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "2  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "3  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "4  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "5  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "6  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "7                                                                 [50912, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "8  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  \n",
       "9                [50868, 50882, 50902, 50912, 50931, 50960, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u danh s√°ch Top Labs: ../data/proc/top_lab_items.csv\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 4: L·∫•y x√©t nghi·ªám Top-N theo t·∫ßn su·∫•t (to√†n b·ªô th·ªùi gian nh·∫≠p vi·ªán) ---\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "labs_path = HOSP_DIR / \"labevents.csv.gz\"\n",
    "dlab_path = HOSP_DIR / \"d_labitems.csv.gz\"\n",
    "\n",
    "# 4.1 ƒê·ªçc dictionary lab: itemid -> label\n",
    "dlab = pd.read_csv(dlab_path, usecols=[\"itemid\", \"label\"], compression=\"gzip\")\n",
    "dlab[\"itemid\"] = dlab[\"itemid\"].astype(int)\n",
    "dlab[\"label\"] = dlab[\"label\"].astype(str)\n",
    "\n",
    "# 4.2 Pass 1 ‚Äî ƒê·∫øm t·∫ßn su·∫•t itemid trong to√†n b·ªô cohort\n",
    "cnt = Counter()\n",
    "\n",
    "for chunk in read_csv_chunks(\n",
    "    labs_path,\n",
    "    usecols=[\"hadm_id\", \"itemid\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "    chunk[\"itemid\"]  = chunk[\"itemid\"].astype(int)\n",
    "    # Ch·ªâ l·∫•y c√°c l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "    cnt.update(chunk[\"itemid\"].value_counts().to_dict())\n",
    "\n",
    "# T√≠nh t·∫ßn su·∫•t\n",
    "counts_df = (\n",
    "    pd.DataFrame(list(cnt.items()), columns=[\"itemid\", \"count\"])\n",
    "    if cnt else pd.DataFrame(columns=[\"itemid\", \"count\"])\n",
    ")\n",
    "counts_df = counts_df.sort_values([\"count\", \"itemid\"], ascending=[False, True])\n",
    "top_items = counts_df.head(TOP_LABS)[\"itemid\"].astype(int).tolist()\n",
    "\n",
    "lab_vocab_df = (\n",
    "    counts_df[counts_df[\"itemid\"].isin(top_items)]\n",
    "    .merge(dlab, on=\"itemid\", how=\"left\")\n",
    "    [[\"itemid\", \"label\", \"count\"]]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 4.3 Pass 2 ‚Äî G√°n danh s√°ch x√©t nghi·ªám theo hadm_id (kh√¥ng gi·ªõi h·∫°n th·ªùi gian)\n",
    "lab_rows = []\n",
    "\n",
    "if len(top_items) > 0:\n",
    "    for chunk in read_csv_chunks(\n",
    "        labs_path,\n",
    "        usecols=[\"hadm_id\", \"itemid\"],\n",
    "        chunksize=CHUNKSIZE_DEFAULT,\n",
    "    ):\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"]).copy()\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "        chunk[\"itemid\"]  = chunk[\"itemid\"].astype(int)\n",
    "        chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        early_top = chunk[chunk[\"itemid\"].isin(top_items)]\n",
    "        if not early_top.empty:\n",
    "            lab_rows.append(early_top[[\"hadm_id\", \"itemid\"]])\n",
    "\n",
    "if lab_rows:\n",
    "    labs_concat = pd.concat(lab_rows, ignore_index=True)\n",
    "    lab_items_by_hadm = (\n",
    "        labs_concat\n",
    "        .groupby(\"hadm_id\")[\"itemid\"]\n",
    "        .apply(lambda s: sorted(set(s.tolist())))\n",
    "        .reset_index()\n",
    "        .rename(columns={\"itemid\": \"lab_items\"})\n",
    "    )\n",
    "else:\n",
    "    lab_items_by_hadm = pd.DataFrame(columns=[\"hadm_id\", \"lab_items\"])\n",
    "\n",
    "# √Ånh x·∫° itemid -> label (ƒë·ªÉ hi·ªÉn th·ªã d·ªÖ hi·ªÉu h∆°n)\n",
    "itemid_to_label = dict(zip(lab_vocab_df[\"itemid\"], lab_vocab_df[\"label\"]))\n",
    "\n",
    "# B√°o c√°o nhanh\n",
    "print(\"S·ªë ph·∫ßn t·ª≠ vocab x√©t nghi·ªám (TOP_N):\", len(lab_vocab_df))\n",
    "print(\"S·ªë ca c√≥ √≠t nh·∫•t m·ªôt x√©t nghi·ªám trong TOP_N:\", lab_items_by_hadm[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(lab_vocab_df.head(10))\n",
    "display(lab_items_by_hadm.head(10))\n",
    "\n",
    "# 4.4 L∆∞u danh s√°ch Top Labs\n",
    "out_top_labs = PROC_DIR / \"top_lab_items.csv\"\n",
    "lab_vocab_df.to_csv(out_top_labs, index=False)\n",
    "print(\"ƒê√£ l∆∞u danh s√°ch Top Labs:\", out_top_labs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb92b8b",
   "metadata": {},
   "source": [
    "## 4) Ghi ch√∫ Radiology trong 12 gi·ªù ƒë·∫ßu (l·ªçc theo COHORT, ƒë·ªçc theo `chunksize`)\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- L·∫•y **ghi ch√∫ radiology s·ªõm nh·∫•t** trong **0‚Äì12 gi·ªù** k·ªÉ t·ª´ `admittime` cho m·ªói `hadm_id` trong **COHORT_HADM**, l√†m ƒë·∫ßu v√†o m√¥ h√¨nh text‚Üílabel.\n",
    "\n",
    "**D·ªØ li·ªáu ƒë·∫ßu v√†o & r√†ng bu·ªôc**  \n",
    "- `radiology.csv.gz`: `hadm_id`, `charttime`, `text`  \n",
    "- `admissions_idx` (B∆∞·ªõc 1): tra c·ª©u `admittime` theo `hadm_id`  \n",
    "- **Ch·ªâ l·∫•y b·∫£n ghi c√≥ `hadm_id ‚àà COHORT_HADM`**. ƒê·ªçc theo `chunksize` ƒë·ªÉ ti·∫øt ki·ªám RAM.\n",
    "\n",
    "**X·ª≠ l√Ω**  \n",
    "1) ƒê·ªçc radiology theo `chunksize`, l·ªçc theo `COHORT_HADM`.  \n",
    "2) Join `admittime` t·ª´ `admissions_idx`, t√≠nh \\(\\Delta t\\) (gi·ªù).  \n",
    "3) Gi·ªØ c√°c ghi ch√∫ c√≥ \\(0 \\le \\Delta t \\le 12\\).  \n",
    "4) `normalize_text` n·ªôi dung v√† **ch·ªçn ghi ch√∫ s·ªõm nh·∫•t** (nh·ªè nh·∫•t `charttime`) cho m·ªói `hadm_id`.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- `text_df`: DataFrame g·ªìm `hadm_id`, `text` (radiology note s·ªõm nh·∫•t trong 12h, ƒë√£ chu·∫©n ho√°).\n",
    "\n",
    "**√ù nghƒ©a tr∆∞·ªùng trong k·∫øt qu·∫£**  \n",
    "- `hadm_id`: m√£ l·∫ßn nh·∫≠p vi·ªán (kh√≥a ch√≠nh ƒë·ªÉ join).  \n",
    "- `text`: vƒÉn b·∫£n ghi ch√∫ radiology ƒë·∫ßu ti√™n trong 12h ƒë·∫ßu, ƒë√£ l√†m s·∫°ch ƒë·ªÉ s·∫µn s√†ng tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d5081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discharge ‚Äî s·ªë hadm c√≥ ghi ch√∫ xu·∫•t vi·ªán: 10000 / 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20005070</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Patient recorded as having No Known Allergies to Drugs Att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20005426</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: NEUROLOGY Allergies: Penicillins / Amoxicillin / Banana Attending: ___ Chief C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20005473</td>\n",
       "      <td>Name: ___. Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: NEUROSURGERY Allergies: No Known Allergies / Adverse Drug Reactions Attending...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20006377</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Morphine / Oxycodone / Iodine-Iodine Containing / Percodan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20006679</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: SURGERY Allergies: aspirin / NSAIDS (Non-Steroidal Anti-Inflammatory Drug) / a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hadm_id  \\\n",
       "0  20005070   \n",
       "1  20005426   \n",
       "2  20005473   \n",
       "3  20006377   \n",
       "4  20006679   \n",
       "\n",
       "                                                                                                                                                                                  text  \n",
       "0  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Patient recorded as having No Known Allergies to Drugs Att...  \n",
       "1  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: NEUROLOGY Allergies: Penicillins / Amoxicillin / Banana Attending: ___ Chief C...  \n",
       "2  Name: ___. Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: NEUROSURGERY Allergies: No Known Allergies / Adverse Drug Reactions Attending...  \n",
       "3  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: MEDICINE Allergies: Morphine / Oxycodone / Iodine-Iodine Containing / Percodan...  \n",
       "4  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: M Service: SURGERY Allergies: aspirin / NSAIDS (Non-Steroidal Anti-Inflammatory Drug) / a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gi·∫£i th√≠ch k·∫øt qu·∫£:\n",
      "- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (tr√πng kh√≥a chu·∫©n).\n",
      "- text: n·ªôi dung ghi ch√∫ xu·∫•t vi·ªán m·ªõi nh·∫•t c·ªßa m·ªói ca nh·∫≠p vi·ªán, ƒë√£ chu·∫©n h√≥a.\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 5: L·∫•y ghi ch√∫ xu·∫•t vi·ªán (Discharge Summary) ---\n",
    "import pandas as pd\n",
    "\n",
    "dis_path = NOTE_DIR / \"discharge.csv.gz\"\n",
    "\n",
    "rows = []\n",
    "for chunk in read_csv_chunks(\n",
    "    dis_path,\n",
    "    usecols=[\"hadm_id\", \"charttime\", \"text\"],\n",
    "    chunksize=CHUNKSIZE_DEFAULT,\n",
    "):\n",
    "    # Gi·ªØ l·∫°i b·∫£n ghi h·ª£p l·ªá\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"charttime\", \"text\"]).copy()\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    chunk[\"hadm_id\"] = chunk[\"hadm_id\"].astype(int)\n",
    "\n",
    "    # Ch·ªâ gi·ªØ nh·ªØng ca c√≥ trong cohort (c√≥ note xu·∫•t vi·ªán)\n",
    "    chunk = chunk[chunk[\"hadm_id\"].isin(COHORT_HADM)]\n",
    "    if chunk.empty:\n",
    "        continue\n",
    "\n",
    "    # Chu·∫©n h√≥a vƒÉn b·∫£n\n",
    "    chunk[\"charttime\"] = pd.to_datetime(chunk[\"charttime\"], errors=\"coerce\")\n",
    "    chunk[\"text\"] = chunk[\"text\"].map(normalize_text)\n",
    "\n",
    "    rows.append(chunk[[\"hadm_id\", \"charttime\", \"text\"]])\n",
    "\n",
    "# G·ªôp to√†n b·ªô\n",
    "if rows:\n",
    "    dis_all = pd.concat(rows, ignore_index=True)\n",
    "    # Ch·ªçn b·∫£n ghi discharge m·ªõi nh·∫•t cho m·ªói hadm_id\n",
    "    dis_all = dis_all.sort_values([\"hadm_id\", \"charttime\"], ascending=[True, False])\n",
    "    text_df = (\n",
    "        dis_all.groupby(\"hadm_id\", as_index=False)[\"text\"]\n",
    "        .first()\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "else:\n",
    "    text_df = pd.DataFrame(columns=[\"hadm_id\", \"text\"])\n",
    "\n",
    "# B√°o c√°o k·∫øt qu·∫£\n",
    "print(\"Discharge ‚Äî s·ªë hadm c√≥ ghi ch√∫ xu·∫•t vi·ªán:\", text_df[\"hadm_id\"].nunique(), \"/\", len(COHORT_HADM))\n",
    "display(text_df.head())\n",
    "\n",
    "print(\"Gi·∫£i th√≠ch k·∫øt qu·∫£:\")\n",
    "print(\"- hadm_id: m√£ l·∫ßn nh·∫≠p vi·ªán (tr√πng kh√≥a chu·∫©n).\")\n",
    "print(\"- text: n·ªôi dung ghi ch√∫ xu·∫•t vi·ªán m·ªõi nh·∫•t c·ªßa m·ªói ca nh·∫≠p vi·ªán, ƒë√£ chu·∫©n h√≥a.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5328929e",
   "metadata": {},
   "source": [
    "## 5) Gh√©p d·ªØ li·ªáu & sinh nh√£n ƒëa nh√£n (multi-hot) ‚Äî **theo COHORT**\n",
    "\n",
    "**M·ª•c ƒë√≠ch**  \n",
    "- Gom c√°c ph·∫ßn: **ICD-block** (B∆∞·ªõc 2), **lab s·ªõm 0‚Äì6h** (B∆∞·ªõc 3), **radiology 0‚Äì12h** (B∆∞·ªõc 4), **demographics** (B∆∞·ªõc 2.5) th√†nh **m·ªôt b·∫£ng m·∫´u/nh√£n** d√πng cho hu·∫•n luy·ªán.\n",
    "\n",
    "**Kh√≥a n·ªëi & ƒë·∫ßu v√†o**  \n",
    "- N·ªëi theo `hadm_id` gi·ªØa `icd_df`, `lab_items_by_hadm`, `text_df`.  \n",
    "- Th√™m demographics t·ª´ `demo_df` theo c·∫∑p kh√≥a `[hadm_id, subject_id]`.\n",
    "\n",
    "**X·ª≠ l√Ω**  \n",
    "1) Chu·∫©n h√≥a c√°c c·ªôt list/text/demographics.  \n",
    "2) T·∫°o **vocabulary**:  \n",
    "   ‚Ä¢ `icd_vocab`: danh s√°ch ICD-block ph·ªï bi·∫øn (gi·ªõi h·∫°n b·ªüi `ICD_MAX`).  \n",
    "   ‚Ä¢ `lab_vocab_items`: ch√≠nh l√† Top-N ·ªü B∆∞·ªõc 3 (gi·ªØ nguy√™n th·ª© t·ª±).  \n",
    "3) Sinh vector **multi-hot** cho m·ªói h√†ng: `y_icd`, `y_lab`.\n",
    "\n",
    "**K·∫øt qu·∫£ mong ƒë·ª£i**  \n",
    "- DataFrame `df_out` g·ªìm: `hadm_id`, `subject_id`, `gender`, `age_at_admit`, `text`, `icd_blocks`, `lab_items`, `y_icd`, `y_lab`.  \n",
    "- Ghi file:  \n",
    "  ‚Ä¢ `examples.parquet`  \n",
    "  ‚Ä¢ `vocab_meta.json` (l∆∞u vocab & mapping `itemid‚Üílabel`).\n",
    "\n",
    "**√ù nghƒ©a c√°c tr∆∞·ªùng ch√≠nh**  \n",
    "- `icd_blocks`: danh s√°ch ICD-block (3 k√Ω t·ª±).  \n",
    "- `lab_items`: danh s√°ch *duy nh·∫•t* c√°c `itemid` thu·ªôc vocab xu·∫•t hi·ªán trong 0‚Äì6h.  \n",
    "- `y_icd`/`y_lab`: vector multi-hot t∆∞∆°ng ·ª©ng v·ªõi `icd_vocab`/`lab_vocab_items`.  \n",
    "- `gender` (`M/F/U`), `age_at_admit` (0‚Äì120, `Int64`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e1d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K√≠ch th∆∞·ªõc vocab ICD: 20\n",
      "K√≠ch th∆∞·ªõc vocab Proc: 20\n",
      "K√≠ch th∆∞·ªõc vocab Lab (Top-N): 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id_x</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_blocks</th>\n",
       "      <th>subject_id_y</th>\n",
       "      <th>proc_blocks</th>\n",
       "      <th>lab_items</th>\n",
       "      <th>text</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_at_admit</th>\n",
       "      <th>y_icd</th>\n",
       "      <th>y_lab</th>\n",
       "      <th>y_proc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001725</td>\n",
       "      <td>25563031</td>\n",
       "      <td>[300, 311, 314, 333, 457, 493, 530, 564, 618, 729, 780, 788, 995, E93, V10, V15]</td>\n",
       "      <td>10001725</td>\n",
       "      <td>[705, 709, 869]</td>\n",
       "      <td>[50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]</td>\n",
       "      <td>Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: OBSTETRICS/GYNECOLOGY Allergies: Codeine / gabapentin / morphine / Amoxicillin...</td>\n",
       "      <td>10001725</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id_x   hadm_id                                                                        icd_blocks  subject_id_y  \\\n",
       "0      10001725  25563031  [300, 311, 314, 333, 457, 493, 530, 564, 618, 729, 780, 788, 995, E93, V10, V15]      10001725   \n",
       "\n",
       "       proc_blocks  \\\n",
       "0  [705, 709, 869]   \n",
       "\n",
       "                                                                                                                                      lab_items  \\\n",
       "0  [50868, 50882, 50893, 50902, 50912, 50931, 50960, 50970, 50971, 50983, 51006, 51221, 51222, 51248, 51249, 51250, 51265, 51277, 51279, 51301]   \n",
       "\n",
       "                                                                                                                                                                                  text  \\\n",
       "0  Name: ___ Unit No: ___ Admission Date: ___ Discharge Date: ___ Date of Birth: ___ Sex: F Service: OBSTETRICS/GYNECOLOGY Allergies: Codeine / gabapentin / morphine / Amoxicillin...   \n",
       "\n",
       "   subject_id gender  age_at_admit                                                         y_icd  \\\n",
       "0    10001725      F            46  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]   \n",
       "\n",
       "                                                          y_lab                                                        y_proc  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£t nh·∫≠p vi·ªán kh√¥ng c√≥ th·ªß thu·∫≠t: 4694 / 10000\n",
      "ƒê√£ l∆∞u (ch·ªâ c√°c HADM c√≥ note):\n",
      "- ../data/proc/examples.parquet\n",
      "- ../data/proc/vocab_meta.json\n"
     ]
    }
   ],
   "source": [
    "# --- B∆∞·ªõc 5: Merge & sinh nh√£n multi-hot (g·ªìm ICD + Lab + Procedure) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "# 5.1 Gh√©p theo hadm_id\n",
    "df = (\n",
    "    icd_df\n",
    "    .merge(proc_df,             on=\"hadm_id\", how=\"left\")   # ‚¨ÖÔ∏è th√™m th·ªß thu·∫≠t\n",
    "    .merge(lab_items_by_hadm,  on=\"hadm_id\", how=\"left\")\n",
    "    .merge(text_df,             on=\"hadm_id\", how=\"left\")\n",
    "    .merge(demo_df,             on=\"hadm_id\", how=\"left\")   # ‚¨ÖÔ∏è s·ª≠a ·ªü ƒë√¢y\n",
    ")\n",
    "\n",
    "# 5.2 Chu·∫©n ho√° c√°c c·ªôt\n",
    "df[\"icd_blocks\"] = df[\"icd_blocks\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"proc_blocks\"] = df[\"proc_blocks\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"lab_items\"]  = df[\"lab_items\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df[\"text\"]       = df[\"text\"].fillna(\"\")\n",
    "df[\"gender\"]     = df[\"gender\"].fillna(\"U\").astype(str).str.upper().str[0]\n",
    "df[\"age_at_admit\"] = df[\"age_at_admit\"].astype(\"Int64\")\n",
    "\n",
    "# Ch·ªâ gi·ªØ l·∫ßn nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán\n",
    "df[\"text\"] = df[\"text\"].str.strip()\n",
    "df = df[df[\"text\"].str.len() > 0].copy()\n",
    "\n",
    "# 5.3 Vocabulary\n",
    "cnt_icd = Counter(b for blocks in df[\"icd_blocks\"] for b in blocks)\n",
    "icd_vocab = [b for b, _ in cnt_icd.most_common(TOP_ICD)]\n",
    "icd_index = {b: i for i, b in enumerate(icd_vocab)}\n",
    "\n",
    "cnt_proc = Counter(p for ps in df[\"proc_blocks\"] for p in ps if pd.notna(p))\n",
    "proc_vocab = [p for p, _ in cnt_proc.most_common(TOP_ICD)]\n",
    "proc_index = {p: i for i, p in enumerate(proc_vocab)}\n",
    "\n",
    "lab_vocab_items = lab_vocab_df[\"itemid\"].astype(int).tolist()\n",
    "lab_index = {it: i for i, it in enumerate(lab_vocab_items)}\n",
    "\n",
    "# 5.4 Multi-hot\n",
    "def to_multihot_generic(labels, index_map, length):\n",
    "    arr = np.zeros(length, dtype=np.int8)\n",
    "    for t in labels:\n",
    "        if t in index_map:\n",
    "            arr[index_map[t]] = 1\n",
    "    return arr\n",
    "\n",
    "df[\"y_icd\"]  = df[\"icd_blocks\"].apply(lambda xs: to_multihot_generic(xs, icd_index, len(icd_vocab)))\n",
    "df[\"y_lab\"]  = df[\"lab_items\"].apply(lambda xs: to_multihot_generic(xs, lab_index, len(lab_vocab_items)))\n",
    "df[\"y_proc\"] = df[\"proc_blocks\"].apply(lambda xs: to_multihot_generic(xs, proc_index, len(proc_vocab)))\n",
    "\n",
    "# 5.5 √Ånh x·∫° itemid -> label (lab)\n",
    "itemid_to_label = dict(zip(lab_vocab_df[\"itemid\"].astype(int), lab_vocab_df[\"label\"].astype(str)))\n",
    "\n",
    "print(\"K√≠ch th∆∞·ªõc vocab ICD:\", len(icd_vocab))\n",
    "print(\"K√≠ch th∆∞·ªõc vocab Proc:\", len(proc_vocab))\n",
    "print(\"K√≠ch th∆∞·ªõc vocab Lab (Top-N):\", len(lab_vocab_items))\n",
    "display(df.head(1))\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ to√†n b·ªô y_proc = 0\n",
    "n_no_proc = (df[\"y_proc\"].apply(lambda a: np.sum(a) == 0)).sum()\n",
    "print(\"S·ªë l∆∞·ª£t nh·∫≠p vi·ªán kh√¥ng c√≥ th·ªß thu·∫≠t:\", n_no_proc, \"/\", len(df))\n",
    "\n",
    "\n",
    "# 5.6 L∆∞u ra ƒëƒ©a\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_examples = PROC_DIR / \"examples.parquet\"\n",
    "df_out = df[[\n",
    "    \"hadm_id\", \"subject_id\", \"gender\", \"age_at_admit\",\n",
    "    \"text\", \"icd_blocks\", \"proc_blocks\", \"lab_items\",\n",
    "    \"y_icd\", \"y_proc\", \"y_lab\"\n",
    "]].copy()\n",
    "df_out.to_parquet(out_examples, index=False)\n",
    "\n",
    "out_vocab = PROC_DIR / \"vocab_meta.json\"\n",
    "with open(out_vocab, \"w\") as f:\n",
    "    json.dump({\n",
    "        \"icd_vocab\": icd_vocab,\n",
    "        \"n_icd\": len(icd_vocab),\n",
    "        \"proc_vocab\": proc_vocab,\n",
    "        \"n_proc\": len(proc_vocab),\n",
    "        \"lab_vocab_items\": lab_vocab_items,\n",
    "        \"n_lab\": len(lab_vocab_items),\n",
    "        \"itemid_to_label\": {int(k): str(v) for k, v in itemid_to_label.items()}\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"ƒê√£ l∆∞u (ch·ªâ c√°c HADM c√≥ note):\")\n",
    "print(\"-\", out_examples)\n",
    "print(\"-\", out_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e6e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra 5 m·∫´u c√≥ lab_items KH√îNG r·ªóng (v√† y_lab c√≥ √≠t nh·∫•t 1 nh√£n)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def has_lab_items(x):\n",
    "    return isinstance(x, (list, tuple)) and len(x) > 0\n",
    "\n",
    "def has_y_lab(x):\n",
    "    try:\n",
    "        return np.asarray(x).sum() > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# N·∫øu b·∫°n ƒë√£ l∆∞u ra df_out (·ªü B∆∞·ªõc 5), th√¨ ƒë·ªçc l·∫°i; c√≤n n·∫øu ƒëang c√≥ bi·∫øn df th√¨ d√πng df\n",
    "try:\n",
    "    _ = df\n",
    "    frame = df\n",
    "except NameError:\n",
    "    frame = pd.read_parquet(PROC_DIR / \"examples.parquet\")\n",
    "\n",
    "mask_items = frame[\"lab_items\"].apply(has_lab_items)\n",
    "mask_y     = frame[\"y_lab\"].apply(has_y_lab)\n",
    "\n",
    "nonempty_lab = frame[mask_items].copy()\n",
    "print(f\"S·ªë ca c√≥ lab_items kh√¥ng r·ªóng: {len(nonempty_lab)} / {len(frame)} \"\n",
    "      f\"({len(nonempty_lab)/len(frame):.1%})\")\n",
    "\n",
    "nonempty_both = frame[mask_items & mask_y].copy()\n",
    "print(f\"S·ªë ca c√≥ lab_items‚â†‚àÖ v√† y_lab>0: {len(nonempty_both)}\")\n",
    "\n",
    "# L·∫•y ng·∫´u nhi√™n 5 m·∫´u ƒë·ªÉ xem chi ti·∫øt\n",
    "sample_n = min(5, len(nonempty_lab))\n",
    "sample_rows = nonempty_lab.sample(sample_n, random_state=42) if sample_n > 0 else nonempty_lab.head(0)\n",
    "\n",
    "cols_show = [\"subject_id\", \"hadm_id\", \"gender\", \"age_at_admit\", \"icd_blocks\", \"lab_items\", \"text\"]\n",
    "display(sample_rows[cols_show])\n",
    "\n",
    "# (Tu·ª≥ ch·ªçn) In k√®m t·ªïng s·ªë nh√£n lab ƒë∆∞·ª£c b·∫≠t ƒë·ªÉ x√°c nh·∫≠n kh·ªõp y_lab\n",
    "if sample_n > 0:\n",
    "    tmp = sample_rows.copy()\n",
    "    tmp[\"y_lab_sum\"] = tmp[\"y_lab\"].apply(lambda a: int(np.asarray(a).sum()) if isinstance(a, (list,np.ndarray)) else 0)\n",
    "    display(tmp[[\"hadm_id\", \"lab_items\", \"y_lab_sum\"]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
