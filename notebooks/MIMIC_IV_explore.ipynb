{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c384a54",
   "metadata": {},
   "source": [
    "\n",
    "# üîç Kh√°m ph√° d·ªØ li·ªáu MIMIC‚ÄëIV (ƒë·ªçc nh·∫π, kh√¥ng gi·∫£i n√©n to√†n b·ªô)\n",
    "Notebook n√†y gi√∫p b·∫°n **xem nhanh** v√† **duy·ªát theo t·ª´ng ph·∫ßn** c√°c file `.csv.gz` c·ª±c l·ªõn c·ªßa MIMIC‚ÄëIV / MIMIC‚ÄëIV‚ÄëNote **m√† kh√¥ng c·∫ßn gi·∫£i n√©n**, ƒë·ªÉ tr√°nh ƒë·∫ßy b·ªô nh·ªõ.\n",
    "\n",
    "**B·∫°n c√≥ th·ªÉ:**\n",
    "- Xem v√†i d√≤ng ƒë·∫ßu (`nrows`) c·ªßa t·ª´ng b·∫£ng.\n",
    "- ƒê·ªçc theo **chunk** nh·ªè (t·ª´ng l√¥ 5k‚Äì50k d√≤ng) ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu.\n",
    "- L·∫•y **m·∫´u ng·∫´u nhi√™n** m·ªôt s·ªë d√≤ng t·ª´ file c·ª±c l·ªõn (b·∫±ng *reservoir sampling* tr√™n c√°c chunk).\n",
    "\n",
    "> üí° Ph√π h·ª£p cho MacBook Air M2 / m√°y RAM th·∫•p.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef611722",
   "metadata": {},
   "source": [
    "\n",
    "## 0) C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu\n",
    "ƒêi·ªÅn ƒë√∫ng th∆∞ m·ª•c g·ªëc ch·ª©a 2 c√¢y th∆∞ m·ª•c sau (theo b·∫°n cung c·∫•p):\n",
    "\n",
    "```\n",
    "data/\n",
    "‚îú‚îÄ‚îÄ mimic-iv-note/2.2/note/*.csv(.gz)\n",
    "‚îî‚îÄ‚îÄ mimiciv/3.1/{hosp,icu}/*.csv.gz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40081bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªìn t·∫°i: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimiciv/3.1/hosp -> True\n",
      "T·ªìn t·∫°i: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimiciv/3.1/icu -> True\n",
      "T·ªìn t·∫°i: /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/mimic-iv-note/2.2/note -> True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# L√πi m·ªôt c·∫•p ra kh·ªèi notebooks/, r·ªìi v√†o data/\n",
    "DATA_ROOT = Path(\"..\") / \"data\"\n",
    "\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "ICU_DIR  = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"icu\"\n",
    "NOTE_DIR = DATA_ROOT / \"mimic-iv-note\" / \"2.2\" / \"note\"\n",
    "\n",
    "for p in [HOSP_DIR, ICU_DIR, NOTE_DIR]:\n",
    "    print(f\"T·ªìn t·∫°i: {p.resolve()} ->\", p.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9aae7c",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Li·ªát k√™ nhanh c√°c file `.csv.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58696520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ HOSP:\n",
      "‚Ä¢ admissions.csv.gz\n",
      "‚Ä¢ d_hcpcs.csv.gz\n",
      "‚Ä¢ d_icd_diagnoses.csv.gz\n",
      "‚Ä¢ d_icd_procedures.csv.gz\n",
      "‚Ä¢ d_labitems.csv.gz\n",
      "‚Ä¢ diagnoses_icd.csv.gz\n",
      "‚Ä¢ drgcodes.csv.gz\n",
      "‚Ä¢ emar.csv.gz\n",
      "‚Ä¢ emar_detail.csv.gz\n",
      "‚Ä¢ hcpcsevents.csv.gz\n",
      "‚Ä¢ labevents.csv.gz\n",
      "‚Ä¢ microbiologyevents.csv.gz\n",
      "‚Ä¢ omr.csv.gz\n",
      "‚Ä¢ patients.csv.gz\n",
      "‚Ä¢ pharmacy.csv.gz\n",
      "‚Ä¢ poe.csv.gz\n",
      "‚Ä¢ poe_detail.csv.gz\n",
      "‚Ä¢ prescriptions.csv.gz\n",
      "‚Ä¢ procedures_icd.csv.gz\n",
      "‚Ä¢ provider.csv.gz\n",
      "‚Ä¢ services.csv.gz\n",
      "‚Ä¢ transfers.csv.gz\n",
      "\n",
      "üìÇ ICU:\n",
      "‚Ä¢ caregiver.csv.gz\n",
      "‚Ä¢ chartevents.csv.gz\n",
      "‚Ä¢ d_items.csv.gz\n",
      "‚Ä¢ datetimeevents.csv.gz\n",
      "‚Ä¢ icustays.csv.gz\n",
      "‚Ä¢ ingredientevents.csv.gz\n",
      "‚Ä¢ inputevents.csv.gz\n",
      "‚Ä¢ outputevents.csv.gz\n",
      "‚Ä¢ procedureevents.csv.gz\n",
      "\n",
      "üìÇ NOTE:\n",
      "‚Ä¢ discharge.csv.gz\n",
      "‚Ä¢ discharge_detail.csv.gz\n",
      "‚Ä¢ radiology.csv.gz\n",
      "‚Ä¢ radiology_detail.csv.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "def list_gz(dir_path):\n",
    "    files = sorted(glob.glob(str(dir_path / \"*.csv.gz\")))\n",
    "    for f in files:\n",
    "        print(\"‚Ä¢\", Path(f).name)\n",
    "    return files\n",
    "\n",
    "print(\"üìÇ HOSP:\")\n",
    "_ = list_gz(HOSP_DIR)\n",
    "print(\"\\nüìÇ ICU:\")\n",
    "_ = list_gz(ICU_DIR)\n",
    "print(\"\\nüìÇ NOTE:\")\n",
    "_ = list_gz(NOTE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0f867",
   "metadata": {},
   "source": [
    "\n",
    "## 2) H√†m ti·ªán √≠ch ƒë·ªçc **nh·∫π** (kh√¥ng gi·∫£i n√©n to√†n b·ªô)\n",
    "- `preview_csv(path, nrows)`: xem **n d√≤ng ƒë·∫ßu** tr·ª±c ti·∫øp t·ª´ `.csv.gz`  \n",
    "- `read_in_chunks(path, chunksize)`: duy·ªát **t·ª´ng chunk** ƒë·ªÉ ki·ªÉm tra c·∫•u tr√∫c/gi√° tr·ªã  \n",
    "- `show_columns(path)`: ch·ªâ ƒë·ªçc **1 d√≤ng** ƒë·ªÉ l·∫•y **t√™n c·ªôt**\n",
    "- `sample_rows(path, k, chunksize)`: **l·∫•y m·∫´u ng·∫´u nhi√™n** `k` d√≤ng t·ª´ file r·∫•t l·ªõn (reservoir sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47604e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def preview_csv(path, nrows=5):\n",
    "    df = pd.read_csv(path, compression=\"gzip\", nrows=nrows, low_memory=False)\n",
    "    print(f\"üìÑ {path} ‚Äî hi·ªÉn th·ªã {nrows} d√≤ng ƒë·∫ßu:\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def read_in_chunks(path, chunksize=10000, max_chunks=2, head_each=3):\n",
    "    i = 0\n",
    "    for chunk in pd.read_csv(path, compression=\"gzip\", chunksize=chunksize, low_memory=False):\n",
    "        print(f\"üîπ Chunk {i} (kho·∫£ng {len(chunk)} d√≤ng) ‚Äî xem {head_each} d√≤ng ƒë·∫ßu:\")\n",
    "        display(chunk.head(head_each))\n",
    "        i += 1\n",
    "        if i >= max_chunks:\n",
    "            break\n",
    "\n",
    "def show_columns(path):\n",
    "    df = pd.read_csv(path, compression=\"gzip\", nrows=1, low_memory=False)\n",
    "    print(f\"üìë C·ªôt trong {path}:\")\n",
    "    print(list(df.columns))\n",
    "    return df.columns.tolist()\n",
    "\n",
    "def sample_rows(path, k=1000, chunksize=50000, random_state=42):\n",
    "    \"\"\"Reservoir sampling cho file c·ª±c l·ªõn: ch·ªçn ng·∫´u nhi√™n k d√≤ng m√† kh√¥ng c·∫ßn load to√†n b·ªô.\"\"\"\n",
    "    random.seed(random_state)\n",
    "    reservoir = None\n",
    "    total = 0\n",
    "    for chunk in pd.read_csv(path, compression=\"gzip\", chunksize=chunksize, low_memory=False):\n",
    "        # l·∫•y ng·∫´u nhi√™n c√°c index trong chunk ƒë·ªÉ th√™m v√†o reservoir\n",
    "        if reservoir is None:\n",
    "            reservoir = chunk.sample(min(k, len(chunk)), random_state=random_state)\n",
    "        else:\n",
    "            m = len(chunk)\n",
    "            take = min(k, m)\n",
    "            # v·ªõi m·ªói h√†ng c·ªßa chunk, x√°c su·∫•t gi·ªØ l·∫°i ~ k/(total + i)\n",
    "            # ƒë·ªÉ ƒë∆°n gi·∫£n & hi·ªáu qu·∫£, d√πng sampling theo t·ª∑ l·ªá\n",
    "            add = chunk.sample(take, random_state=random_state)\n",
    "            combined = pd.concat([reservoir, add], ignore_index=True)\n",
    "            reservoir = combined.sample(min(k, len(combined)), random_state=random_state)\n",
    "        total += len(chunk)\n",
    "    print(f\"‚úÖ L·∫•y m·∫´u {len(reservoir)} d√≤ng ng·∫´u nhi√™n t·ª´ t·ªïng ~{total} d√≤ng.\")\n",
    "    return reservoir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb3586",
   "metadata": {},
   "source": [
    "\n",
    "## 3) V√≠ d·ª• nhanh tr√™n HOSP (admissions, patients, diagnoses_icd, labevents, d_labitems)\n",
    "> B·∫°n c√≥ th·ªÉ ch·∫°y t·ª´ng cell d∆∞·ªõi ƒë√¢y tu·ª≥ nhu c·∫ßu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb11401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "admissions_path = HOSP_DIR / \"admissions.csv.gz\"\n",
    "patients_path   = HOSP_DIR / \"patients.csv.gz\"\n",
    "diagnoses_path  = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "labevents_path  = HOSP_DIR / \"labevents.csv.gz\"\n",
    "dlab_path       = HOSP_DIR / \"d_labitems.csv.gz\"\n",
    "\n",
    "preview_csv(admissions_path, nrows=1000000)\n",
    "show_columns(admissions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f773f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preview_csv(patients_path, nrows=5)\n",
    "show_columns(patients_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preview_csv(diagnoses_path, nrows=5)\n",
    "show_columns(diagnoses_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca35e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ‚ö†Ô∏è labevents r·∫•t l·ªõn ‚Äî ch·ªâ xem 5 d√≤ng + duy·ªát 1-2 chunk nh·ªè\n",
    "preview_csv(labevents_path, nrows=5)\n",
    "read_in_chunks(labevents_path, chunksize=50000, max_chunks=1, head_each=5)\n",
    "show_columns(labevents_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preview_csv(dlab_path, nrows=5)\n",
    "show_columns(dlab_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bde3fc6",
   "metadata": {},
   "source": [
    "\n",
    "## 4) V√≠ d·ª• nhanh tr√™n NOTE (discharge, radiology)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ƒê·ªçc m·ªôt ph·∫ßn nh·ªè ƒë·ªÉ kh√¥ng n·∫∑ng m√°y\n",
    "df_dis = pd.read_csv(\n",
    "    discharge_path,\n",
    "    usecols=[\"hadm_id\", \"charttime\", \"text\"],\n",
    "    compression=\"gzip\",\n",
    "    nrows=3\n",
    ")\n",
    "\n",
    "# Hi·ªÉn th·ªã to√†n b·ªô n·ªôi dung m√† kh√¥ng b·ªã r√∫t g·ªçn\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "for i, row in df_dis.iterrows():\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"HADM_ID: {row['hadm_id']} | CHARTTIME: {row['charttime']}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(row[\"text\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72f705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28979390</td>\n",
       "      <td>9</td>\n",
       "      <td>5551</td>\n",
       "      <td>Nephroureterectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26134563</td>\n",
       "      <td>9</td>\n",
       "      <td>3734</td>\n",
       "      <td>Excision or destruction of other lesion or tis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>26134563</td>\n",
       "      <td>9</td>\n",
       "      <td>3728</td>\n",
       "      <td>Intracardiac echocardiography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29541074</td>\n",
       "      <td>9</td>\n",
       "      <td>4562</td>\n",
       "      <td>Other partial resection of small intestine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>22119639</td>\n",
       "      <td>9</td>\n",
       "      <td>4576</td>\n",
       "      <td>Open and other sigmoidectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>21544441</td>\n",
       "      <td>10</td>\n",
       "      <td>0TTB4ZZ</td>\n",
       "      <td>Resection of Bladder, Percutaneous Endoscopic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>21544441</td>\n",
       "      <td>10</td>\n",
       "      <td>0UT9FZZ</td>\n",
       "      <td>Resection of Uterus, Via Natural or Artificial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>21544441</td>\n",
       "      <td>10</td>\n",
       "      <td>0UTC7ZZ</td>\n",
       "      <td>Resection of Cervix, Via Natural or Artificial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>21544441</td>\n",
       "      <td>10</td>\n",
       "      <td>0UT2FZZ</td>\n",
       "      <td>Resection of Bilateral Ovaries, Via Natural or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>26840593</td>\n",
       "      <td>10</td>\n",
       "      <td>3E0436Z</td>\n",
       "      <td>Introduction of Nutritional Substance into Cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>28058085</td>\n",
       "      <td>10</td>\n",
       "      <td>BT14YZZ</td>\n",
       "      <td>Fluoroscopy of Kidneys, Ureters and Bladder us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>29250371</td>\n",
       "      <td>10</td>\n",
       "      <td>BT13YZZ</td>\n",
       "      <td>Fluoroscopy of Bilateral Kidneys using Other C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>29250371</td>\n",
       "      <td>10</td>\n",
       "      <td>BT13YZZ</td>\n",
       "      <td>Fluoroscopy of Bilateral Kidneys using Other C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>23506139</td>\n",
       "      <td>9</td>\n",
       "      <td>734</td>\n",
       "      <td>Medical induction of labor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>27463908</td>\n",
       "      <td>9</td>\n",
       "      <td>8853</td>\n",
       "      <td>Angiocardiography of left heart structures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>25563031</td>\n",
       "      <td>9</td>\n",
       "      <td>7055</td>\n",
       "      <td>Repair of rectocele with graft or prosthesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>21728396</td>\n",
       "      <td>10</td>\n",
       "      <td>B211YZZ</td>\n",
       "      <td>Fluoroscopy of Multiple Coronary Arteries usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>26184834</td>\n",
       "      <td>10</td>\n",
       "      <td>3E0G76Z</td>\n",
       "      <td>Introduction of Nutritional Substance into Upp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>26202981</td>\n",
       "      <td>10</td>\n",
       "      <td>0DJ08ZZ</td>\n",
       "      <td>Inspection of Upper Intestinal Tract, Via Natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>29897682</td>\n",
       "      <td>10</td>\n",
       "      <td>0DJ68ZZ</td>\n",
       "      <td>Inspection of Stomach, Via Natural or Artifici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id  icd_version icd_code  \\\n",
       "6    28979390            9     5551   \n",
       "7    26134563            9     3734   \n",
       "8    26134563            9     3728   \n",
       "22   29541074            9     4562   \n",
       "45   22119639            9     4576   \n",
       "49   21544441           10  0TTB4ZZ   \n",
       "51   21544441           10  0UT9FZZ   \n",
       "52   21544441           10  0UTC7ZZ   \n",
       "53   21544441           10  0UT2FZZ   \n",
       "58   26840593           10  3E0436Z   \n",
       "69   28058085           10  BT14YZZ   \n",
       "73   29250371           10  BT13YZZ   \n",
       "74   29250371           10  BT13YZZ   \n",
       "76   23506139            9      734   \n",
       "78   27463908            9     8853   \n",
       "81   25563031            9     7055   \n",
       "84   21728396           10  B211YZZ   \n",
       "94   26184834           10  3E0G76Z   \n",
       "96   26202981           10  0DJ08ZZ   \n",
       "103  29897682           10  0DJ68ZZ   \n",
       "\n",
       "                                            long_title  \n",
       "6                                   Nephroureterectomy  \n",
       "7    Excision or destruction of other lesion or tis...  \n",
       "8                        Intracardiac echocardiography  \n",
       "22          Other partial resection of small intestine  \n",
       "45                        Open and other sigmoidectomy  \n",
       "49   Resection of Bladder, Percutaneous Endoscopic ...  \n",
       "51   Resection of Uterus, Via Natural or Artificial...  \n",
       "52   Resection of Cervix, Via Natural or Artificial...  \n",
       "53   Resection of Bilateral Ovaries, Via Natural or...  \n",
       "58   Introduction of Nutritional Substance into Cen...  \n",
       "69   Fluoroscopy of Kidneys, Ureters and Bladder us...  \n",
       "73   Fluoroscopy of Bilateral Kidneys using Other C...  \n",
       "74   Fluoroscopy of Bilateral Kidneys using Other C...  \n",
       "76                          Medical induction of labor  \n",
       "78          Angiocardiography of left heart structures  \n",
       "81        Repair of rectocele with graft or prosthesis  \n",
       "84   Fluoroscopy of Multiple Coronary Arteries usin...  \n",
       "94   Introduction of Nutritional Substance into Upp...  \n",
       "96   Inspection of Upper Intestinal Tract, Via Natu...  \n",
       "103  Inspection of Stomach, Via Natural or Artifici...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "HOSP_DIR = Path(\"../data/mimiciv/3.1/hosp\")\n",
    "\n",
    "proc = pd.read_csv(HOSP_DIR / \"procedures_icd.csv.gz\", compression=\"gzip\")\n",
    "dproc = pd.read_csv(HOSP_DIR / \"d_icd_procedures.csv.gz\", compression=\"gzip\")\n",
    "\n",
    "merged = proc.merge(dproc, on=[\"icd_code\", \"icd_version\"], how=\"left\")\n",
    "\n",
    "imaging_kw = [\n",
    "    \"x-ray\", \"radiograph\", \"ct\", \"mri\", \"ultrasound\",\n",
    "    \"fluoroscopy\", \"angiography\", \"echocardiography\", \"imaging\"\n",
    "]\n",
    "\n",
    "pattern = \"|\".join(imaging_kw)\n",
    "imaging_codes = merged[merged[\"long_title\"].str.lower().str.contains(pattern, na=False)]\n",
    "\n",
    "display(imaging_codes[[\"hadm_id\", \"icd_version\", \"icd_code\", \"long_title\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1f64fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== T·ªîNG QUAN D·ªÆ LI·ªÜU THEO L·∫¶N NH·∫¨P VI·ªÜN ===\n",
      "- T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán (hadm_id): 546,028\n",
      "- C√≥ ghi ch√∫ xu·∫•t vi·ªán (discharge note): 331,793 (60.8%)\n",
      "- C√≥ th·ªß thu·∫≠t (procedures_icd): 287,504 (52.7%)\n",
      "- C√≥ x√©t nghi·ªám (labevents): 447,689 (82.0%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ======== C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ========\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "NOTE_DIR = DATA_ROOT / \"mimic-iv-note\" / \"2.2\" / \"note\"\n",
    "\n",
    "# ======== 1Ô∏è‚É£ T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ========\n",
    "adm = pd.read_csv(HOSP_DIR / \"admissions.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "total_hadm = adm[\"hadm_id\"].nunique()\n",
    "\n",
    "# ======== 2Ô∏è‚É£ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ note xu·∫•t vi·ªán ========\n",
    "discharge = pd.read_csv(\n",
    "    NOTE_DIR / \"discharge.csv.gz\",\n",
    "    usecols=[\"hadm_id\"],\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "hadm_with_discharge = discharge[\"hadm_id\"].dropna().astype(int).nunique()\n",
    "\n",
    "# ======== 3Ô∏è‚É£ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ th·ªß thu·∫≠t (procedures_icd) ========\n",
    "procedures = pd.read_csv(\n",
    "    HOSP_DIR / \"procedures_icd.csv.gz\",\n",
    "    usecols=[\"hadm_id\"],\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "hadm_with_proc = procedures[\"hadm_id\"].dropna().astype(int).nunique()\n",
    "\n",
    "# ======== 4Ô∏è‚É£ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ x√©t nghi·ªám (labevents) ========\n",
    "labs = pd.read_csv(\n",
    "    HOSP_DIR / \"labevents.csv.gz\",\n",
    "    usecols=[\"hadm_id\"],\n",
    "    compression=\"gzip\"\n",
    ")\n",
    "hadm_with_lab = labs[\"hadm_id\"].dropna().astype(int).nunique()\n",
    "\n",
    "# ======== 5Ô∏è‚É£ In th·ªëng k√™ ========\n",
    "print(\"=== T·ªîNG QUAN D·ªÆ LI·ªÜU THEO L·∫¶N NH·∫¨P VI·ªÜN ===\")\n",
    "print(f\"- T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán (hadm_id): {total_hadm:,}\")\n",
    "print(f\"- C√≥ ghi ch√∫ xu·∫•t vi·ªán (discharge note): {hadm_with_discharge:,} \"\n",
    "      f\"({hadm_with_discharge/total_hadm:.1%})\")\n",
    "print(f\"- C√≥ th·ªß thu·∫≠t (procedures_icd): {hadm_with_proc:,} \"\n",
    "      f\"({hadm_with_proc/total_hadm:.1%})\")\n",
    "print(f\"- C√≥ x√©t nghi·ªám (labevents): {hadm_with_lab:,} \"\n",
    "      f\"({hadm_with_lab/total_hadm:.1%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "763f294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TH·ªêNG K√ä D·ªÆ LI·ªÜU G·ªêC MIMIC-IV THEO L·∫¶N NH·∫¨P VI·ªÜN ===\n",
      "- T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán: 546,028\n",
      "- C√≥ ghi ch√∫ xu·∫•t vi·ªán:   331,793 (60.8%)\n",
      "- C√≥ ch·∫©n ƒëo√°n (ICD):     545,497 (99.9%)\n",
      "- C√≥ th·ªß thu·∫≠t (PROC):    287,504 (52.7%)\n",
      "- C√≥ x√©t nghi·ªám (LAB):    447,689 (82.0%)\n",
      "\n",
      "‚û°Ô∏è  C√≥ ƒë·ªß c·∫£ 4 (Discharge + ICD + Procedure + Lab): 186,014 (34.1%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ====== C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ======\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "NOTE_DIR = DATA_ROOT / \"mimic-iv-note\" / \"2.2\" / \"note\"\n",
    "\n",
    "# ====== 1Ô∏è‚É£ T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán ======\n",
    "adm = pd.read_csv(HOSP_DIR / \"admissions.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "total_hadm = adm[\"hadm_id\"].dropna().astype(int).nunique()\n",
    "\n",
    "# ====== 2Ô∏è‚É£ C√°c nh√≥m ch√≠nh ======\n",
    "hadm_with_discharge = set(\n",
    "    pd.read_csv(NOTE_DIR / \"discharge.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "      [\"hadm_id\"].dropna().astype(int)\n",
    ")\n",
    "hadm_with_icd = set(\n",
    "    pd.read_csv(HOSP_DIR / \"diagnoses_icd.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "      [\"hadm_id\"].dropna().astype(int)\n",
    ")\n",
    "hadm_with_proc = set(\n",
    "    pd.read_csv(HOSP_DIR / \"procedures_icd.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "      [\"hadm_id\"].dropna().astype(int)\n",
    ")\n",
    "hadm_with_lab = set(\n",
    "    pd.read_csv(HOSP_DIR / \"labevents.csv.gz\", usecols=[\"hadm_id\"], compression=\"gzip\")\n",
    "      [\"hadm_id\"].dropna().astype(int)\n",
    ")\n",
    "\n",
    "# ====== 3Ô∏è‚É£ Giao gi·ªØa c√°c nh√≥m ======\n",
    "has_all = hadm_with_discharge & hadm_with_icd & hadm_with_proc & hadm_with_lab\n",
    "\n",
    "# ====== 4Ô∏è‚É£ In th·ªëng k√™ ======\n",
    "print(\"=== TH·ªêNG K√ä D·ªÆ LI·ªÜU G·ªêC MIMIC-IV THEO L·∫¶N NH·∫¨P VI·ªÜN ===\")\n",
    "print(f\"- T·ªïng s·ªë l∆∞·ª£t nh·∫≠p vi·ªán: {total_hadm:,}\")\n",
    "print(f\"- C√≥ ghi ch√∫ xu·∫•t vi·ªán:   {len(hadm_with_discharge):,} ({len(hadm_with_discharge)/total_hadm:.1%})\")\n",
    "print(f\"- C√≥ ch·∫©n ƒëo√°n (ICD):     {len(hadm_with_icd):,} ({len(hadm_with_icd)/total_hadm:.1%})\")\n",
    "print(f\"- C√≥ th·ªß thu·∫≠t (PROC):    {len(hadm_with_proc):,} ({len(hadm_with_proc)/total_hadm:.1%})\")\n",
    "print(f\"- C√≥ x√©t nghi·ªám (LAB):    {len(hadm_with_lab):,} ({len(hadm_with_lab)/total_hadm:.1%})\")\n",
    "print()\n",
    "print(f\"‚û°Ô∏è  C√≥ ƒë·ªß c·∫£ 4 (Discharge + ICD + Procedure + Lab): {len(has_all):,} ({len(has_all)/total_hadm:.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41866d2d",
   "metadata": {},
   "source": [
    "\n",
    "## 5) L·∫•y **m·∫´u ng·∫´u nhi√™n** t·ª´ file r·∫•t l·ªõn (kh√¥ng load to√†n b·ªô)\n",
    "V√≠ d·ª•: l·∫•y 2.000 d√≤ng ng·∫´u nhi√™n t·ª´ `labevents.csv.gz`, sau ƒë√≥ l∆∞u ra file nh·ªè ƒë·ªÉ xem nhanh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b992699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample = sample_rows(labevents_path, k=2000, chunksize=100000, random_state=7)\n",
    "out_path = DATA_ROOT / \"sample_labevents_2000rows.csv\"\n",
    "sample.to_csv(out_path, index=False)\n",
    "print(\"üíæ ƒê√£ l∆∞u:\", out_path)\n",
    "display(sample.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b561d34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ ƒêang x·ª≠ l√Ω ICD...\n",
      "‚úÖ L∆∞u top 50 m√£ ICD ‚Üí ../data/proc/top_50_icd.csv (28,562 m√£, t·ªïng 6,364,488 l∆∞·ª£t)\n",
      "üõ†Ô∏è  ƒêang x·ª≠ l√Ω th·ªß thu·∫≠t...\n",
      "‚úÖ L∆∞u top 50 th·ªß thu·∫≠t ‚Üí ../data/proc/top_50_procedures.csv (14,911 m√£, t·ªïng 859,655 l∆∞·ª£t)\n",
      "üß™ ƒêang x·ª≠ l√Ω x√©t nghi·ªám...\n",
      "‚úÖ L∆∞u top 50 x√©t nghi·ªám ‚Üí ../data/proc/top_50_labs.csv (896 m√£, t·ªïng 84,605,867 l∆∞·ª£t)\n",
      "\n",
      "=== T·ªîNG K·∫æT ===\n",
      "- T·ªïng m√£ ICD: 28,562\n",
      "- T·ªïng m√£ th·ªß thu·∫≠t: 14,911\n",
      "- T·ªïng m√£ x√©t nghi·ªám: 896\n",
      "- T·ªïng l∆∞·ª£t ICD ghi nh·∫≠n: 6,364,488\n",
      "- T·ªïng l∆∞·ª£t th·ªß thu·∫≠t ghi nh·∫≠n: 859,655\n",
      "- T·ªïng l∆∞·ª£t x√©t nghi·ªám ghi nh·∫≠n: 84,605,867\n",
      "üìÇ C√°c file ƒë√£ l∆∞u trong /Users/lehoangkhang/TaÃÄi lieÃ£ÃÇu/revita-sympdiag/data/proc\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "PROC_DIR = DATA_ROOT / \"proc\"\n",
    "\n",
    "# ==========================\n",
    "# H√ÄM: L·∫§Y & L∆ØU TOP M√É PH·ªî BI·∫æN\n",
    "# ==========================\n",
    "def export_top_codes(HOSP_DIR, PROC_DIR, TOP_N=50):\n",
    "    PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- 1Ô∏è‚É£ ICD (diagnoses_icd) ---\n",
    "    diag_path = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "    print(\"üìñ ƒêang x·ª≠ l√Ω ICD...\")\n",
    "    diag_cnt = Counter()\n",
    "    for chunk in pd.read_csv(diag_path, usecols=[\"hadm_id\", \"icd_code\"], compression=\"gzip\", chunksize=200_000):\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"])\n",
    "        diag_cnt.update(chunk[\"icd_code\"].astype(str))\n",
    "    diag_df = pd.DataFrame(diag_cnt.items(), columns=[\"icd_code\", \"count\"]).sort_values(\"count\", ascending=False)\n",
    "    diag_top = diag_df.head(TOP_N)\n",
    "    out_icd = PROC_DIR / f\"top_{TOP_N}_icd.csv\"\n",
    "    diag_top.to_csv(out_icd, index=False)\n",
    "    print(f\"‚úÖ L∆∞u top {TOP_N} m√£ ICD ‚Üí {out_icd} ({len(diag_df):,} m√£, t·ªïng {diag_df['count'].sum():,} l∆∞·ª£t)\")\n",
    "\n",
    "    # --- 2Ô∏è‚É£ Procedures (procedures_icd) ---\n",
    "    proc_path = HOSP_DIR / \"procedures_icd.csv.gz\"\n",
    "    print(\"üõ†Ô∏è  ƒêang x·ª≠ l√Ω th·ªß thu·∫≠t...\")\n",
    "    proc_cnt = Counter()\n",
    "    for chunk in pd.read_csv(proc_path, usecols=[\"hadm_id\", \"icd_code\"], compression=\"gzip\", chunksize=200_000):\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"])\n",
    "        proc_cnt.update(chunk[\"icd_code\"].astype(str))\n",
    "    proc_df = pd.DataFrame(proc_cnt.items(), columns=[\"proc_code\", \"count\"]).sort_values(\"count\", ascending=False)\n",
    "    proc_top = proc_df.head(TOP_N)\n",
    "    out_proc = PROC_DIR / f\"top_{TOP_N}_procedures.csv\"\n",
    "    proc_top.to_csv(out_proc, index=False)\n",
    "    print(f\"‚úÖ L∆∞u top {TOP_N} th·ªß thu·∫≠t ‚Üí {out_proc} ({len(proc_df):,} m√£, t·ªïng {proc_df['count'].sum():,} l∆∞·ª£t)\")\n",
    "\n",
    "    # --- 3Ô∏è‚É£ Labs (labevents + d_labitems) ---\n",
    "    lab_path = HOSP_DIR / \"labevents.csv.gz\"\n",
    "    dlab_path = HOSP_DIR / \"d_labitems.csv.gz\"\n",
    "    print(\"üß™ ƒêang x·ª≠ l√Ω x√©t nghi·ªám...\")\n",
    "    lab_cnt = Counter()\n",
    "    for chunk in pd.read_csv(lab_path, usecols=[\"hadm_id\", \"itemid\"], compression=\"gzip\", chunksize=200_000):\n",
    "        chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"])\n",
    "        lab_cnt.update(chunk[\"itemid\"].astype(int))\n",
    "    lab_df = pd.DataFrame(lab_cnt.items(), columns=[\"itemid\", \"count\"]).sort_values(\"count\", ascending=False)\n",
    "\n",
    "    # G·∫Øn label t·ª´ d_labitems (t√™n x√©t nghi·ªám)\n",
    "    dlab = pd.read_csv(dlab_path, usecols=[\"itemid\", \"label\"], compression=\"gzip\")\n",
    "    lab_df = lab_df.merge(dlab, on=\"itemid\", how=\"left\")\n",
    "    lab_top = lab_df.head(TOP_N)\n",
    "    out_lab = PROC_DIR / f\"top_{TOP_N}_labs.csv\"\n",
    "    lab_top.to_csv(out_lab, index=False)\n",
    "    print(f\"‚úÖ L∆∞u top {TOP_N} x√©t nghi·ªám ‚Üí {out_lab} ({len(lab_df):,} m√£, t·ªïng {lab_df['count'].sum():,} l∆∞·ª£t)\")\n",
    "\n",
    "    # --- T·ªïng k·∫øt ---\n",
    "    print(\"\\n=== T·ªîNG K·∫æT ===\")\n",
    "    print(f\"- T·ªïng m√£ ICD: {len(diag_df):,}\")\n",
    "    print(f\"- T·ªïng m√£ th·ªß thu·∫≠t: {len(proc_df):,}\")\n",
    "    print(f\"- T·ªïng m√£ x√©t nghi·ªám: {len(lab_df):,}\")\n",
    "    print(f\"- T·ªïng l∆∞·ª£t ICD ghi nh·∫≠n: {diag_df['count'].sum():,}\")\n",
    "    print(f\"- T·ªïng l∆∞·ª£t th·ªß thu·∫≠t ghi nh·∫≠n: {proc_df['count'].sum():,}\")\n",
    "    print(f\"- T·ªïng l∆∞·ª£t x√©t nghi·ªám ghi nh·∫≠n: {lab_df['count'].sum():,}\")\n",
    "    print(f\"üìÇ C√°c file ƒë√£ l∆∞u trong {PROC_DIR.resolve()}\")\n",
    "\n",
    "# ==========================\n",
    "# G·ªåI H√ÄM\n",
    "# ==========================\n",
    "export_top_codes(HOSP_DIR, PROC_DIR, TOP_N=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bad605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Top ICD: 50 | Top Procedures: 50 | Top Labs: 50\n",
      "\n",
      "=== T·ªîNG K·∫æT THEO L∆Ø·ª¢T NH·∫¨P VI·ªÜN ===\n",
      "- C√≥ b·ªánh (ICD): 454,431\n",
      "- C√≥ th·ªß thu·∫≠t (Procedure): 145,381\n",
      "- C√≥ x√©t nghi·ªám (Lab): 441,727\n",
      "\n",
      "‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ƒê·ª¶ c·∫£ 3 (ICD + Proc + Lab): 116,554\n",
      "üìÇ ƒê√£ l∆∞u danh s√°ch 116,554 l∆∞·ª£t nh·∫≠p vi·ªán ƒë·∫ßy ƒë·ªß v√†o: ../data/proc/hadm_with_all3.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================\n",
    "# C·∫•u h√¨nh th∆∞ m·ª•c\n",
    "# ==========================\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "HOSP_DIR = DATA_ROOT / \"mimiciv\" / \"3.1\" / \"hosp\"\n",
    "PROC_DIR = DATA_ROOT / \"proc\"    # th∆∞ m·ª•c ch·ª©a top_50_xxx.csv\n",
    "\n",
    "# ==========================\n",
    "# ƒê·ªçc danh s√°ch top m√£\n",
    "# ==========================\n",
    "top_icd = pd.read_csv(PROC_DIR / \"top_50_icd.csv\")[\"icd_code\"].astype(str).tolist()\n",
    "top_proc = pd.read_csv(PROC_DIR / \"top_50_procedures.csv\")[\"proc_code\"].astype(str).tolist()\n",
    "top_lab = pd.read_csv(PROC_DIR / \"top_50_labs.csv\")[\"itemid\"].astype(int).tolist()\n",
    "\n",
    "print(f\"üîç Top ICD: {len(top_icd)} | Top Procedures: {len(top_proc)} | Top Labs: {len(top_lab)}\")\n",
    "\n",
    "# ==========================\n",
    "# 1Ô∏è‚É£ ƒê·ªçc t·ª´ng b·∫£ng & l·ªçc theo top m√£\n",
    "# ==========================\n",
    "\n",
    "# --- ICD ---\n",
    "diag_path = HOSP_DIR / \"diagnoses_icd.csv.gz\"\n",
    "hadm_icd = set()\n",
    "for chunk in pd.read_csv(diag_path, usecols=[\"hadm_id\", \"icd_code\"], compression=\"gzip\", chunksize=200_000):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"])\n",
    "    chunk[\"icd_code\"] = chunk[\"icd_code\"].astype(str)\n",
    "    hadm_icd.update(chunk.loc[chunk[\"icd_code\"].isin(top_icd), \"hadm_id\"].astype(int))\n",
    "\n",
    "# --- Procedures ---\n",
    "proc_path = HOSP_DIR / \"procedures_icd.csv.gz\"\n",
    "hadm_proc = set()\n",
    "for chunk in pd.read_csv(proc_path, usecols=[\"hadm_id\", \"icd_code\"], compression=\"gzip\", chunksize=200_000):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"icd_code\"])\n",
    "    chunk[\"icd_code\"] = chunk[\"icd_code\"].astype(str)\n",
    "    hadm_proc.update(chunk.loc[chunk[\"icd_code\"].isin(top_proc), \"hadm_id\"].astype(int))\n",
    "\n",
    "# --- Labs ---\n",
    "lab_path = HOSP_DIR / \"labevents.csv.gz\"\n",
    "hadm_lab = set()\n",
    "for chunk in pd.read_csv(lab_path, usecols=[\"hadm_id\", \"itemid\"], compression=\"gzip\", chunksize=200_000):\n",
    "    chunk = chunk.dropna(subset=[\"hadm_id\", \"itemid\"])\n",
    "    chunk[\"itemid\"] = chunk[\"itemid\"].astype(int)\n",
    "    hadm_lab.update(chunk.loc[chunk[\"itemid\"].isin(top_lab), \"hadm_id\"].astype(int))\n",
    "\n",
    "# ==========================\n",
    "# 2Ô∏è‚É£ Th·ªëng k√™ & giao t·∫≠p\n",
    "# ==========================\n",
    "print(\"\\n=== T·ªîNG K·∫æT THEO L∆Ø·ª¢T NH·∫¨P VI·ªÜN ===\")\n",
    "print(f\"- C√≥ b·ªánh (ICD): {len(hadm_icd):,}\")\n",
    "print(f\"- C√≥ th·ªß thu·∫≠t (Procedure): {len(hadm_proc):,}\")\n",
    "print(f\"- C√≥ x√©t nghi·ªám (Lab): {len(hadm_lab):,}\")\n",
    "\n",
    "# Giao t·∫≠p\n",
    "hadm_all = hadm_icd & hadm_proc & hadm_lab\n",
    "print(f\"\\n‚úÖ S·ªë l∆∞·ª£t nh·∫≠p vi·ªán c√≥ ƒê·ª¶ c·∫£ 3 (ICD + Proc + Lab): {len(hadm_all):,}\")\n",
    "\n",
    "# ==========================\n",
    "# 3Ô∏è‚É£ L∆∞u ra file\n",
    "# ==========================\n",
    "out_path = PROC_DIR / \"hadm_with_all3.csv\"\n",
    "pd.DataFrame(sorted(list(hadm_all)), columns=[\"hadm_id\"]).to_csv(out_path, index=False)\n",
    "print(f\"üìÇ ƒê√£ l∆∞u danh s√°ch {len(hadm_all):,} l∆∞·ª£t nh·∫≠p vi·ªán ƒë·∫ßy ƒë·ªß v√†o: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8488b493",
   "metadata": {},
   "source": [
    "\n",
    "## 6) M·∫πo ti·∫øt ki·ªám b·ªô nh·ªõ\n",
    "- D√πng `nrows` ƒë·ªÉ xem nhanh v√†i d√≤ng ƒë·∫ßu, **kh√¥ng** gi·∫£i n√©n to√†n b·ªô.\n",
    "- D√πng `chunksize` ƒë·ªÉ **duy·ªát t·ª´ng ph·∫ßn**, tr√°nh ƒë·∫ßy RAM.\n",
    "- Ch·ªâ ch·ªçn **c·ªôt c·∫ßn thi·∫øt** b·∫±ng `usecols=[...]` n·∫øu b·∫°n bi·∫øt s·∫µn danh s√°ch c·ªôt.\n",
    "- L∆∞u **m·∫´u nh·ªè** ra `.csv` ƒë·ªÉ th·ª≠ nghi·ªám pipeline tr∆∞·ªõc khi x·ª≠ l√Ω to√†n b·ªô d·ªØ li·ªáu.\n",
    "- Tr√°nh `.read_csv(..., low_memory=True)` v·ªõi file nhi·ªÅu ki·ªÉu d·ªØ li·ªáu; d√πng `low_memory=False` ƒë·ªÉ pandas ƒëo√°n ki·ªÉu ·ªïn ƒë·ªãnh h∆°n (√≠t l·ªói).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
