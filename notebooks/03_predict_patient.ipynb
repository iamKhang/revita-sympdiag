{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load model bundle\n",
    "import joblib, numpy as np, pandas as pd\n",
    "bundle = joblib.load(\"../models/ovr_sgd_tfidf.joblib\")\n",
    "clf = bundle[\"clf\"]; word_vec = bundle[\"word_vec\"]; char_vec = bundle[\"char_vec\"]\n",
    "mlb = bundle[\"mlb\"]; cfg = bundle[\"cfg\"]\n",
    "MAX_TOKENS = cfg.get(\"MAX_TOKENS_PER_DOC\", 8000)\n",
    "\n",
    "def _truncate(s, mx=MAX_TOKENS): return \" \".join(str(s).split()[:mx])\n",
    "\n",
    "def _to_X(texts):\n",
    "    s = pd.Series(texts).map(_truncate)\n",
    "    Xw = word_vec.transform(s)\n",
    "    if char_vec is not None:\n",
    "        from scipy.sparse import hstack\n",
    "        Xc = char_vec.transform(s)\n",
    "        return hstack([Xw, Xc], format=\"csr\")\n",
    "    return Xw\n",
    "\n",
    "def predict_topk(texts, K=5):\n",
    "    P = clf.predict_proba(_to_X(texts))\n",
    "    codes = mlb.classes_; out = []\n",
    "    for i in range(len(texts)):\n",
    "        idx = np.argsort(-P[i])[:K]\n",
    "        out.append([(codes[j], float(P[i,j])) for j in idx])\n",
    "    return out\n",
    "\n",
    "# 2) Demo nhanh\n",
    "samples = [\n",
    "    \"Service: MEDICINE\\nHistory: chest pain, HTN, DM, hyperlipidemia...\",\n",
    "    \"Service: SURGERY\\nPost-op day #2, fever, wound infection, antibiotics...\"\n",
    "]\n",
    "for i, preds in enumerate(predict_topk(samples, K=5), 1):\n",
    "    print(f\"\\nCase {i}:\")\n",
    "    for c,p in preds: print(f\"  {c}: {p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201345b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/proc/train_unified.parquet\").head(50)  # ví dụ\n",
    "K = 5\n",
    "rows = []\n",
    "for _, r in df.iterrows():\n",
    "    topk = predict_topk([r[\"text_clean\"]], K=K)[0]\n",
    "    rows.append({\n",
    "        \"hadm_id\": r[\"hadm_id\"],\n",
    "        \"pred_topK\": \";\".join([f\"{c}:{p:.3f}\" for c,p in topk])\n",
    "    })\n",
    "pd.DataFrame(rows).to_csv(\"models/preds_sample_local.csv\", index=False)\n",
    "print(\"Saved models/preds_sample_local.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfdacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator SGDClassifier from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator OneVsRestClassifier from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lehoangkhang/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:348: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.2.2 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HADM 25535697 | subj 12188716\n",
      "  9-4019: 0.329\n",
      "  9-V5861: 0.099\n",
      "  9-2724: 0.096\n",
      "  9-V1582: 0.064\n",
      "  9-7840: 0.058\n",
      "\n",
      "HADM 20296734 | subj 14826102\n",
      "  9-2859: 0.129\n",
      "  9-78701: 0.111\n",
      "  9-78903: 0.106\n",
      "  9-78900: 0.104\n",
      "  9-49390: 0.084\n",
      "\n",
      "HADM 26826685 | subj 19319976\n",
      "  9-V5867: 0.619\n",
      "  9-4019: 0.457\n",
      "  9-2761: 0.438\n",
      "  9-29680: 0.386\n",
      "  9-25000: 0.338\n",
      "\n",
      "HADM 26002726 | subj 12139397\n",
      "  10-D62: 0.190\n",
      "  10-Z87891: 0.148\n",
      "  10-I10: 0.112\n",
      "  10-Y92239: 0.085\n",
      "  10-N179: 0.084\n",
      "\n",
      "HADM 28782684 | subj 17193228\n",
      "  9-4019: 0.518\n",
      "  9-53081: 0.403\n",
      "  9-2724: 0.258\n",
      "  9-99592: 0.217\n",
      "  9-V5867: 0.184\n",
      "\n",
      "HADM 26588327 | subj 17355488\n",
      "  9-V5811: 0.818\n",
      "  9-20500: 0.686\n",
      "  9-30000: 0.595\n",
      "  9-53081: 0.560\n",
      "  9-V160: 0.399\n",
      "\n",
      "HADM 29494996 | subj 13555204\n",
      "  10-I10: 0.614\n",
      "  10-Z87891: 0.276\n",
      "  10-E785: 0.186\n",
      "  10-K219: 0.181\n",
      "  10-F17210: 0.111\n",
      "\n",
      "HADM 24605015 | subj 14312872\n",
      "  10-Z5111: 0.863\n",
      "  10-Z888: 0.329\n",
      "  10-T451X5A: 0.276\n",
      "  10-F419: 0.159\n",
      "  10-Z87891: 0.154\n",
      "\n",
      "HADM 21787279 | subj 12107161\n",
      "  9-3051: 0.277\n",
      "  9-4019: 0.166\n",
      "  9-E8499: 0.132\n",
      "  9-E8781: 0.109\n",
      "  9-2724: 0.095\n",
      "\n",
      "HADM 28475484 | subj 10941013\n",
      "  10-J441: 0.351\n",
      "  10-K219: 0.282\n",
      "  10-Z87891: 0.268\n",
      "  10-I2510: 0.264\n",
      "  10-Z66: 0.261\n"
     ]
    }
   ],
   "source": [
    "import joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ========= Load model =========\n",
    "bundle = joblib.load(\"../models/ovr_sgd_tfidf.joblib\")\n",
    "clf = bundle[\"clf\"]; word_vec = bundle[\"word_vec\"]; char_vec = bundle[\"char_vec\"]\n",
    "mlb = bundle[\"mlb\"]; cfg = bundle[\"cfg\"]\n",
    "MAX_TOKENS = cfg.get(\"MAX_TOKENS_PER_DOC\", 8000)\n",
    "\n",
    "def _truncate(s, mx=MAX_TOKENS): return \" \".join(str(s).split()[:mx])\n",
    "def _to_X(texts):\n",
    "    s = pd.Series(texts).map(_truncate)\n",
    "    Xw = word_vec.transform(s)\n",
    "    if char_vec is not None:\n",
    "        from scipy.sparse import hstack\n",
    "        Xc = char_vec.transform(s)\n",
    "        return hstack([Xw, Xc], format=\"csr\")\n",
    "    return Xw\n",
    "\n",
    "def predict_topk(texts, K=5):\n",
    "    P = clf.predict_proba(_to_X(texts))\n",
    "    codes = mlb.classes_; out = []\n",
    "    for i in range(len(texts)):\n",
    "        idx = np.argsort(-P[i])[:K]\n",
    "        out.append([(codes[j], float(P[i,j])) for j in idx])\n",
    "    return out\n",
    "\n",
    "# ========= Load bảng tên ICD =========\n",
    "PATH_D_ICD = \"../data/mimiciv/3.1/hosp/d_icd_diagnoses.csv.gz\"  # đúng thư mục hosp\n",
    "d = pd.read_csv(PATH_D_ICD, compression=\"gzip\", usecols=[\"icd_code\",\"icd_version\",\"long_title\"])\n",
    "title_map = {(int(v), c.strip()): lt for c, v, lt in zip(d.icd_code, d.icd_version, d.long_title)}\n",
    "\n",
    "def icd_name_from_prefixed(code_with_prefix: str) -> str:\n",
    "    # \"9-4019\" -> (9,\"4019\"), \"10-I10\" -> (10,\"I10\")\n",
    "    try:\n",
    "        ver_str, code = code_with_prefix.split(\"-\", 1)\n",
    "        return title_map.get((int(ver_str), code), \"(unknown title)\")\n",
    "    except Exception:\n",
    "        return \"(unknown title)\"\n",
    "\n",
    "# ========= Lấy 10 mẫu và in kết quả (kèm tên bệnh) =========\n",
    "df = pd.read_parquet(\"../data/proc/train_unified.parquet\").sample(10, random_state=42)\n",
    "for _, r in df.iterrows():\n",
    "    preds = predict_topk([r[\"text_clean\"]], K=5)[0]\n",
    "    print(f\"\\nHADM {r['hadm_id']} | subj {r['subject_id']}\")\n",
    "    for c, p in preds:\n",
    "        print(f\"  {c}: {p:.3f}  —  {icd_name_from_prefixed(c)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
