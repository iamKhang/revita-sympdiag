"""
Script ƒë·ªÉ th·ªëng nh·∫•t c√°c ICD code c√≥ long_title tr√πng l·∫∑p.
T√¨m c√°c ICD tr√πng, t·∫°o mapping v√† √°p d·ª•ng v√†o diagnoses_icd.csv
Gi·ªØ nguy√™n d·ªØ li·ªáu, ch·ªâ c·∫≠p nh·∫≠t ICD code ƒë·ªÉ th·ªëng nh·∫•t.
"""

import pandas as pd
from pathlib import Path
import os
import sys

# ƒê∆∞·ªùng d·∫´n g·ªëc c·ªßa project
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"

# ƒê∆∞·ªùng d·∫´n c√°c file
SOURCE_FILE = DATA_DIR / "mimiciv" / "3.1" / "hosp" / "d_icd_diagnoses.csv.gz"
DUPLICATE_FILE = DATA_DIR / "mimic-iv-lite" / "duplicate_icd_diagnoses.csv"
MAPPING_FILE = DATA_DIR / "mimic-iv-lite" / "icd_deduplicated_mapping.csv"

def find_duplicate_icd_diagnoses():
    """T√¨m v√† l∆∞u c√°c ICD code c√≥ long_title tr√πng l·∫∑p"""
    
    print("=" * 60)
    print("B∆Ø·ªöC 1: T√åM C√ÅC ICD CODE TR√ôNG L·∫∂P")
    print("=" * 60)
    
    if not SOURCE_FILE.exists():
        print(f"‚ùå File kh√¥ng t·ªìn t·∫°i: {SOURCE_FILE}")
        return None
    
    print(f"üìñ ƒêang ƒë·ªçc: {SOURCE_FILE.name}")
    
    try:
        # ƒê·ªçc file gzip
        df = pd.read_csv(SOURCE_FILE, compression='gzip', low_memory=False)
        
        print(f"   T·ªïng s·ªë d√≤ng: {len(df):,}")
        print(f"   S·ªë ICD-9: {len(df[df['icd_version'] == 9]):,}")
        print(f"   S·ªë ICD-10: {len(df[df['icd_version'] == 10]):,}")
        
        # Chu·∫©n h√≥a long_title: lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a v√† chuy·ªÉn v·ªÅ lowercase ƒë·ªÉ so s√°nh
        df['long_title_normalized'] = df['long_title'].astype(str).str.strip().str.lower()
        
        # T√¨m c√°c long_title xu·∫•t hi·ªán nhi·ªÅu h∆°n 1 l·∫ßn
        title_counts = df.groupby('long_title_normalized').size()
        duplicate_titles = title_counts[title_counts > 1].index.tolist()
        
        print(f"   T√¨m th·∫•y {len(duplicate_titles):,} long_title tr√πng l·∫∑p")
        
        if len(duplicate_titles) == 0:
            print("   Kh√¥ng c√≥ long_title n√†o b·ªã tr√πng l·∫∑p")
            return pd.DataFrame(columns=['icd_code', 'icd_version', 'long_title'])
        
        # L·ªçc ra t·∫•t c·∫£ c√°c d√≤ng c√≥ long_title tr√πng l·∫∑p
        mask = df['long_title_normalized'].isin(duplicate_titles)
        duplicate_df = df[mask].copy()
        
        # X√≥a c·ªôt normalized (ch·ªâ d√πng ƒë·ªÉ so s√°nh)
        duplicate_df = duplicate_df[['icd_code', 'icd_version', 'long_title']]
        
        # S·∫Øp x·∫øp theo long_title ƒë·ªÉ d·ªÖ xem
        duplicate_df = duplicate_df.sort_values(['long_title', 'icd_version', 'icd_code'])
        
        print(f"   T·ªïng s·ªë ICD code b·ªã tr√πng: {len(duplicate_df):,}")
        print(f"   S·ªë long_title duy nh·∫•t b·ªã tr√πng: {len(duplicate_titles):,}")
        
        # Th·ªëng k√™ c√°c tr∆∞·ªùng h·ª£p tr√πng
        duplicate_df['long_title_normalized'] = duplicate_df['long_title'].astype(str).str.strip().str.lower()
        
        # ƒê·∫øm c√°c tr∆∞·ªùng h·ª£p: 9-9, 9-10, 10-10
        icd9_vs_icd9 = 0
        icd9_vs_icd10 = 0
        icd10_vs_icd10 = 0
        
        for title_norm in duplicate_titles:
            group = duplicate_df[duplicate_df['long_title_normalized'] == title_norm]
            versions = set(group['icd_version'].unique())
            
            if len(versions) == 1:
                if 9 in versions:
                    icd9_vs_icd9 += 1
                elif 10 in versions:
                    icd10_vs_icd10 += 1
            else:
                if 9 in versions and 10 in versions:
                    icd9_vs_icd10 += 1
        
        print(f"\nüìä Th·ªëng k√™ c√°c tr∆∞·ªùng h·ª£p tr√πng:")
        print(f"   ICD-9 tr√πng v·ªõi ICD-9: {icd9_vs_icd9:,} nh√≥m")
        print(f"   ICD-9 tr√πng v·ªõi ICD-10: {icd9_vs_icd10:,} nh√≥m")
        print(f"   ICD-10 tr√πng v·ªõi ICD-10: {icd10_vs_icd10:,} nh√≥m")
        
        # L∆∞u file duplicate (t√πy ch·ªçn, ƒë·ªÉ tham kh·∫£o)
        DUPLICATE_FILE.parent.mkdir(parents=True, exist_ok=True)
        duplicate_df[['icd_code', 'icd_version', 'long_title']].to_csv(DUPLICATE_FILE, index=False)
        print(f"\n‚úÖ ƒê√£ l∆∞u danh s√°ch duplicate: {DUPLICATE_FILE.name}")
        
        return duplicate_df
        
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def create_icd_mapping(duplicate_df=None):
    """T·∫°o mapping ƒë·ªÉ th·ªëng nh·∫•t c√°c ICD code tr√πng long_title"""
    
    print("\n" + "=" * 60)
    print("B∆Ø·ªöC 2: T·∫†O MAPPING TH·ªêNG NH·∫§T ICD CODE")
    print("=" * 60)
    
    if duplicate_df is None:
        if not DUPLICATE_FILE.exists():
            print(f"‚ö†Ô∏è  File duplicate kh√¥ng t·ªìn t·∫°i. Ch·∫°y find_duplicate_icd_diagnoses() tr∆∞·ªõc")
            return None
        duplicate_df = pd.read_csv(DUPLICATE_FILE)
    
    # Chu·∫©n h√≥a long_title ƒë·ªÉ nh√≥m
    duplicate_df['long_title_normalized'] = duplicate_df['long_title'].astype(str).str.strip().str.lower()
    
    # T·∫°o mapping: v·ªõi m·ªói long_title tr√πng, ch·ªçn ICD canonical
    # Quy t·∫Øc: ∆Øu ti√™n ICD-10, n·∫øu c√≥ nhi·ªÅu ICD-10 th√¨ ch·ªçn theo th·ª© t·ª± alphabet c·ªßa icd_code
    mappings = []
    
    # Nh√≥m c√°c ICD theo long_title_normalized
    duplicate_titles = duplicate_df['long_title_normalized'].unique()
    print(f"\nüîÑ ƒêang x·ª≠ l√Ω {len(duplicate_titles):,} long_title tr√πng l·∫∑p...")
    
    for title_norm in duplicate_titles:
        # L·∫•y t·∫•t c·∫£ ICD c√≥ c√πng long_title
        group = duplicate_df[duplicate_df['long_title_normalized'] == title_norm].copy()
        
        # S·∫Øp x·∫øp: ∆∞u ti√™n ICD-10, sau ƒë√≥ theo icd_code
        group = group.sort_values(['icd_version', 'icd_code'], ascending=[False, True])
        
        # Ch·ªçn ICD ƒë·∫ßu ti√™n l√†m canonical (∆∞u ti√™n ICD-10)
        canonical = group.iloc[0]
        canonical_icd_code = canonical['icd_code']
        canonical_icd_version = canonical['icd_version']
        
        # T·∫°o mapping cho t·∫•t c·∫£ c√°c ICD trong nh√≥m (bao g·ªìm c·∫£ canonical)
        for _, row in group.iterrows():
            mappings.append({
                'original_icd_code': row['icd_code'],
                'original_icd_version': row['icd_version'],
                'canonical_icd_code': canonical_icd_code,
                'canonical_icd_version': canonical_icd_version,
                'long_title': row['long_title']
            })
    
    # T·∫°o DataFrame mapping
    mapping_df = pd.DataFrame(mappings)
    
    # Lo·∫°i b·ªè c√°c mapping tr√πng (n·∫øu c√≥)
    mapping_df = mapping_df.drop_duplicates(['original_icd_code', 'original_icd_version'])
    
    print(f"\n‚úÖ ƒê√£ t·∫°o {len(mapping_df):,} mapping")
    
    # Th·ªëng k√™ chi ti·∫øt c√°c tr∆∞·ªùng h·ª£p mapping
    icd9_to_icd10 = len(mapping_df[
        (mapping_df['original_icd_version'] == 9) & 
        (mapping_df['canonical_icd_version'] == 10)
    ])
    icd10_to_icd10 = len(mapping_df[
        (mapping_df['original_icd_version'] == 10) & 
        (mapping_df['canonical_icd_version'] == 10)
    ])
    icd9_to_icd9 = len(mapping_df[
        (mapping_df['original_icd_version'] == 9) & 
        (mapping_df['canonical_icd_version'] == 9)
    ])
    
    print(f"\nüìä Th·ªëng k√™ mapping:")
    print(f"   ICD-9 -> ICD-10: {icd9_to_icd10:,}")
    print(f"   ICD-10 -> ICD-10: {icd10_to_icd10:,}")
    print(f"   ICD-9 -> ICD-9: {icd9_to_icd9:,}")
    
    # S·∫Øp x·∫øp ƒë·ªÉ d·ªÖ ƒë·ªçc
    mapping_df = mapping_df.sort_values(['long_title', 'original_icd_version', 'original_icd_code'])
    
    # L∆∞u file mapping
    MAPPING_FILE.parent.mkdir(parents=True, exist_ok=True)
    mapping_df.to_csv(MAPPING_FILE, index=False)
    print(f"\n‚úÖ ƒê√£ l∆∞u mapping: {MAPPING_FILE.name}")
    print(f"   K√≠ch th∆∞·ªõc: {os.path.getsize(MAPPING_FILE) / 1024:.2f} KB")
    
    # Hi·ªÉn th·ªã m·ªôt v√†i v√≠ d·ª•
    print("\nüìã M·ªôt v√†i v√≠ d·ª• mapping:")
    sample = mapping_df.head(10)
    for _, row in sample.iterrows():
        if row['original_icd_version'] != row['canonical_icd_version']:
            print(f"   {row['original_icd_version']}-{row['original_icd_code']} -> "
                  f"{row['canonical_icd_version']}-{row['canonical_icd_code']}")
            print(f"      '{row['long_title'][:60]}...'")
    
    return mapping_df

def apply_mapping_to_diagnoses_icd(mapping_df=None, input_file=None, output_file=None, use_full_file=False):
    """√Åp d·ª•ng mapping v√†o diagnoses_icd.csv
    
    Args:
        mapping_df: DataFrame ch·ª©a mapping (n·∫øu None s·∫Ω ƒë·ªçc t·ª´ file)
        input_file: ƒê∆∞·ªùng d·∫´n file input (n·∫øu None s·∫Ω d√πng file m·∫∑c ƒë·ªãnh)
        output_file: ƒê∆∞·ªùng d·∫´n file output (n·∫øu None s·∫Ω d√πng file m·∫∑c ƒë·ªãnh)
        use_full_file: N·∫øu True, x·ª≠ l√Ω file g·ªëc ƒë·∫ßy ƒë·ªß t·ª´ mimiciv/3.1/hosp/
    """
    
    print("\n" + "=" * 60)
    print("B∆Ø·ªöC 3: √ÅP D·ª§NG MAPPING V√ÄO diagnoses_icd.csv")
    print("=" * 60)
    
    if mapping_df is None:
        if not MAPPING_FILE.exists():
            print(f"‚ö†Ô∏è  File mapping ch∆∞a t·ªìn t·∫°i. Ch·∫°y create_icd_mapping() tr∆∞·ªõc.")
            return None
        mapping_df = pd.read_csv(MAPPING_FILE)
    
    # X√°c ƒë·ªãnh file input v√† output
    if use_full_file:
        # S·ª≠ d·ª•ng file g·ªëc ƒë·∫ßy ƒë·ªß
        if input_file is None:
            input_file = DATA_DIR / "mimiciv" / "3.1" / "hosp" / "diagnoses_icd.csv.gz"
        if output_file is None:
            # L∆∞u v√†o th∆∞ m·ª•c proc ƒë·ªÉ kh√¥ng ·∫£nh h∆∞·ªüng file g·ªëc
            output_dir = DATA_DIR / "proc"
            output_dir.mkdir(parents=True, exist_ok=True)
            output_file = output_dir / "diagnoses_icd_unified.csv.gz"
    else:
        # S·ª≠ d·ª•ng file lite (m·∫∑c ƒë·ªãnh)
        if input_file is None:
            input_file = DATA_DIR / "mimic-iv-lite" / "diagnoses_icd.csv"
        if output_file is None:
            output_file = DATA_DIR / "mimic-iv-lite" / "diagnoses_icd_unified.csv"
    
    if not input_file.exists():
        print(f"‚ö†Ô∏è  File {input_file} kh√¥ng t·ªìn t·∫°i. B·ªè qua.")
        return None
    
    print(f"\nüîÑ √Åp d·ª•ng mapping v√†o {input_file.name}...")
    
    # T·∫°o mapping dictionary ƒë·ªÉ lookup nhanh
    mapping_dict = {}
    for _, row in mapping_df.iterrows():
        key = (str(row['original_icd_code']), int(row['original_icd_version']))
        mapping_dict[key] = (str(row['canonical_icd_code']), int(row['canonical_icd_version']))
    
    print(f"   ƒê√£ load {len(mapping_dict):,} mapping")
    
    # X·ª≠ l√Ω file gzip ho·∫∑c file th∆∞·ªùng
    is_gzip = str(input_file).endswith('.gz')
    use_chunks = use_full_file  # Ch·ªâ d√πng chunks cho file l·ªõn
    
    if use_chunks:
        # X·ª≠ l√Ω theo chunks ƒë·ªÉ ti·∫øt ki·ªám memory
        print(f"   X·ª≠ l√Ω file l·ªõn theo chunks...")
        chunk_size = 100_000
        total_rows = 0
        changed_count = 0
        first_chunk = True
        
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        # X√≥a file output n·∫øu ƒë√£ t·ªìn t·∫°i
        if output_file.exists():
            output_file.unlink()
        
        for chunk_num, chunk in enumerate(pd.read_csv(input_file, compression='gzip' if is_gzip else None, 
                                                      chunksize=chunk_size, low_memory=False)):
            total_rows += len(chunk)
            
            # √Åp d·ª•ng mapping
            def map_icd(row):
                key = (str(row['icd_code']), int(row['icd_version']))
                if key in mapping_dict:
                    return mapping_dict[key]
                return (str(row['icd_code']), int(row['icd_version']))
            
            # L∆∞u ICD g·ªëc ƒë·ªÉ ƒë·∫øm s·ªë thay ƒë·ªïi
            original_icd = chunk[['icd_code', 'icd_version']].copy()
            
            mapped = chunk.apply(lambda row: map_icd(row), axis=1)
            chunk['icd_code'] = [x[0] for x in mapped]
            chunk['icd_version'] = [x[1] for x in mapped]
            
            # ƒê·∫øm s·ªë d√≤ng thay ƒë·ªïi
            changed_mask = (original_icd['icd_code'] != chunk['icd_code']) | (original_icd['icd_version'] != chunk['icd_version'])
            changed_count += changed_mask.sum()
            
            # L∆∞u chunk
            mode = 'w' if first_chunk else 'a'
            header = first_chunk
            chunk.to_csv(output_file, mode=mode, header=header, index=False, 
                        compression='gzip' if str(output_file).endswith('.gz') else None)
            first_chunk = False
            
            if (chunk_num + 1) % 10 == 0:
                print(f"   ƒê√£ x·ª≠ l√Ω {total_rows:,} d√≤ng, ƒë√£ thay ƒë·ªïi {changed_count:,} d√≤ng...")
        
        print(f"\n‚úÖ ƒê√£ l∆∞u file ƒë√£ unified: {output_file}")
        print(f"   T·ªïng s·ªë d√≤ng: {total_rows:,}")
        print(f"   S·ªë d√≤ng ƒë∆∞·ª£c thay ƒë·ªïi: {changed_count:,}")
        print(f"   T·ª∑ l·ªá thay ƒë·ªïi: {changed_count/total_rows*100:.2f}%")
        
    else:
        # X·ª≠ l√Ω file nh·ªè (load to√†n b·ªô v√†o memory)
        df_diag = pd.read_csv(input_file, compression='gzip' if is_gzip else None, low_memory=False)
        print(f"   S·ªë d√≤ng ban ƒë·∫ßu: {len(df_diag):,}")
        
        # L∆∞u ICD g·ªëc ƒë·ªÉ ƒë·∫øm
        original_icd = df_diag[['icd_code', 'icd_version']].copy()
        
        # √Åp d·ª•ng mapping
        def map_icd(row):
            key = (str(row['icd_code']), int(row['icd_version']))
            if key in mapping_dict:
                canonical_code, canonical_version = mapping_dict[key]
                return pd.Series({
                    'icd_code': canonical_code,
                    'icd_version': canonical_version
                })
            return pd.Series({
                'icd_code': row['icd_code'],
                'icd_version': row['icd_version']
            })
        
        mapped = df_diag.apply(lambda row: map_icd(row), axis=1)
        df_diag['icd_code'] = mapped['icd_code']
        df_diag['icd_version'] = mapped['icd_version']
        
        # ƒê·∫øm s·ªë d√≤ng thay ƒë·ªïi
        changed_mask = (original_icd['icd_code'] != df_diag['icd_code']) | (original_icd['icd_version'] != df_diag['icd_version'])
        changed_count = changed_mask.sum()
        
        print(f"   S·ªë d√≤ng ƒë∆∞·ª£c thay ƒë·ªïi: {changed_count:,}")
        print(f"   T·ª∑ l·ªá thay ƒë·ªïi: {changed_count/len(df_diag)*100:.2f}%")
        
        # L∆∞u file m·ªõi
        output_file.parent.mkdir(parents=True, exist_ok=True)
        df_diag.to_csv(output_file, index=False, compression='gzip' if str(output_file).endswith('.gz') else None)
        print(f"\n‚úÖ ƒê√£ l∆∞u file ƒë√£ unified: {output_file}")
        print(f"   S·ªë d√≤ng sau mapping: {len(df_diag):,}")
        
        # Th·ªëng k√™ sau mapping
        unique_icd_after = df_diag.groupby(['icd_code', 'icd_version']).size().reset_index(name='count')
        print(f"   S·ªë ICD unique sau mapping: {len(unique_icd_after):,}")
        
        return df_diag
    
    return None

def load_icd_mapping():
    """H√†m ti·ªán √≠ch ƒë·ªÉ load mapping t·ª´ file"""
    if not MAPPING_FILE.exists():
        print(f"‚ö†Ô∏è  File mapping ch∆∞a t·ªìn t·∫°i: {MAPPING_FILE}")
        return None
    
    mapping_df = pd.read_csv(MAPPING_FILE)
    
    # T·∫°o dictionary ƒë·ªÉ lookup nhanh: (icd_code, icd_version) -> (canonical_code, canonical_version)
    mapping_dict = {}
    for _, row in mapping_df.iterrows():
        key = (str(row['original_icd_code']), int(row['original_icd_version']))
        mapping_dict[key] = (str(row['canonical_icd_code']), int(row['canonical_icd_version']))
    
    return mapping_dict

def map_single_icd(icd_code, icd_version, mapping_dict=None):
    """H√†m ti·ªán √≠ch ƒë·ªÉ map m·ªôt ICD code ƒë∆°n l·∫ª"""
    if mapping_dict is None:
        mapping_dict = load_icd_mapping()
        if mapping_dict is None:
            return icd_code, icd_version
    
    key = (str(icd_code), int(icd_version))
    if key in mapping_dict:
        return mapping_dict[key]
    return (str(icd_code), int(icd_version))

if __name__ == "__main__":
    # T√¨m duplicate
    duplicate_df = find_duplicate_icd_diagnoses()
    
    if duplicate_df is None or len(duplicate_df) == 0:
        print("\n‚ö†Ô∏è  Kh√¥ng c√≥ ICD tr√πng l·∫∑p ƒë·ªÉ x·ª≠ l√Ω.")
        sys.exit(0)
    
    # T·∫°o mapping
    mapping_df = create_icd_mapping(duplicate_df)
    
    if mapping_df is None:
        print("\n‚ö†Ô∏è  Kh√¥ng th·ªÉ t·∫°o mapping.")
        sys.exit(1)
    
    # M·∫∑c ƒë·ªãnh x·ª≠ l√Ω file g·ªëc ƒë·∫ßy ƒë·ªß
    # C√≥ th·ªÉ d√πng --lite ƒë·ªÉ x·ª≠ l√Ω file m·∫´u
    use_lite = '--lite' in sys.argv
    
    if use_lite:
        print("\nüìù Ch·∫ø ƒë·ªô: X·ª≠ l√Ω file lite (m·∫´u)")
        apply_mapping_to_diagnoses_icd(mapping_df, use_full_file=False)
        
        print("\n" + "=" * 60)
        print("‚ú® HO√ÄN TH√ÄNH!")
        print("=" * 60)
        print(f"\nüìÅ C√°c file ƒë√£ t·∫°o:")
        print(f"   1. Duplicate list: {DUPLICATE_FILE}")
        print(f"   2. Mapping: {MAPPING_FILE}")
        print(f"   3. Diagnoses ƒë√£ unified (file lite): {DATA_DIR / 'mimic-iv-lite' / 'diagnoses_icd_unified.csv'}")
    else:
        print("\n‚ö†Ô∏è  X·ª≠ l√Ω file g·ªëc ƒë·∫ßy ƒë·ªß (6M+ d√≤ng), c√≥ th·ªÉ m·∫•t v√†i ph√∫t...")
        apply_mapping_to_diagnoses_icd(mapping_df, use_full_file=True)
        
        print("\n" + "=" * 60)
        print("‚ú® HO√ÄN TH√ÄNH!")
        print("=" * 60)
        print(f"\nüìÅ C√°c file ƒë√£ t·∫°o:")
        print(f"   1. Duplicate list: {DUPLICATE_FILE}")
        print(f"   2. Mapping: {MAPPING_FILE}")
        print(f"   3. Diagnoses ƒë√£ unified (file g·ªëc): {DATA_DIR / 'proc' / 'diagnoses_icd_unified.csv.gz'}")
    
    print(f"\nüí° ƒê·ªÉ s·ª≠ d·ª•ng mapping trong code kh√°c:")
    print(f"   from jobs.02_unify_duplicate_icd import load_icd_mapping, map_single_icd")
    print(f"   mapping = load_icd_mapping()")
    print(f"   canonical_code, canonical_version = map_single_icd('99962', 9, mapping)")

